% \include{1-intro}
% \include{2-preliminary}
% \include{3-background}
% \include{4-standard}
% \include{5-zerocost}

% \include{6-depth}


\section{Evaluating Depth-Based Tiebreaking}
\label{sec:depth-based-evaluation}
We evaluated our depth-based diversifying tiebreaking strategies against standard
tiebreaking strategies.
In addition to the 35 IPC benchmark domains with 1104 instances used in
the previous set of experiments, we used 28 zerocost domains with 620
instances.
%  For randomized strategies, we
% show the coverage (mean $\pm$ sd) on
% 10 independent runs.


% This comparison below may be useful in a future version of the paper, but not necessary in this version.
%% First, we compared $[h,\ld,\lifo]$ and $[h,\fd,\fifo]$
%% with $[f,h,\lifo]$ and $[f,h,\fifo]$, respectively, in order to see
%% the extra cost of managing the depth-based buckets.
%% The node evaluation order of $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$
%% are exactly the same as $[f,h,\fifo]$ and $[f,h,\lifo]$.
%% This is because:
%% (1) $[f,h,\lifo]$ expands the most recently evaluated/inserted
%% states, and (2) the depth increases monotonically within the same $[f,h]$,
%% thus (3) $[f,h,\lifo]$ always expands the largest depth. (Similar logic
%% applies to $[f,h,\fifo]$.)
%% % 
%% % yet these results are useful in assessing the extra cost of managing the
%% % depth-based buckets.
%% As expected, the performances of $[h,\ld,\lifo]$ and
%% $[h,\fd,\fifo]$ are slightly worse than $[f,h,\lifo]$ and
%% $[f,h,\fifo]$, respectively, due to the cost of managing the depth-based buckets.

We compared 
$[h,\fd,\ro]$, $[h,\ld,\ro]$, and $[h,\rd,\ro]$. These all use 
$h$ as the first-level tiebreaking criterion, one of \fd, \ld, \rd as
the depth-based 2nd-level tiebreaking criterion, and finally,
\ro as the 3rd-level criterion.
Since these configurations are randomized, we run each configuration with 10 different random seeds.
To see whether differences among the mean coverages were statistically significant,
% of $[h,\ld,\ro]$, $[h,\rd,\ro]$,
we applied the non-parametric Wilcoxon's signed-rank test.
% ``non-parametric'' means ``normal distribution not assumed
%Wilcoxon test,
%a non-parametric significance testing method applicable to
%the populations in which normal distribution cannot be assumed.

\reftbl{tbl:depth} shows the coverage (mean $\pm$ sd),
along with the rightmost columns showing the 
Wilcoxon test $p$ values  for  $[h,\rd,\ro]$ vs. 3 other strategies.
%The results depend on the domains, but in many domains, 
In many domains,
the performance was significantly affected by 2nd-level tiebreaking, and
$[h,\rd,\ro]$ dominated the others. 
Although $[h, \ld, \ro]$ and $[h,\rd,\ro]$ performed similarly on most domains, 
the performance of $[h,\rd,\ro]$ in some
domains are notable (e.g., \pddl{Cybersec}, \pddl{Woodworking-cut}). 
The standard deviation of $[h,\rd,\ro]$ coverage tends to be smaller
than that of $[h,\ld,\ro]$, indicating that $[h,\rd,\ro]$ is robust with respect to random seeds.
$[h,\fd,\ro]$ is mostly dominated by $[h,\rd,\ro]$ and $[h,\ld,\ro]$,
except in \pddl{Scanalyzer-analyze}.
% 2015/9/13 -- let's try not including the following analysis in this submission -- due to space, and also too complicated, without sufficient payoff.
% We no longer need the ``depth as explanation of LIFO/FIFO'' story, because  the ``random is good'' depth-based methods [h,rd,ro]  story is simpler.

%% \todo{move this to the final section after reviewing the action ordering}
%% % removed \fifo
%% Finally, we answer two following concerns regarding \lifo final-level
%% tiebreaking criteria which appear in $[f,h,\lifo]$ and
%% $[h,\ld,\lifo]$. The evaluation in the earlier sections contains
%% two open questions: (1) Do the action orderings affect the performance of \lifo? 
%% (2) Doesn't \lifo benefit from its efficient low-level memory access pattern (high
%% probability of hitting the cache), not by the search efficiency?
%% They are both rejected because the
%% coverage of $[h,\ld,\lifo]=[f,h,\lifo]$ is not significantly
%% different from $[h,\ld,\ro]$, i.e.,
%% $859,857 \in [863.5-8.9,863.5+8.9]$,
%% despite the difference in the third-level tiebreaking (\lifo vs \ro).
%% % 
%% It means that the
%% performance of $[f,h,\lifo]$($=[h,\ld,\lifo]$) was not caused by the final-level
%% \lifo, but instead by the implicit second-level tiebreaking LastDepth.
%% %% remove
%% % Besides, this problem is not important now that RandomDepth
%% % is outperforming LastDepth-based tiebreaking strategy.
%% % 
%% With the similar logic, we can claim that the bad performance of
%% $[h,\fd,\fifo]$ and $[f,h,\fifo]$ can be attributed to its the
%% inherent second-level FirstDepth, and not to the third-level \fifo.
%% %% Unfortunately, 829,828 is not \in 816.7 +- 2.2.
%% %% this can be changed if we rerun _random with O(1) random deletion.


\begin{table}[htbp]
 {
 \centering
 \input{tables/aaai16-robustnesscheck/aaai16prelim3/1-depth.tex}
 \caption{
 Coverage comparison (the number of instances solved in 5min, 2GB, LMcut
 heuristics) between
 the standard baseline tiebreaking and depth-based tiebreaking. We highlight the
 best results when the difference between the maximum and the mininum coverage exceeds 2.
 }
 \label{tbl:lmcut-ipc-full}
 }
\end{table}

\begin{table}[htbp]
 {
 \centering
 \input{tables/aaai16-robustnesscheck-mands/aaai16prelim3/1-depth.tex}
 \caption{
 Coverage comparison (the number of instances solved in 5min, 2GB, M\&S heuristics) between
 the standard baseline tiebreaking and depth-based tiebreaking. We highlight the
 best results when the difference between the maximum and the mininum coverage exceeds 2.
 }
 \label{tbl:mands-ipc-full}
 }
\end{table}


% \begin{table}[htb]
%  {
%  \centering
%  \input{tables/aaai16-robustnesscheck-mands/zerocost/1-depth.tex}
%  \caption{
%  Full version of the bottom line of \reftbl{depth} showing 
%  the experiments on the IPC benchmark instances using \mands heuritics.
%  Each cell shows the coverage of the domain solved with 5 min, 2GB.
%  As in the original \reftbl{depth}, we highlighted the best results in
%  \textbf{boldface} only when the maximum pairwise coverage difference $\mit{MaxDiff}>2$.
%  }
%  \label{mands-zerocost-full}
%  }
% \end{table}
% 
% \begin{table}[htb]
%  {
%  \centering
%  \input{tables/aaai16-robustnesscheck/zerocost/1-depth.tex}
%  \caption{
%  Full version of the lower half of \reftbl{depth} showing 
%  the experiments on the Zerocost instances using \lmcut heuritics.
%  Each cell shows the coverage of the domain solved with 5 min, 2GB.
%  As in the original \reftbl{depth}, we highlighted the best results in
%  \textbf{boldface} only when the maximum pairwise coverage difference $\mit{MaxDiff}>2$.
%  }
%  \label{lmcut-zerocost-full}
%  }
% \end{table}


\subsection{Depth-Based Tiebreaking Without Considering $h$}

In \refsec{sec:h-necessary}, we showed that $[f,\lifo]$ tiebreaking (without considering $h$) is
sufficient for the standard IPC benchmarks -- the performance of $[f,\lifo]$, $[f,h,\lifo]$, and $[f,h,\fifo]$ are comparable.
\reftbl{tbl:depth} shows that $[\rd,\ro]$, which randomly selects an element from a randomly selected depth-bucket, dominates $[f,h,\fifo]$,
and performs comparably to $[f,h,\lifo]$.
Although $[\rd,\ro]$ behaves in a less greedy/depth-first manner than $[f,\lifo]$, 
it explores nodes with high depth sufficiently often so that even if \lifo behavior (seeking nodes that are far from the plateau entrance) is required, $[\rd,\ro]$ will eventually find the solution.
Moreover, there are some domains (\pddl{pipesworld-pushend} and \pddl{woodworking-opt11}) where a the more randomized behavior of $[\rd,\ro]$ is advantageous.
Thus, overall, $[\rd,\ro]$ performs moderately well, and 
\emph{neither $h$ nor \lifo-behavior is necessary in order to obtain performance that is competitive with the standard
tiebreaking strategies}.



%% moved to Table 2

\subsection{Is Depth-Based Tiebreaking Necessary?}
% is this the right location -- maybe this should in a discussion section?

We have shown that $[h,\rd,\ro]$ performs well overall, but
one might wonder whether the power of this strategy really comes from depth-based tiebreaking, or from randomness.
\reftbl{tbl:depth} shows that $[h,\ro]$ performs poorly, so clearly, random tiebreaking combined with $h$-based tiebreaking is not sufficient.
The reason that $[h,\ro]$ performs so poorly is that if we select uniformly from the bucket of all open nodes in the plateau, there is a very strong bias for selecting a node with low depth, simply because at any given point during the search in the plateau region, more nodes closer to the plateau entrance (i.e., lower depth) will have been generated.
By randomly selecting a depth bucket, $[h,\rd,\ro]$ explicitly eliminates this bias for selecting nodes for low depth.

% COMMENTED OUT: random-h is too weak, because if we have an admissible heuristic, the adversary can't fool h.
% One might also wonder whether the power of $[h,\rd,\ro]$ comes from having multiple levels of randomness, and not from the notion of depth.
% This is not the case -- multiple levels of randomness would not suffice to capture the power of $[h,\rd,\ro]$ due to the following reason:
% Consider another possible randomized strategy, $[random-h,\ro]$, which first picks a random $h$-bucket, 
% and then picks a random element from that bucket.
% When the final plateau of [f,h] is small, tiebreaking strategies do not significantly affect performance.
% However, when the final plateau of [f,h] is large, then $[random-h,\ro]$ will behave similarly to $[h,\ro]$, because almost all nodes in the search space have the same h-value, and we have shown that $[h,\ro]$ performs poorly on domains with large plateaus, i.e., domains with zero-cost-actions., compared to $[h,\rd,\ro]$.
% Thus, multiple levels of randomness alone do not account for the success of $[h,\rd,\ro]$, and the notion of depth buckets seems necessary.


\subsection{Search Behavior Within a Plateau}

To understand the behavior of depth-based policies, we plotted the histogram of
the depths of search nodes opened by
the most successful depth-based strategy, $[h,\rd,\ro]$, as well as 
the standard $[f,h,\fifo]$, $[f,h,\lifo]$ strategies
in the final plateau, plateau($f^*,0$) until the solution is found.
% 
Although $[f,h,\fifo]$ and $[f,h,\lifo]$ do not operate with an explicit notion of ``depth'', 
they are equivalent to $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$, respectively,
%so we recorded the depths according to these depth-based equivalents of $[f,h,\fifo]$ and $[f,h,\lifo]$.
so we recorded and plotted the depths according to  $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$.


\refig{fig:depth-histogram} shows the result
on
 \pddl{Openstacks-opt11} p10 (left) and
 \pddl{Woodworking-cut} p04 (right).
 % and \pddl{psr-small-open} p48 (right)
In both instances, 
% \pddl{openstacks} and \pddl{Woodworking-cut}, 
we observed that the depth-first behavior of $[f,h,\lifo]$ results in 
deeper search, missing the key branch at intermediate depths.
On the other hand, the breadth-first behavior of $[f,h,\fifo]$ often gets stuck spending an excessive amount of time searching around the plateau entrance.
$[h,\rd,\ro]$ is balancing the search at various depths, which results in successfully solving more problems within the time limit (\reftbl{tbl:depth}). %to avoid confusion, avoiding word ``coverage'' here because coverage could refer to search algorithm ``covering'' the search space.

% The figure also illustrates the behavior of RandomDepth: Although it
% randomly selects from the buckets,
% a new depth is found only when the largest-depth bucket is selected,
% resulting in a decreasing curves.
% Finding the optimal balance is an interesting avenue of
% future work.

\begin{figure}[tb]
 \centering \relsize{-3}
 \hfill
 \includegraphics{tables/aaai16-log-rd/aaai16prelim3/depth-histogram-openstacks-opt11-strips-p10.pdf}
 \hfill
 \includegraphics{tables/aaai16-log-rd/2zerocost/depth-histogram-woodworking-cut-p04.pdf}
 \hfill
 % \includegraphics{tables/aaai16-log-rd/2zerocost/depth-histogram-psr-small-open-p48.pdf}
 \caption{Number of nodes ($y$-axis) expanded per depth ($x$-axis) in
 the final plateau for 
 % (in left-to-right order)
 \pddl{Openstacks} p10 
 (left)
 and
 \pddl{Woodworking-cut} p04
 (right)
 %  and
 % \pddl{psr-small-open} p48
 with different tiebreakings.
 % Axes are logarithmic.
 }
 \label{fig:depth-histogram}
\end{figure}

\subsection{Comparison With $\varepsilon$-Cost Transformation}

\begin{table}[tb]
 \centering
 \begin{tabular}{|c|c|c||c|c|}
  \hline
  Domain & $[f,h,\fifo]/\varepsilon$ &  $[f,h,\lifo]/\varepsilon$ &  $[h,\fd,\ro]$ &  $[h,\rd,\ro]$ \\
  \hline
  \lmcut Zerocost & 261 & 259 & 257.4\spm{}2.0  &  \textbf{294.2\spm{}2.3} \\
  \hline
  \mands Zerocost & 282 & 282 & 274.0\spm{}0.9  &  \textbf{310.2\spm{}2.1} \\
  \hline
 \end{tabular}
 \caption{Comparison of  depth-based tiebreaking methods vs. standard $[f,h,\fifo]$ and $[h,lifo]$ methods applied to $\varepsilon$-cost-transformed versions of the problem instances}
 \label{tbl:epsilon}
\end{table}

An alternative approach to addressing the large plateaus in zero-cost domains is
to eliminate plateaus by introducing artificial gradients in the search space.
For example, the cost of all zero-cost actions can be replaced by a small $\varepsilon\ll 1$, where 
$\varepsilon$ is chosen such that the optimal cost for the result of  this \emph{$\varepsilon$-cost transformation} (``$\varepsilon$-transformation'') is the same as the cost of the optimal solution to the original domain with zero costs when the $\varepsilon$-transformed costs are mapped back to 0.

We evaluated the $[f,h,\fifo]/\varepsilon$ and $[f,h,\lifo]/\varepsilon$ strategies, which are the standard $[f,h,\fifo]$ and $[f,h,\lifo]$ tiebreaking strategies applied to  the $\varepsilon$-transformed version of the problems.
Since Fast Downward  only supports integer costs, we implemented/simulated the transformation by multiplying the non-zero costs by $10^6$, and assigning cost 1 to zero-cost actions -- in effect,  $\varepsilon=10^{-6}$.
\reftbl{tbl:epsilon} shows that $[f,h,\fifo]$ and $[f,h,\lifo]$ with $\varepsilon$-transformation
 perform comparably to $[h,\fd,\ro]$, but are outperformed by $[h,\rd,\ro]$.
% 
The similarity in performance between $\varepsilon$-transformation and $[h,\fd,\ro]$ can be explained by the fact that  OPEN is sorted according to  $f(n)+k(n)\varepsilon$,
where $k(n)$ is a number of zero-cost actions in the path to node $n$,
while expansion order of FirstDepth is equivalent to $f(n)+\depth{n}\varepsilon$.
($\depth{n}\leq k(n)$ because $k(n)$ accounts zero-cost actions also in non-final plateaus).
% 
One advantage of the $\varepsilon$-transformation is that it can be implemented by transforming the input problem and does not require implementation of depth-based buckets in the search algorithm.
On the other hand, there are two issues with the $\varepsilon$-transformation:
(1) $\varepsilon$ must be chosen carefully -- admissibility is lost  when $k(n)\varepsilon\approx 1$, and
(2) the number of possible $g$ and $f$ values becomes very large, making it difficult to use efficient $O(1)$ array-based implementation of the OPEN list and requiring the use of a heap-based $O(\log n)$ OPEN list.
% it makes array-based $O(1)$ OPEN-list consume too much memory
% because the queue contains too many different key values, 
% or it forces
% In contrast, depth can be directly implemented with just another level of nested arrays.

\subsection{Comparison to Multi-Heuristic Tiebreaking with PLUSONE Cost Type}



\section{Related Work}
\label{sec-4}

Previous work on escaping search space plateaus has focused on
non-admissible search.  DBFS \cite{imai2011novel} % is a technique which
adds stochastic backtracking to Greedy Best First Search (GBFS) to avoid
being misdirected by the heuristic function. Type based bucket
\cite{xie14type} classifies the plateau of GBFS according to the
$[g,h]$ pair and distributes the effort.  Marvin \cite{Coles07} learns plateau-escaping macros
from the Enhanced Hill Climbing phase of the FF planner
\cite{Hoffmann01}, and the use of these macros is inadmissible.
\citeauthor{Hoffmann05} gives a detailed analysis of the
structure of the search spaces of satisficing planning (\citeyear{Hoffmann05,Hoffmann11}).
\cite{benton2010g} proposes inadmissible technique for temporal planning
where short actions 
% are hidden behind long actions and
do not increase makespan. 
\cite{cushing2010cost} investigates ``$\varepsilon$-cost
traps''($\varepsilon=\frac{\min cost}{\max cost}$),  showing that (non-admissibly) treating all actions as unit cost sometimes finds an optimal plan quickly.
\cite{wilt2011cost} also analyzes inadmissible distance-to-go estimates.
% 
To our knowledge, 
plateaus have not been previously investigated for cost-optimal planning with admissible search.
Admissible and inadmissible search differ significantly in how non-final plateaus (plateaus with $f < f^*$) are treated:
Inadmissible search can skip or escape plateaus whenever possible, while
admissible search cannot, unless it
is the final plateau ($f=f^*$, $h=0$) and a solution is found. %it directly finds a solution.

%In their work on combining multiple heuristics in a planner, 
% \citeauthor{RogerH10} (\citeyear{RogerH10}) considered a tiebreaking approach which works as follows:
% When combining two heuristics, one of the
% heuristics is used as the primary criterion, % for guiding the search,
% and the second heuristic is used to break ties among nodes with the same primary
% heuristic value.
% While this did not perform well in their work on satisficing planning, 
% additional policy using a secondary heuristic
% for cost-optimal search is an interesting direction for future work.


The PLUSONE %\footnote{This term is used on the Fast Downward website.} XXfootnote takes too much space
cost-type (or distance-to-go) is a non-admissible search technique in the Fast Downward/LAMA planner
\cite{richter2010lama} which increases all action costs by 1.
% By eliminating zero-cost actions, this behaves similar to our $[h,\fd,\ro]$ tiebreaking.
%Using PLUSONE, three successive
%applications of zero-cost operators have cost 3, and two
%applications have cost 2, and smaller cost is preferred, just as
%\astar always expands the node with smaller $f$-value.
This technique explicitly targeted zero-cost actions,
and resulted in significantly better performance in the IPC-6
satisficing track \cite[p.137, Sec. 3.3.2]{richter2010lama}.
%\todo*{citation}
% There's a long discussion of Openstacks in \cite{richter2010lama}, p.167-169, but I can't find PLUSONE anywhere. Maybe it's called something else in the paper?  Maybe \richter2010lama is the wrong citation??
Unlike PLUSONE, depth-based tiebreaking is admissible.
%because unlike PLUSONE, action costs are not modified.  
Also, unlike PLUSONE, depth-based tiebreaking does not necessarily favor smaller depth over larger depth.
LAMA prefers smaller cost (including the increased cost),
which biases the search toward nodes with fewer zero-cost actions on their path.
This bias is similar to the $[h,\fd,\ro]$ policy,
the worst performer among all depth-variants in our experiments (\reftbl{depth}).
The best depth-based methods are  $[h,\ld,\ro]$ and $[h,\rd,\ro]$,
which do not prefer smaller depth.

% It's not clear what these techniques have in common, except that they are all orthogonal to heuristics,
% If that's the case, then there's no need to cite them in this paper -- there's no reason why these particular techniques
% are more relevant to this paper than hundreds of other techniques that are orthogonal to heuristics.
%% In admissible planning,
%% \emph{Symmetry Breaking}
%% \cite{Fox1998,pochter2011exploiting,domshlak2013symmetry} is the search
%% technique that tries to prune the states with symmetric
%% paths. \emph{Partial Order Reduction}
%% % , \emph{Strong Stubborn Sets} and \emph{Expansion Core} are
%% is also a technique which prunes the
%% intermediate states that reach to the same goal using the different
%% orders of same actions. \emph{Dominance Pruning} \cite{hall2013faster} is a
%% technique which prunes a state if it can be proven to be worse than the other nodes.
%% % 
%% These are usually not considered an attempt to improve the heuristic
%% estimates, however, in terms of \emph{Path-dependent globally admissible
%% heuristics} \cite{karpas2012optimal}, a class of heuristics which is
%% admissible only on a particular optimal path, generalizes the above
%% techniques as assigning an infinite cost to some nodes on the other optimal paths.
%% % 
%% % From a slightly different category, Pathmax \cite{mero1984heuristic} and
%% % Bidirectional Pathmax \cite{felner2011inconsistent} are the techniques
%% % which converts an inconsistent heuristics into non-decreasing,
%% % consistent heuristics.
%% Thus, in a broad term, all of these methods are the
%% attempts to improve the heuristic estimates.
%% % Although in some particular
%% % case they may be able to return a perfect heuristics, they are still not
%% % always a perfect heuristics, implying that the plateau is unavoidable.
%% In contrast, our tiebreaking techniques aims specifically at the case
%% where the plateau is encountered and the planners are forced to run a
%% knowledge-free search.

%% $LA^*$ \cite{stern2010look} extends \astar by performing a
%% cost-bounded depth-first \emph{lookahead} from each node as it is generated.
%% Under the lookahead cost bound $k=0$ ($LA^*_0$ in their notation),
%% all children with the same $f$-value are expanded.
%% The tiebreaking among the same $f$ is not documented either
%% in its main $A^*$ expansion nor in its DFS lookahead.


\section{Conclusion}

In this paper, we evaluated standard tiebreaking
strategies for \astar.
We showed that contrary to conventional wisdom, tiebreaking based on the heuristic value is not necessary to achieve good performance, and proposed
a new framework for defining tiebreaking policies based on \emph{depth}.
We showed that a depth-based, randomized strategy $[h,\rd,\ro]$, which uses the heuristic value, but explicitly avoids depth and ordering biases present in previous methods,
significantly outperforms previous strategies on domains with zero-cost actions, 
including practical application domains with resource optimization objectives in the IPC benchmarks.
% and slightly outperforms previous strategies on benchmark problems without zero-cost actions.
%We have shown that our $[h,\rd,\ro]$ strategy is successful because the randomized depth bucket selection explicitly avoids the depth bias that was present in previous methods
The proposed approach is highly effective on domains where zero-cost actions create large plateau regions where all nodes have the same $f$ and $h$ costs
and the heuristic function provides no useful guidance.
% We argued that such domains arise naturally when considering resource optimization problems.
%It also avoids the effect of action ordering in the domain definition,
%providing a robust behavior.
 % when the distribution of optimal solutions is not uniform within the open list.
% We also showed that this nonuniform distribution still appears when we have almost-perfect % heuristics.
%% Our method differs from the pruning techniques because we do not prune
%% any states, nor from the other general improvements to the heuristic
%% accuracy because we just change the evaluation order within the same
%% $f$, yet it address the fundamental problems in the heuristic forward
%% search. 
%% % 


%While we focused on randomized policies because plateaus, by definition do not provide useful heuristic information, 
%a direction for future work is development of deterministic variants.

%% not much details of the idea were presented in this paper. Also, I
%% don't want it to be copied by someone;;
% on-line adaptation methods that exploit search space neighborhood structure
% in order to adjust the tiebreaking policies.

\section{Background: Tiebreaking Strategy for GBFS}

\label{sec:gbfs}

\section{Notations and Backgrounds for \\Diversified Algorithms}

We first define some notation and the terminology used throughout the
rest of the paper.
$h(s)$ denotes the heuristic estimate from the current state to the
goal state.
$g(s)$ is the current shortest path cost from the initial state to the
current state.
$f(s)=g(s)+h(s)$ is the estimate of the resulting cost of the path
containing the current state.
We omit the argument $(s)$ unless necessary.

A \emph{sorting strategy} of a best first search algorithm is a strategy
which tries to select a single node from the OPEN list.
Sorting strategies are denoted as $[\text{criterion}_1, \text{criterion}_2, ..., \text{criterion}_k]$,
which means: From the OPEN list, first, select a set of nodes using $\text{criterion}_1$.
If there are still multiple nodes remaining in the set, then break ties
using $\text{criterion}_2$ and so on,
until a single node is selected.
The \emph{first-level sorting policy} of a strategy is
$\text{criterion}_1$, the \emph{second-level sorting policy} is
$\text{criterion}_2$, and so on.
%% the word frontier is no longer used in the later text.
% \emph{final frontier} is the set of open nodes with $f^*$.
Note that this corresponds to the command line option format of Fast
Downward \cite{Helmert2006}.

Using this notation, \astar without any tiebreaking strategy can be
denoted as BFS with $[f]$, and \astar which breaks ties according to $h$
value is denoted as $[f,h]$. Similarly, GBFS is denoted as 
$[h]$.  Unless stated otherwise, we assume the nodes are sorted in the
increasing order of the key value, and a BFS always selects the smallest
key value.



The sorting strategy may fail to select a single node. In such cases, a
search algorithm must decide which node to expand by the
\emph{last-resort} tiebreaking strategy, which is one of FIFO
(First-In-First-Out), LIFO (Last-In-First-Out) or RAND (random
ordering).  Trivially, these strategies are able to select a single node
from the set of nodes.  Throughout the paper, we show the last-resort
tiebreaking in the subscript such as $[f,h]_{\lifo}$, and we imply LIFO
when it is omitted.

% A \emph{plateau} is a set of nodes in OPEN with both the same $f$ and same $h$ costs.
% A plateau whose nodes have $f$-cost $f_p$ and $h$-cost $h_p$ is denoted as
% $\plateau{f_p,h_p}$.
% An  \emph{entrance} to a $\plateau{f_p,h_p}$ is a node $n \in \plateau{f_p,h_p}$, whose current parent is not a member of $\plateau{f_p,h_p}$.
% The \emph{final plateau},  is the plateau containing the solution found by the search algorithm.
% In \astar using admissible heuristics, the final plateau is  $\plateau{f^*,0}$.

\section{Backgrounds}

\todo{unrelated -- interesting but too ambitious?}
Heuristic errors consist of two major components called \emph{precision}
and \emph{accuracy}. Both terms are defined based on the distribution of
the heuristic estimates compared to the true distance to the goal $h^*$,
but has a key difference as follows: \emph{accuracy} accounts for the
difference of means, while \emph{precision} accounts for the deviation
from the true distance. The notion was proposed in the early days of
literature for investigating the performance of probabilistic heuristic
function \cite{pearl1984heuristics}, but is largely forgotten in the
current search community. \citeauthor{pearl1984heuristics}
concluded that, for satsificing search, the key characteristics which
determines the performance of inadmissible heuristics is
\emph{precision}, rather than \emph{accuracy}. Assume we have an
inadmissible heuristic function which always overestimates the true
distance $h^*$ by a constant error $e$ --- the guidance provided by
function $h^*(s)+e$ is not much different from that of $h^*(s)$
itself. This is because it changes the accuracy but does not change
the precision of the heuristics.

KBFS(k) \cite{Korf??} is an early attempt on alleviating the problem of
GBFS. It expands $k$ nodes at a time in order to prevent the search
algorithm from getting stuck in the heuristic trap. KBFS provided an
interesting observation to GBFS --- KBFS(1) is equivalent to GBFS, and
KBFS($\infty$) is equivalent to Breadth-First Search.

Alternation OPEN List \cite{RogerH10} is a technique to combine multiple
heuristic functions during the search in order to improve the robustness
of the search algorithm. Nodes are simultaneously stored and sorted into the
multiple independent OPEN lists with different sorting strategies, and
it alternates among the OPEN lists when it expands a new node.
We denote an alternating OPEN list as $\mit{alt}(X_1,X_2,\ldots)$ where
each $X_i$ is a sorting strategy.

$\epsilon$-greedy GBFS \cite{valenzano2014comparison} is a variation of GBFS
which selects a random node in the OPEN list at a certain fixed
probability $\epsilon <1$ given as a parameter. When the random
exploration takes place, the entire nodes in OPEN list are treated equally, and
there is no explicit criteria for characterising the nodes.
This is conceptually equivalent to the weighted version of the alternation
open list using $[h]_{\fifo}$ and $[\ ]_{\ro}$ (no sorting criteria) with weights
$1-\epsilon$ and $\epsilon$. We denote such a weighted alternation open
list as $\mit{alt}(w_1X_1,w_2X_2,\ldots)$ where each $w_i$ is a weight
for a sorting strategy $X_i$. Now $\epsilon$-greedy GBFS corresponds to
$\mit{alt}((1-\epsilon)[h]_{\fifo},\epsilon [\ ]_{\ro})$.

While the exploration phase of $\epsilon$-greedy GBFS does not have any method to detect the bias
between the nodes,
Type-GBFS \cite{xie14type} does this by running the 
classification of the nodes. The nodes are categorized into buckets
(called ``type bucket''), each associated with a specific vector of key
values, such as $[g,h]$ for each state. On each explorative
expansion, the search algorithm selects a random node in a random
bucket, which avoids the cardinality bias --- the search nodes
may be more concentrated in a particular bucket, and exploration done by
$\epsilon$-greedy fails to explore the variety of search space, unlike
Type-GBFS.

Type-GBFS categorizes the nodes in type buckets, but does not sort the
buckets with the key vector. Thus, we denote such a random
selection among buckets as $\brackets{\ldots}$ where $\ldots$ is a
classification criteria, e.g., $\brackets{g,h}$ denotes the type buckets
whose keys are the vector $[g,h]$.

In their paper, the method was evaluated under a
configuration that the explorative expansion and the exploitative
expansion (standard GBFS) alternates. 
Thus, we can write this algorithm as $\mit{alt}([h], \brackets{g,h}_{\ro})$.
% This also corresponds to the case of $\epsilon$-greedy with $\epsilon=0.5$.
% 
They empirically show that
this configuration results in larger coverage and that it
expands much broader variety of nodes in the explorative
expansion phase.

\begin{table}[htbp]
 \centering
 \setlength{\tabcolsep}{0.2em}
 % \begin{tabular}{|l|l|}
 \begin{align*}
  \mbox{\astar without tiebreaking}         &: [f]   \\
  \mbox{\astar, break ties for smaller $h$} &: [f,h] \\
  \mbox{Standard GBFS}                      &: [h]   \\
  \mbox{GBFS+Alternation (2 heuristics)}    &: \mit{alt}([h_1],[h_2])   \\
  \mbox{$\epsilon$-greedy GBFS}             &: \mit{alt}((1-\epsilon)[h], \epsilon [\ ]_{\ro}) \\
  \mbox{Type-GBFS, type = $[g,h]$}          &: \mit{alt}(\quad       [h],\quad \brackets{g,h}_{\ro}) \\
  \mbox{$\epsilon$-greedy Type-GBFS}        &: \mit{alt}((1-\epsilon)[h], \epsilon\brackets{g,h}_{\ro}) \\
  \mbox{\astar + $h$ tiebreaking + depth}   &: [f,h]_{\brackets{\mit{\scriptsize depth}}} \\
  \mbox{GBFS + depth}                       &: [h]_{\brackets{\mit{\scriptsize depth}}} \\
 \end{align*}
 % \end{tabular}
 \caption{Various search algorithms using the notation in this paper}
\end{table}

%% less priority. remove?
% DBFS \cite{imai2011novel} is also an algorithm which diversifies the
% search based on $g$ and $h$ values, but with several key differences from
% above two algorithms: First, the explorative selection is not uniformly
% random, but is subject to a particular distribution function defined by
% $h, g, h_{min}$ and $g_{max}$. Second, it uses a local search with
% a bounded number of expansions equal to $h(s)$, which dynamically balances the exploration
% and exploitation --- it does more GBFS when $h$ is large (far
% from the goal), and less GBFS near the goal ($h$ is small).



% The diversification based on the depth can be considered as an instance
% of last-resort tiebreaking, since the depth is used \emph{after} the
% sorting strategy selects a set of nodes.
% % 
% We can also view the depth-based diversification as a classification of
% the nodes into type-based buckets with depth as a single key value.
% Thus, we call this framework as \emph{typed-sorting strategy}, a mix of
% sorting strategy and type-based buckets, denoted as $[\mbox{sorting
% strategy}]_{\brackets{\mbox{\small type vector}}}$.
% % 
% For example, \astar using $h$ as the first tiebreaking criteria and
% depth as a diversification method can be expressed as
% $[f,h]_{\brackets{d}}$. 
% % _{\fifo}
% % The reason \fifo is present
% % after $\brackets{d}$ is that when multiple nodes are in the same depth, a
% % single node is selected in a FIFO order.
% % Trivially, $[\ ]_{\brackets{X}}$ is equivalent to $\brackets{X}$ and
% % $[X]_{\brackets{\ }}$ is equivalent to $[X]$.


\section{Depth-based Tiebreaking for GBFS}

%\citeauthor{Korf1985depth} uses $h$-based tiebreaking in the context of WA*
%\cite{korf1993linear} 
% 
% (g-based tiebreaking, p69, for GBFS:) With all the weight on h, meaning
% that g is used only for tie-breaking among nodes with equal h values,
% 
% (p73:) to break ties in favor of nodes closest to the initial state.  
% ** not sure how/where to put this..


Compared to \astar, to our knowledge, there are currently no
well-established tiebreaking policy for GBFS. GBFS does not use $f$ and
$g$ value during the search process.  The search by GBFS is solely
guided by the heuristic value $h$: It always expands the node with the
smallest $h$ value, and hence the analogy from \astar e.g.\ sorting the
nodes with $f$ and breaking ties according to $h$ is not possible.

As a consequence, except for diversification,
search enhancement for GBFS have been achieved by
modifying the heuristic function itself.  This includes not only using the
different heuristic functions, but also lazy evaluation,
preferred operators and PLUSONE/ONE cost type.
 
Lazy evaluation is a technique which derives the heuristic value of a
state from its parent. This sacrifices the informativeness of the
heuristics against the effort of computing each heuristic function.
 
Preferred operator (helpful action in \cite{Hoffmann01}) marks some
operators to be promising when it improved the least cost estimate in the
previous node expansion. Marked nodes are put in a special queue
which is expanded more often, which is equivalent to temporarily
increasing the priority of the particular nodes.
 
PLUSONE cost type is a technique which adds a cost of 1 to each edge
cost, which also affects the heuristic value. Similarly, ONE cost type
treats all actions to have a unit cost.  ONE cost type is used in
the first GBFS iteration of LAMA, and PLUSONE cost type is used in the
second GBFS iteration of LAMA (followed by WA*).

We instead consider the use of the depth-based tiebreaking policy, which
is able to identify the relative location of the current state in the
plateau.  In this section, we evaluate the effect of depth-based
tiebreaking on Eager GBFS, and also compare the effect
against various search enhancements stated above.

\subsection{Comparison against GBFS}

We compared the performance of 
($G$) the standard GBFS
$[h]$,
($G_d$) GBFS using depth-based diversification
$[h]_{\relsize{-2}\brackets{d}}$,
($T$) Type-GBFS
$alt([h],\brackets{g,h})$,
($T_d$) Type-GBFS using depth-based diversification
$alt([h]_{\brackets{d}},\brackets{g,h})$,
($T^d$) Type-GBFS using depth-based type bucket
$alt([h],\brackets{g,h,d})$,
($T_d^d$) Type-GBFS using both depth-based diversification and depth-based type bucket
$alt([h]_{\brackets{d}},\brackets{g,h,d})$.

Since the effect of depth could be heuristic-dependent, we tested three
heuristics as $h$:
FF heuristics\cite{Hoffmann01}, Causal Graph (CG) heuristics \cite{Helmert2006}, Context Enhanced
Additive (CEA) heuristics\cite{helmert2008unifying}.
%% not included --- its is a pseudo heuristics anyways
% , Landmark-Count (LC) heuristics\cite{richter2008landmarks}



% In order to remove the effect of randomness of the algorithm, we
% implemented a deterministic version of Type-based queue for Type-GBFS
% which, instead of selecting a bucket at random, iterates over the
% buckets in a reverse order that each bucket is introduced.
% Similarly, the diversification based on the depth is not randomized but
% is implemented as a loop-based implementation.

Results are shown in \reftbl{eager-results}. Overall, depth offers
improvements to all of CEA, CG and FF heuristics. Thus, we conjecture
that the effect of depth-based diversification is heuristic-independent.

We also tested the effect of lazy (deferred) evaluation of the
heuristic functions. As explained in the previous section, lazy
evaluation can be considered as a form of modifying the heuristic
function by sacrificing the accuracy for the node expansion rate.
As expected, depth-based diversification offers the similar speedup as
in the case of eager evaluation.

Another dimension we should consider in evaluating the depth
diversification is the use of PLUSONE which treats all
action costs as the original value plus 1, or ONE cost type which treats
all actions as the unit cost.

% \newcommand{\htitle}[1]{\multicolumn{#1}{c|}{CEA} & \multicolumn{#1}{|c|}{CG} & \multicolumn{#1}{|c|}{FF}}
\newcommand{\etitle}[2]{ \multicolumn{#1}{|c||}{Eager} & \multicolumn{#1}{|c|#2}{Lazy}}
\newcommand{\htitle}[2]{\multicolumn{#1}{c|}{CEA} & \multicolumn{#1}{|c|}{CG} & \multicolumn{#1}{|c|#2}{FF}}
\newcommand{\titles}[3]{
&\etitle{#1}{#3} \\
\hline
&\htitle{#2}{|} #3 &\htitle{#2}{}\\
\hline
}

\begin{table}[htbp]
 \setlength{\tabcolsep}{0.1em}
 % \setlength{\tabcolsep}{0.05em}
 % \relsize{-1}
\centering
\begin{tabular}{|l*{2}{*{3}{|cc}|}*{2}{*{3}{|cc}|}}
\hline
&\etitle{6}{|} & \etitle{6}{}\\
\hline
&\htitle{2}{|} & \htitle{2}{|} &\htitle{2}{|} & \htitle{2}{}\\
\hline
 & g & G & g & G & g & G & g & G & g & G & g & G & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt\\
\hline
coverage & 189 & \bi{193} & 174 & \bi{183} & 166 & 167 & 139 & \bi{172} & 137 & \bi{144} & 146 & \bi{162} & \bi{203} & 200 & 203 & \bi{210} & \bi{217} & 215 & 157 & \bi{173} & 165 & \bi{179} & 178 & \bi{212}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
lvtr & 1 & \bi{3} & 3 & \bi{5} & 0 & 0 & 1 & \bi{4} & 1 & \bi{4} & 0 & 0 & 1 & \bi{3} & 3 & 3 & 0 & 0 & 1 & \bi{3} & 1 & \bi{4} & 0 & 0\\
flrt & 4 & 4 & 0 & 0 & 7 & 7 & 6 & 6 & 0 & 0 & \bi{8} & 4 & 7 & 7 & 2 & 2 & 9 & 9 & 6 & 7 & 2 & 2 & 8 & 9\\
nmys & 7 & 7 & 7 & 7 & 6 & \bi{8} & 8 & 8 & 9 & 9 & 5 & \bi{7} & 9 & 9 & \bi{16} & 14 & 16 & 15 & 11 & 11 & 14 & 15 & 15 & 16\\
pnst & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
prcp & 15 & 15 & 15 & 15 & 5 & 5 & 12 & 12 & 11 & 11 & 0 & 0 & 15 & 15 & 15 & 15 & 7 & 7 & 11 & 11 & 10 & 10 & 6 & 6\\
prkn & 0 & 1 & 12 & 13 & 15 & 14 & 2 & \bi{4} & 3 & \bi{11} & 14 & \bi{19} & 3 & 2 & 7 & \bi{9} & \bi{12} & 8 & 1 & 0 & 3 & 4 & 15 & 16\\
pgsl & 19 & 19 & 20 & 20 & 19 & 19 & 19 & 19 & 20 & 19 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 19 & 20 & 20 & 20 & 20\\
scnl & 17 & 17 & 17 & 17 & 14 & 14 & 17 & 17 & 17 & 17 & 15 & 14 & 17 & 17 & 17 & 17 & 16 & 16 & 17 & 17 & 17 & 17 & 17 & 17\\
skbn & 12 & 12 & 14 & 14 & 18 & 17 & 10 & 11 & 15 & 15 & 18 & 17 & 15 & 16 & 16 & 17 & 18 & 18 & 16 & 16 & 13 & \bi{16} & 18 & 18\\
tdyb & 16 & 17 & 14 & \bi{18} & 15 & 14 & 16 & 17 & 14 & \bi{17} & 14 & 13 & 16 & 16 & 19 & 19 & 16 & 16 & 16 & 17 & 20 & 20 & 14 & \bi{16}\\
trns & 7 & 7 & 9 & \bi{11} & 0 & 0 & 3 & \bi{5} & 7 & 8 & 0 & 0 & 7 & 7 & 11 & 11 & 0 & 0 & 4 & 5 & 9 & 8 & 0 & 0\\
vstl & 3 & 3 & 3 & 3 & 5 & 5 & 3 & 3 & 3 & 3 & 5 & 4 & 4 & 4 & 4 & 5 & 6 & 5 & 4 & 4 & 5 & 5 & 4 & \bi{6}\\
wdwr & 10 & 10 & 10 & 10 & 12 & 12 & 2 & 3 & 1 & 1 & 10 & 11 & 12 & 11 & 12 & 13 & 15 & 15 & 3 & 4 & 1 & 1 & 7 & \bi{13}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 & 2 & 0 & 0 & 0 & 0 & 0 & 0\\
cvdv & 6 & 6 & 7 & 7 & 6 & 6 & 4 & \bi{7} & 7 & 7 & 6 & 6 & 6 & 7 & 7 & 7 & 7 & 7 & 7 & 7 & 8 & 8 & 7 & 7\\
chld & 2 & 2 & 2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \bi{2} & 0 & \bi{3} & 0 & 0 & 0 & 2 & 1 & 6 & 5 & 2 & 2\\
ctyc & 20 & 20 & 0 & \bi{2} & 0 & 0 & 1 & \bi{20} & 0 & 0 & 0 & 0 & 20 & 20 & 1 & 1 & 18 & \bi{20} & 1 & \bi{15} & 0 & 0 & 1 & \bi{10}\\
flrt & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 & 0 & 0 & 3 & 3 & \bi{5} & 3 & 2 & 1 & \bi{5} & 3 & 3 & 2 & 2 & 2 & 3 & 3\\
gd-s & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
hkng & 17 & 16 & 15 & 14 & 16 & \bi{18} & 17 & 17 & \bi{16} & 13 & 12 & \bi{14} & 16 & 16 & 20 & 20 & 20 & 20 & 16 & 15 & 18 & 19 & 18 & 18\\
mntn & 16 & 16 & 16 & 16 & 11 & 12 & 0 & 0 & 0 & 0 & 4 & \bi{7} & 16 & 16 & 16 & 16 & 13 & 14 & 7 & 7 & 7 & 7 & 9 & 10\\
pnst & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
prkn & 0 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 3 & \bi{11} & 0 & 0 & 0 & 0 & 2 & 2 & 0 & 0 & 0 & 0 & 1 & \bi{8}\\
ttrs & 3 & 4 & 2 & 2 & 3 & 3 & 1 & \bi{4} & 2 & 2 & 1 & \bi{3} & 2 & 2 & 6 & \bi{12} & 2 & \bi{4} & 1 & 2 & 2 & \bi{9} & 3 & \bi{6}\\
thgh & 11 & 11 & 4 & 5 & 11 & 10 & 12 & 12 & \bi{6} & 4 & 7 & \bi{9} & 9 & 8 & 5 & 5 & 12 & 13 & 9 & 9 & 5 & 5 & 10 & 11\\
trns & 1 & 0 & \bi{3} & 1 & 0 & 0 & \bi{3} & 0 & \bi{5} & 2 & 0 & 0 & 1 & 1 & 1 & \bi{3} & 0 & 0 & 1 & 1 & 2 & 2 & 0 & 0\\
vstl & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\hline
\end{tabular}
\caption{Results of 5 min, 4Gb experiments, comparing the variants with and without depths:}%
 % (g): GBFS $[h]$,
 % (G): GBFS with depth based diversification $[h]_\{d\}$.
 % Left side shows the result of eager evaluation, and the right side shows
 % the result of lazy evaluation.
 % ,
 % (gt): $alt([h],\brackets{g,h})$,
 % (gT): $alt([h],\brackets{g,h,d})$,
 % (Gt): $alt([h]_{\brackets{d}},\brackets{g,h})$,
 % (GT): $alt([h]_{\brackets{d}},\brackets{g,h,d})$
 % }
\end{table}

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{0.1em}
\begin{tabular}{lll|ccc|ccc}
 &  &  & Eager & Eager & Eager & Lazy & Lazy & Lazy\\
 &  &  & IPC7 & IPC8 & sum & IPC7 & IPC8 & sum\\
\hline
ce & g & F & 112 & 70 & 182 & 116 & 54 & 170\\
ce & G & F & 113 & 70 & 183 & 119 & 48 & 167\\
ce & gt & F & 120 & 67 & 187 & 125 & 67 & 192\\
ce & gT & F & 120 & 67 & 187 & 125 & 66 & 191\\
ce & Gt & F & 120 & \bi{77} & 197 & 128 & 62 & 190\\
ce & GT & F & 121 & \bi{77} & 198 & 129 & 62 & 191\\
cg & g & F & 126 & 54 & 180 & 110 & 37 & 147\\
cg & G & F & 132 & 55 & 187 & 118 & 36 & 154\\
cg & gt & F & 139 & 63 & 202 & 122 & 49 & 171\\
cg & gT & F & 138 & 63 & 201 & 121 & 49 & 170\\
cg & Gt & F & \bi{142} & 63 & \bi{205} & 129 & 56 & 185\\
cg & GT & F & \bi{142} & 63 & \bi{205} & 128 & 56 & 184\\
ff & g & F & 110 & 49 & 159 & 110 & 48 & 158\\
ff & G & F & 110 & 54 & 164 & 117 & 45 & 162\\
ff & gt & F & 130 & 71 & 201 & \bi{137} & \bi{75} & \bi{212}\\
ff & gT & F & 129 & 71 & 200 & 136 & \bi{75} & 211\\
ff & Gt & F & 134 & 68 & 202 & 132 & 59 & 191\\
ff & GT & F & 135 & 70 & \bi{205} & 133 & 59 & 192\\
\hline
ce & g & L & 111 & 78 & 189 & 99 & 40 & 139\\
ce & G & L & 115 & 78 & 193 & 109 & 63 & 172\\
ce & gt & L & 126 & 77 & 203 & 110 & 47 & 157\\
ce & gT & L & 127 & 76 & 203 & 114 & 45 & 159\\
ce & Gt & L & 127 & 73 & 200 & 114 & 59 & 173\\
ce & GT & L & 125 & 75 & 200 & 116 & 54 & 170\\
cg & g & L & 124 & 50 & 174 & 101 & 36 & 137\\
cg & G & L & 133 & 50 & 183 & 115 & 29 & 144\\
cg & gt & L & 142 & 61 & 203 & 115 & 50 & 165\\
cg & gT & L & 141 & 57 & 198 & 119 & 41 & 160\\
cg & Gt & L & \bi{145} & 65 & 210 & 122 & 57 & 179\\
cg & GT & L & \bi{145} & 59 & 204 & 122 & 48 & 170\\
ff & g & L & 116 & 50 & 166 & 110 & 36 & 146\\
ff & G & L & 115 & 52 & 167 & 109 & 53 & 162\\
ff & gt & L & 135 & 82 & \bi{217} & 124 & 54 & 178\\
ff & gT & L & 127 & 79 & 206 & 130 & 46 & 176\\
ff & Gt & L & 130 & \bi{85} & 215 & 137 & \bi{75} & \bi{212}\\
ff & GT & L & 133 & 74 & 207 & \bi{140} & 70 & 210\\
\end{tabular}
\end{table}

\begin{table}[htbp]
 \setlength{\tabcolsep}{0.1em}
 % \setlength{\tabcolsep}{0.05em}
 % \relsize{-1}
\centering
\begin{tabular}{|l*{2}{*{3}{|cc}|}*{2}{*{3}{|cc}|}}
\hline
&\etitle{6}{|} & \etitle{6}{}\\
\hline
&\htitle{2}{|} & \htitle{2}{|} &\htitle{2}{|} & \htitle{2}{}\\
\hline
 % & e & e & e & e & e & e & l & l & l & l & l & l & e & e & e & e & e & e & l & l & l & l & l & l\\
 % & ce1 & ce1 & cg1 & cg1 & ff1 & ff1 & ce1 & ce1 & cg1 & cg1 & ff1 & ff1 & ce1 & ce1 & cg1 & cg1 & ff1 & ff1 & ce1 & ce1 & cg1 & cg1 & ff1 & ff1\\
 & g & G & g & G & g & G & g & G & g & G & g & G & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt\\
\hline
IPC7 & 118 & 118 & 140 & \bi{143} & \bi{142} & 139 & 99 & \bi{117} & 113 & \bi{134} & 112 & \bi{143} & 130 & 130 & 153 & 154 & \bi{166} & 157 & 106 & \bi{121} & 124 & \bi{146} & 135 & \bi{156}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 10 & 10 & 0 & 0 & 0 & 0 & 2 & 2\\
lvtr & 8 & 8 & 8 & 9 & 10 & 10 & 10 & 10 & 9 & 8 & 8 & \bi{12} & 8 & 8 & 8 & 9 & 10 & 10 & 5 & \bi{8} & 7 & \bi{9} & 4 & \bi{11}\\
flrt & 3 & 3 & 0 & 0 & 3 & 4 & 3 & 3 & 0 & 0 & 3 & 3 & 5 & 5 & 2 & 2 & 8 & 7 & 5 & 5 & 2 & 2 & 6 & 6\\
nmys & 7 & 7 & 7 & 7 & 6 & \bi{8} & 8 & 8 & 9 & 9 & 4 & \bi{7} & 9 & 9 & \bi{16} & 14 & 16 & 15 & 11 & 11 & 14 & 15 & 15 & 16\\
pnst & 13 & 12 & 13 & 13 & 15 & 15 & 0 & \bi{15} & 0 & \bi{14} & 0 & \bi{20} & 11 & 11 & 11 & 11 & 13 & 13 & 0 & \bi{11} & 1 & \bi{12} & 4 & \bi{9}\\
prcp & 20 & 20 & 20 & 19 & 20 & 20 & 11 & 11 & 11 & 11 & 11 & 11 & 18 & 18 & 18 & 19 & 20 & 20 & 12 & 13 & 11 & 12 & 14 & 14\\
prkn & 0 & \bi{2} & 12 & 13 & \bi{15} & 11 & 2 & \bi{4} & 3 & \bi{11} & 14 & \bi{19} & 3 & 2 & 7 & \bi{9} & \bi{12} & 8 & 1 & 0 & 3 & 4 & 15 & 16\\
pgsl & 20 & 20 & 20 & 20 & 19 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
scnl & 17 & 17 & 17 & 17 & 14 & 14 & 17 & 17 & 17 & 17 & 12 & 13 & 16 & 16 & 17 & 17 & 15 & 15 & 17 & 17 & 17 & 17 & 17 & 17\\
skbn & 3 & 3 & 13 & 12 & 18 & 17 & 3 & 3 & 15 & 14 & 18 & 17 & 10 & 10 & 17 & 17 & 18 & 17 & 10 & 9 & 15 & \bi{17} & 18 & 18\\
tdyb & 16 & 17 & 14 & \bi{18} & \bi{15} & 13 & 16 & 17 & 14 & \bi{17} & 14 & 13 & 16 & 16 & 19 & 19 & 16 & 15 & 16 & 17 & 20 & 20 & 14 & \bi{16}\\
trns & \bi{7} & 5 & 12 & 11 & 0 & 0 & 4 & 5 & \bi{11} & 9 & 0 & 0 & 6 & \bi{8} & 13 & 12 & 0 & 0 & 3 & \bi{5} & 8 & \bi{12} & 0 & 0\\
vstl & 3 & 3 & 3 & 3 & 5 & 5 & 3 & 3 & 3 & 3 & 5 & 4 & 4 & 4 & 4 & 4 & 6 & 5 & 4 & 4 & 5 & 5 & 4 & \bi{6}\\
wdwr & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 1 & 1 & 1 & 2 & \bi{4} & 4 & 3 & 1 & 1 & 2 & 2 & 2 & 1 & 1 & 1 & 2 & \bi{5}\\
\hline
IPC8 & 62 & 62 & 60 & \bi{64} & 73 & 73 & 36 & \bi{50} & 39 & \bi{48} & 54 & \bi{93} & \bi{57} & 55 & 76 & \bi{79} & 80 & 79 & 44 & \bi{53} & 66 & \bi{74} & 66 & \bi{92}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \bi{4} & 2 & 0 & 0 & 0 & 0 & 0 & 0\\
cvdv & 6 & 6 & 7 & 7 & 7 & 7 & 4 & \bi{7} & 7 & 7 & 6 & 7 & 6 & 6 & 7 & 7 & 7 & 7 & 6 & 7 & 7 & 8 & 7 & 7\\
chld & 2 & 2 & 2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \bi{2} & 0 & \bi{3} & 0 & 0 & 0 & 2 & 1 & 6 & 5 & 2 & 2\\
ctyc & 2 & 2 & 0 & 1 & 0 & 0 & 0 & \bi{2} & 0 & 0 & 0 & 0 & 4 & 5 & 1 & 1 & 3 & 3 & 1 & \bi{9} & 0 & 0 & 0 & \bi{7}\\
flrt & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 1 & 1 & 2 & 2\\
gd-s & 0 & 0 & 0 & 0 & \bi{19} & 17 & 0 & 0 & 0 & 0 & 20 & 20 & 0 & 0 & 8 & 9 & 16 & 15 & 0 & 0 & 11 & 11 & 15 & \bi{17}\\
hkng & 17 & 16 & 15 & 14 & 16 & \bi{18} & 17 & 17 & \bi{16} & 13 & 12 & \bi{14} & 16 & 16 & 20 & 20 & 20 & 20 & 16 & 15 & 18 & 19 & 18 & 18\\
mntn & 16 & 16 & 16 & 16 & 11 & 12 & 0 & 0 & 0 & 0 & 4 & \bi{7} & 16 & 16 & 16 & 16 & 13 & 13 & 7 & 7 & 7 & 7 & 9 & 10\\
pnst & 0 & 0 & 0 & 0 & 4 & 4 & 0 & \bi{3} & 0 & \bi{3} & 0 & \bi{20} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & \bi{6}\\
prkn & 0 & 2 & 1 & 1 & 2 & 1 & 0 & 1 & 0 & 1 & 3 & \bi{11} & 0 & 0 & 0 & 0 & 1 & 2 & 0 & 0 & 0 & 0 & 1 & \bi{8}\\
ttrs & 4 & 3 & 12 & \bi{15} & 1 & 2 & 1 & \bi{5} & 7 & \bi{17} & 0 & \bi{3} & 1 & 1 & 13 & \bi{15} & 2 & 2 & 1 & 3 & 9 & \bi{15} & 2 & \bi{4}\\
thgh & 12 & 11 & 4 & 5 & 11 & 10 & 12 & 12 & \bi{6} & 4 & 7 & \bi{9} & 9 & 8 & 5 & 5 & 12 & 13 & 9 & 9 & 5 & 5 & 10 & 11\\
trns & 1 & 2 & 3 & 3 & 0 & 0 & 0 & 1 & 3 & 3 & 0 & 0 & 1 & 1 & 1 & \bi{4} & 0 & 0 & 0 & 0 & 2 & 2 & 0 & 0\\
vstl & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\hline
\end{tabular}
\caption{Results obtained by treating each action to have a unit cost
 during heuristic calculation.
 5 min, 4Gb experiments, comparing the variants with
 and without depths:
 % (g): GBFS $[h]$,
 % (G): GBFS with depth based diversification $[h]_\brackets{d}$.
 Left side shows the result of eager evaluation, and the right side shows
 the result of lazy evaluation.
 % ,
 % (gt): $alt([h],\brackets{g,h})$,
 % (gT): $alt([h],\brackets{g,h,d})$,
 % (Gt): $alt([h]_{\brackets{d}},\brackets{g,h})$,
 % (GT): $alt([h]_{\brackets{d}},\brackets{g,h,d})$
 }
\end{table}


% \subsection{Comparison against Lazy Evaluation}

% Although the policy was originally designed for optimising
% \astar search with admissible heuristics, the core idea of depth would
% not be much affected by the difference between \astar and GBFS.

\subsection{Comparison against LAMA}

LAMA \cite{richter2010lama} is a \sota planner which is a winner of
IPC2011. It has numerous search enhancements including Lazy Evaluation,
Multi-heuristic search, Preferred Operators and PLUSONE cost type.

LAMA runs a GBFS followed by WA* with decreasing weights, and works in
an anytime fasion. However, this is due to the context of the
competition setting where the task also includes finding a better plan.
Since this paper focuses on GBFS, we only consider 
the coverage within the resource constraint. Thus, in the following
experiments, we do not run the successive iterations of WA* in LAMA.

The first iteration (GBFS) of LAMA is expressed as
$alt([\mit{ff}],\pref{[\mit{ff}]},[\mit{lc}],\pref{[\mit{lc}]})$, where $\mit{ff}$
denotes the FF heuristics, $\mit{lc}$ denotes the Landmark-Count heuristics,
and $\pref{X}$ denotes the preferred operator queue with sorting
strategy $X$.

We compare this base LAMA with the type-based version of LAMA and their
variants using depths.
We followed the best configuration suggested by \citeauthor{xie14type} (\citeyear{xie14type})
for Type-GBFS, which uses the type vector $\brackets{g,\mit{ff}}$.
Due to the multiple enhancements, the configurations are fairly complicated:

\begin{eqnarray}
  alt([\mit{ff}],\pref{[\mit{ff}]},[\mit{lc}],\pref{[\mit{lc}]},\brackets{g,\mit{ff}}) \\
  alt([\mit{ff}]_\brackets{d},\pref{[\mit{ff}]_\brackets{d}},[\mit{lc}]_\brackets{d},\pref{[\mit{lc}]_\brackets{d}},\brackets{g,\mit{ff}}) \\
  alt([\mit{ff}],\pref{[\mit{ff}]},[\mit{lc}],\pref{[\mit{lc}]},\brackets{g,\mit{ff},d}) \\
  alt([\mit{ff}]_\brackets{d},\pref{[\mit{ff}]_\brackets{d}},[\mit{lc}]_\brackets{d},\pref{[\mit{lc}]_\brackets{d}},\brackets{g,\mit{ff},d}) 
\end{eqnarray}

% _\brackets{d}

\begin{table}[htbp]
 \setlength{\tabcolsep}{0.2em}
\centering
\begin{tabular}{l|cccc||cccc}
 & F & F & F & F & L & L & L & L\\
 & g & G & gt & Gt & g & G & gt & Gt\\
\hline
IPC7 & \bi{223} & 220 & 224 & 224 & 210 & \bi{214} & \bi{224} & 219\\
\hline
brmn & 15 & 16 & 16 & 16 & 15 & 14 & \bi{16} & 14\\
lvtr & 14 & \bi{17} & 16 & 17 & 18 & 18 & 16 & \bi{18}\\
flrt & 3 & 2 & 4 & 4 & 3 & 3 & 4 & 4\\
nmys & 11 & 10 & 12 & 12 & 6 & \bi{9} & \bi{12} & 8\\
pnst & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
prcp & \bi{20} & 18 & 16 & 17 & 14 & 14 & 16 & \bi{18}\\
prkn & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
pgsl & 20 & 19 & 20 & 20 & 20 & 20 & 20 & 20\\
scnl & 17 & 17 & 17 & 17 & 17 & 17 & 17 & 17\\
skbn & 16 & 15 & 16 & 16 & 15 & 15 & 16 & 17\\
tdyb & 16 & 15 & \bi{17} & 15 & 13 & 14 & \bi{17} & 13\\
trns & 11 & 11 & 10 & 10 & 10 & 10 & 10 & 10\\
vstl & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
wdwr & 20 & 20 & 20 & 20 & 19 & 20 & 20 & 20\\
\hline
IPC8 & 111 & \bi{125} & 112 & \bi{117} & 111 & \bi{121} & 114 & \bi{120}\\
\hline
brmn & 8 & \bi{10} & 9 & 8 & \bi{9} & 6 & 9 & 8\\
cvdv & 7 & 7 & 6 & 7 & 6 & 7 & 6 & 6\\
chld & 0 & \bi{10} & 2 & \bi{6} & 3 & 3 & 2 & 3\\
ctyc & 1 & 0 & 5 & 4 & 2 & \bi{4} & 5 & 5\\
flrt & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2\\
gd-s & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
hkng & 15 & \bi{17} & 15 & 15 & 14 & 15 & 15 & 16\\
mntn & 1 & 1 & 6 & 6 & 1 & 1 & 6 & 7\\
pnst & 17 & 17 & 15 & \bi{17} & 16 & \bi{18} & 16 & 15\\
prkn & 9 & 9 & 6 & 6 & 9 & 10 & 7 & 8\\
ttrs & 2 & 2 & 2 & 1 & 2 & \bi{4} & 2 & 2\\
thgh & 14 & 15 & 14 & 15 & 13 & \bi{15} & 14 & \bi{17}\\
trns & 2 & 2 & 1 & \bi{3} & 2 & 3 & 1 & 1\\
vstl & 13 & 13 & \bi{9} & 7 & 12 & 13 & 9 & 10\\
\hline
\end{tabular}
\caption{Lama results.}
\end{table}



\section{Related Work}

\cite{schulte2014balancing}

\cite{auer2002finite}
