\include{1-intro}

\section{Preliminaries and Definitions}

We first define some notation and the terminology used throughout the
rest of the paper.
$h(s)$ denotes the heuristic estimate from the current state $s$ to some
goal state.
$g(s)$ is the current shortest path cost from the initial state to the
current state.
$f(s)=g(s)+h(s)$ is the estimate of the resulting cost of the path
containing the current state.
We omit the argument $(s)$ unless necessary.

A \emph{sorting strategy} of a best first search algorithm is a strategy
which tries to select a single node from the OPEN list.
Each sorting strategy is denoted as a vector of several sorting
criteria, such as
[$\text{criterion}_1$, $\text{criterion}_2$, $\ldots$,
$\text{criterion}_k$], which means: From the OPEN list, first, select a
set of nodes using $\text{criterion}_1$.  If there are still multiple
nodes remaining in the set, then break ties using $\text{criterion}_2$
and so on, until a single node is selected.  The \emph{first-level
sorting policy} of a strategy is $\text{criterion}_1$, the
\emph{second-level sorting policy} is $\text{criterion}_2$, and so on.
%% the word frontier is no longer used in the later text.
% \emph{final frontier} is the set of open nodes with $f^*$.
Note that this corresponds to the command line option format of Fast
Downward \cite{Helmert2006}.

Using this notation, \astar without any tiebreaking strategy can be
denoted as a Best-First Search (BFS) with $[f]$, and \astar which breaks ties according to $h$
value is denoted as $[f,h]$. Similarly, GBFS is denoted as 
$[h]$.  Unless stated otherwise, we assume the nodes are sorted in the
increasing order of the key value, and a BFS always selects the smallest
key value.



The sorting strategy may fail to select a single node because some nodes
may share the same sorting keys. In such cases, a
search algorithm must decide which node to expand by a
\emph{last-resort} tiebreaking strategy, which is one of FIFO
(First-In-First-Out), LIFO (Last-In-First-Out) or RO (random
ordering).  Trivially, these strategies are able to select a single node
from the set of nodes.  Throughout the paper, we show the last-resort
tiebreaking in the subscript such as $[f,h]_{\fifo}$.


A \emph{plateau} is a set of nodes in OPEN, the element of which are
indistinguishable according to the sorting strategy. In case of \astar
using tiebreaking with $h$ ($[f,h]$), this is the set of nodes with the
same $f$ cost and the same $h$ cost.
A plateau whose nodes have $f=f_p$ and $h=h_p$ is denoted as $\plateau{f_p,h_p}$.

An \emph{entrance} to a $\plateau{f_p,h_p}$ is a node $n \in \plateau{f_p,h_p}$, whose current parent is not a member of $\plateau{f_p,h_p}$.
The \emph{final plateau},  is the plateau containing the solution found by the search algorithm.
In \astar using admissible heuristics, the final plateau is
$\plateau{f^*}$ (without tiebreaking), or $\plateau{f^*,0}$ (with $h$-based tiebreaking).




\section{Background: Tiebreaking Strategies for \astar}

\label{sec:astar-background}

In each iteration, \astar selects and expands a node $n$ from the OPEN
priority queue.  $n$ is the node which has the lowest $f$-cost in OPEN.
\astar returns an optimal solution when $h$ is admissible, i.e., when
$h(n) \leq h^*(n)$, where $h^*(n)$ is the optimal distance from $n$ to
the nearest goal.

In order to guarantee solution optimality, \astar expands the search
nodes with a best-first order of $f$, until it finds a solution which
have $f=f^*$, the cost of the optimal solution.
Due to the best-first order, any nodes with $f(n) = k$ are expanded after all nodes with $f(n) < k$ are expanded.
Thus, the \emph{effective search space of \astar} is the set of nodes with 
$f(n) \leq f^*$: \astar expands all nodes with $f(n) < f^*$, then
expands \emph{some} of the nodes with $f(n) = f^*$, and
\astar never expands a node with $f(n) > f^*$.

If multiple nodes with the same $f$-cost are possible, \astar
must implement some tiebreaking policy (either
explicitly or implicitly) which selects from among these nodes.
The early literature on heuristic search seems to have been mostly agnostic regarding tiebreaking.
The original \astar paper, as well as Nilsson's subsequent textbook 
states: ``Select the open node $n$ whose value $f$
is smallest. Resolve ties arbitrarily, but always in favor of any [goal
node]'' \cite[p.102 Step 2]{hart1968formal}, \cite[p.69]{Nilsson71}.
% Although it is possible to interpret this to imply $h$-based tiebreaking
% since goal nodes are the special case where $h=0$,
% they make no further mention of tiebreaking.
Pearl's textbook on heuristic search specifies that best-first search should ``break ties arbitrarily'' (\citeyear{pearl1984heuristics}, p.48, Step 3), and does not specifically mention tiebreaking for \astar.
To the best of our knowledge, the first explicit mention of a tiebreaking policy that considers node generation order is by Korf in his analysis of IDA*: ``If \astar employs the tiebreaking rule of 'most-recently generated', it must also expand the same nodes [as IDA*]'', i.e., a \lifo ordering.

In recent years, tiebreaking according to $h$-values has become ``folklore'' in the search community.
\citeauthor{hansen2007anytime} state that ``[i]t is well-known 
that \astar achieves best performance when it breaks ties
in favor of nodes with least h-cost'' \cite{hansen2007anytime}.
\citeauthor{holte2010common} writes ``\astar breaks ties in favor
of larger $g$-values, as is most often done'' \cite[note that since $f=g+h$,
preferring large $g$ is equivalent to preferring smaller $h$]{holte2010common}.
\citeauthor{felner2011inconsistent} also assume ``ties are broken in
favor of low h-values'' in describing Bidirectional Pathmax for \astar \citeyear{felner2011inconsistent}.
In their detailed survey/tutorial on efficient \astar implementations,
\citeauthor{burns2012implementing} \citeyear{burns2012implementing}
also break ties ``preferring high $g$'' (equivalent to low $h$).
%% this could be moved to later analysis
% They further write: ``The reasoning is that the goal can be found more
% quickly in the final $f$ layer of search''.
Thus, tiebreaking according to $h$-values appears
to be ubiquitous in practice while,
to our knowledge, an in-depth experimental analysis of tiebreaking strategies for \astar is lacking in the literature.

Although the standard practice of tiebreaking according to $h$ might be
sufficient in some domains, further levels of tiebreaking (explicit or
implicit) are required if multiple nodes have the same $f$ as well as
the same $h$ values. To date, the effect of such \emph{last-resort} tiebreaking was not investigated
in depth.
For example, the survey of efficient \astar implementation techniques in
\cite{burns2012implementing} did not explicitly mention the last-resort 
tiebreaking, while their library code\footnote{https://github.com/eaburns/search}
uses \lifo last-resort tiebreaking.
It first breaks ties according to $h$, and then
breaks remaining ties according to a \lifo policy (most recently
generated nodes first), i.e., $[f,h]_\lifo$.
Although not documented, their choice of a \lifo 2nd-level tiebreaking policy appears to be a natural consequence of the fact it can be trivially, efficiently implemented in their two-level bucket (vector) implementation of OPEN.
In contrast, the current implementation of the \sota \astar based planner Fast
Downward \cite{Helmert2006}, as well as the work by \cite{RogerH10} uses a $[f,h]_\fifo$ tiebreaking strategy.
Although we could not find an explanation in the publication nor in the website, this choice is most likely due to their use of alternating OPEN lists, in which case the \fifo second-level policy serves to provide a limited form of fairness.
Such lack of explanation suggests that this topic has been out
of focus of the heuristic search literature.

\section{Evaluation of Standard Strategies}
\label{sec:eval-common-strategies}
We evaluated tiebreaking strategies for domain-independent optimal classical planning.
In our experiments, the planners are based on Fast Downward (revision 6251), and all
experiments are run with a 5-minute, 2GB memory limit for the search binary (FD translation/preprocessing times are not included in the 5-minute limit).
All experiments were conducted on Xeon E5410@2.33GHz CPUs.
We used 1104 instances from 35 standard benchmark domains.
%and 620 problems from 28 \emph{zero-cost-action} domains (\refsec{sec:zerocost-domains}).

\begin{figure}[htbp]
   \centering
  \includegraphics{tables/aaai16-frontier/aaai16prelim3/lmcut_frontier-front.pdf}
  \caption{
  Similar to \refig{fig:plateau-noh}; $y$-axis shows
  the number nodes with $f=f^*, h=0$, which forms the final
  plateau when $h$-based tiebreaking is enabled.
  Note that many \pddl{Openstacks} and \pddl{Cybersec} instances are near the $y=x$ line.
  }
  \label{fig:plateau}
\end{figure}

We first compared two commonly used tiebreaking strategies, $[h,\fifo]$, $[h,\lifo]$, which
first break ties according to $h$, and then apply \fifo or \lifo
second-level tiebreaking, respectively.
% The following will be necessary in a future version, if we use LOP:
%Although the search behavior of $[f,h,\fifo]$ corresponds to the default behavior of Fast Downward, this implementation differs 
%from the original, unmodified code because we enabled caching of $h$-values, so that reopened nodes refer to cached $h$-values.\footnote{The current Fast Downward code disables $h$-caching because its current implementation is not compatible with multiple admissible heuristics.}
%Thus, we also show results for unmodified Fast Downward -- as expected, $[f,h,\fifo]$ dominates unmodified FD.
Detailed results for LMcut heuristic \cite{Helmert2009} and M\&S heuristic \cite{HelmertHHN14} are
shown in \reftbl{tbl:depth} (leftmost 2 columns).
Differences in coverage are observed in several domains, and
$[h,\lifo]$ outperforms $[h,\fifo]$ in total.
\refig{fig:f-h-eval} gives us a
more fine-grained analysis by comparing the number of node evaluation
(computations of \lmcut) of the $[h,\lifo]$ and $[h,\fifo]$ strategies.
It shows that the difference in the number of nodes
evaluated can sometimes be larger than a factor of 10 (\pddl{Openstacks}, \pddl{Cybersec} domains).

\begin{figure}[tb]
 \centering \relsize{-3}
 \includegraphics{tables/aaai16-30min-5min-cut/aaai16prelim3/evaluated-lmcut_ff-lmcut_lf.pdf}
 \caption{The number of evaluations of standard \fifo vs
 \lifo second-level tiebreaking, with first-level $h$
 tiebreaking. \lifo evaluates  less than $1/10$ of the nodes evaluated
 by \fifo in \pddl{Cybersec} and \pddl{Openstacks}. 
 }
 \label{fig:f-h-eval}
\end{figure}

\begin{table*}[htb]
 {
 \centering
 \input{tables/aaai16-robustnesscheck/aaai16prelim3/1-nofd.tex}
 \caption{
 Full version of the upper half of \reftbl{depth} showing 
 the experiments on the IPC benchmark instances using \lmcut heuritics.
 Each cell shows the coverage of the domain solved with 5 min, 2GB.
 As in the original \reftbl{depth}, we highlighted the best results in
 \textbf{boldface} only when the maximum pairwise coverage difference $\mit{MaxDiff}>2$.
 }
 \label{lmcut-ipc-full}
 }
\end{table*}



\begin{table*}[htb]
 {
 \centering
 \input{tables/aaai16-robustnesscheck-mands/zerocost/1-nofd.tex}
 \caption{
 Full version of the bottom line of \reftbl{depth} showing 
 the experiments on the IPC benchmark instances using \mands heuritics.
 Each cell shows the coverage of the domain solved with 5 min, 2GB.
 As in the original \reftbl{depth}, we highlighted the best results in
 \textbf{boldface} only when the maximum pairwise coverage difference $\mit{MaxDiff}>2$.
 }
 \label{mands-zerocost-full}
 }
\end{table*}


\begin{table*}[htbp]
 \centering
 \relsize{-1} \setlength{\tabcolsep}{0.3em}
 \input{tables/aaai16-robustnesscheck/aaai16prelim3_zerocost/1-nofd.tex}
 \caption{Coverage comparison (the number of instances solved in 5min, 2GB), \textbf{bold}=best. Zerocost domains are named as [original name]-[name of nonzero action]. Due to space, we only show the domains whose maximum pairwise coverage difference $\mit{MaxDiff}>2$. (We used the means of 10 runs for the randomized strategies.) Domains with $\mit{MaxDiff}\leq 2$ follows:
 (1) $\mit{MaxDiff} = 0$ (same coverages by all configuration and all runs): \pddls{barman-opt11, floortile-opt11, grid, gripper, hanoi, parking-opt11, pegsol-opt11, psr-small, rovers, sokoban-opt11, tpp, transport-opt11, grid-fuel, gripper-move, parking-movecc, psr-small-open, zenotravel-fuel}.
 (2) $0 < \mit{MaxDiff} \leq 1$: \pddls{depot, driverlog, elevators-opt11, freecell, mystery, parcprinter-opt11, pathways, pipesworld-tankage, storage, tidybot-opt11, visitall-opt11, driverlog-fuel, floortile-ink, hiking-fuel, logistic00-fuel, nomystery-fuel, pathways-fuel, sokoban-pushgoal}.
 (3) $1 < \mit{MaxDiff} \leq 2$: \pddls{blocks, nomystery-opt11, pipesworld-notankage, zenotravel, depot-fuel, rovers-fuel, storage-lift, tidybot-motion}.
 }\label{tbl:depth}
\end{table*}

\subsubsection{Is $h$-Based Tiebreaking Necessary?}
\label{sec:h-necessary}
%Next, we investigated whether $h$-based, first-level tiebreaking is necessary.
\reftbl{tbl:depth} also shows the results of $[\fifo]$ and $[\lifo]$,
which rely only on \fifo or \lifo tiebreaking.
$[\lifo]$, which simply breaks ties among nodes with the same $f$-cost by expanding most recently generated nodes first \cite{korf1985depth}, clearly dominates $[\fifo]$.

Interestingly, the performance of the $[\lifo]$ strategy
is comparable to $[h,\lifo]$ and $[h,\fifo]$, the standard two-level strategies that first break ties according to $h$.
This may be surprising, considering the ubiquity of $h$-based tiebreaking in the search and planning communities.
% 
However, \lifo behaves somewhat similarly to $h$-based tiebreaking, in the following sense:
\lifo expands the most recently generated node $n$.
For any child $n'$, 
if the heuristic function is admissible and $f(n') = f(n)$, there are only 2 possibilities :
(1) $g(n') > g(n)$ and $h(n') < h(n)$, or
(2) $g(n') = g(n)$ and $h(n') = h(n)$,
because $g(n)+h(n)=g(n')+h(n')$.
Thus, as \lifo expands nodes in a ``depth-first'' manner,
the nodes that continue to be expanded by \lifo's depth-first
exploration have non-increasing $h$-values, much like in $h$-based tiebreaking.
Although in general, the expansion order of $[\lifo]$ is not the same 
as that of $h$-based tiebreaking strategies,
this might explain why their performances are comparable.
\textbf{An in-depth investigation of the behavior of $[\lifo]$ vs. $h$-based tiebreaking is a direction for future work.}

% Compared to the $h$-based variants which explicitly selects nodes with smaller $h$ and its expanded nodes have non-increasing $h$-values,
% This has the same  can behave somewhat similarly to actively expanding nodes with low $h$-values, as done by $h$-based tiebreaking.

% \citeauthor{burns2012implementing}
% (\citeyear{burns2012implementing}) writes ``the goal can be found more
% quickly in the final $f$ layer of search'' about $h$ tiebreaking.

\subsubsection{Plateaus and Tiebreaking}

In \refig{fig:f-h-eval},
we observed that large performance differences between
2-level tiebreaking strategies $[h,\lifo]$ and $[h,\fifo]$ tend
to occur in problems where there are many nodes with the same $f$ and
$h$ values, creating large plateau regions where the heuristic does not
provide any useful guidance -- by definition, these plateau regions 
require a blind search (because all nodes
have the same $f,h$) which relies solely on the tiebreaking criterion.

\refig{fig:plateau} plots the size of the final plateau on 1104 IPC
benchmark instances.
The $y$-axis
represents the number of nodes with $f=f^*, h=0$, i.e., the final plateau, and the $x$-axis represents the total
number of nodes with $f\leq f^*$.
In some domains such as \pddl{Openstacks} and \pddl{Cybersec}, the planner spends most of the runtime
searching the final plateau even with $h$ tiebreaking, and
thus the runtime on these domains varies significantly depending on the second-level tiebreaking strategy.

\section{Domains with Zero-Cost Actions}
\label{sec:zerocost-domains}
%% best to put openstacks here, considering the connection to the
%% previous section
\pddl{Openstacks}  is a cost
minimization domain introduced in IPC-2006, where the objective is to 
minimize the number of stacks used.
There are many zero-cost actions (i.e., actions that don't increase the number of stacks), and
they prevent the standard heuristics from producing
informative guidance.

%% safe to remove these explanation.
% According to \cite{richter2010lama}, \textbf{??????}
% %Richter talks about the failures on openstacks starting around p.167
% \lmcut \cite{Helmert2009} fails to find a good cost
% partitioning with non-zero values, 
% % A detailed discussion of Openstacks domain and poor performance of landmarks is in \cite{richter10lama}, p.167-169.
% and most edges in the abstraction
% space of M\&S \cite{helmert2007flexible} have zero costs.


% XXX I'm commenting out the paragraphs below because:
% (1) A review of heuristic functions for domain-independent learning is not really
% necessary for this AAAI submission. 
% (2) It's better if this paper is not so strongly associated with the ICAPS community only -- this work applies in general to search with A*, and is not strongly tied to almost-perfect heuristics, lmcut, m&s, etc.

Although domains with zero-cost actions are not common in the current set of benchmarks, we argue that such domains are of an important class of models for cost-minimization problems, i.e.,
assigning zero costs make sense from a practical, modeling perspective.
For example, consider the \pddl{driverlog} domain, where the task is to move packages between locations using trucks.
The IPC version of this domain assigns unit costs to all actions. Thus, cost-optimal planning on this domain seeks to minimize the number of steps in the plan.
However, another natural objective function would be the one which minimizes the amount of fuel spent by driving the trucks,
assigning cost 0 to all actions except \pddl{drive-truck}.

% While I agree with the point you're trying to make,
% There is an ugly issue when arguing that current models try to  optimize plan-execution time (i.e., makespan), 
% which is that if we really cared about makespan optimality, we would consider parallel execution of actions whenever possible.
% however, sequential classical planners do not handle parallel actions at all  (recall ACP).
% so arguing this path can only lead to trouble.. Let's try a safer line of argument.
%% For runtime minimization,
%% nonzero positive costs are reasonable because
%% every actions are supposed to consume a fraction of time.
%% However, such formulation is not suitable for general optimization
%% problems.  For example, when you try to minimize the energy consumption
%% by the elevators in \pddl{Elevators} domain, many actions would have zero-cost
%% --- it does not consume electricity for either boarding or leaving the
%% passenger, or moving the elevator down.
%% % 
%% From the practical point of
%% view, cost minimization domains would have wider interest compared to
%% the simple runtime minimization.
%% Also, as shown previously, such domains pose a
%% difficulty to the current heuristic planners due to their large plateaus.

Similarly, for many practical applications, a natural 
objective is to optimize the usage of one key consumable resource, e.g., fuel/energy minimization.
In fact, two of the IPC domains, \pddl{Openstacks} and \pddl{Cybersec}, which were shown difficult for standard tiebreaking methods in the previous section, both contain many zero-cost actions, and both are based on industrial applications:  \pddl{Openstacks} models production planning \cite{fink1999applications} and \pddl{Cybersec} models Behavioral Adversary Modeling System \cite[minimizing decryption, data transfer, etc.]{boddy2005course}.

Therefore, in this paper, we modified various domains
into cost minimization domains with many zero-cost actions.
Specifically, a domain is modified so that all action schemas are assigned
cost 0 except for a few (usually one) action schema which consumes some key resource.
The last word in the names of these domains indicate the action which is
assigned non-zero cost, e.g., \pddl{elevator-up} is a modified elevator
domain where the \pddl{up} action is assigned non-zero cost (because
elevators are considered to consume energy only when going \pddl{up}), and all other actions have cost 0.
Most of the transportation-type domains are modified to optimize 
energy usage (\pddl{Logistics-fuel}, \pddl{elevator-up} etc.), and  assembly-type domains are modified to minimize resource usage
%% floortile-ink is not shown, so better not to mention it
(\pddl{Woodworking-cut} minimizes wood usage, etc.).
We did not
include domains with only a single action schema and standard domains which already had many
zero-cost actions (these are already in the results for standard IPC domains).
We refer to these 28 new domains as \emph{zerocost domains}.

\refig{fig:plateau-zerocost} plots the size of the final plateau of the
zerocost domain instances, with $h$-tiebreaking enabled.
As expected, many of these zerocost domains have large plateaus even
with the help of $h$-tiebreaking.
Thus, in these cost-minimization problems, the search strategy within
plateaus, i.e., tiebreaking,  becomes yet more important.

\begin{figure}[htbp]
  \centering
  \includegraphics{tables/aaai16-frontier/zerocost/lmcut_frontier-front.pdf}
  \caption{Similar to \refig{fig:plateau}, but for 620 instances from our 
  \emph{zerocost domains} (\refsec{sec:zerocost-domains}),
  where zero-cost actions induce very large plateaus.
 }
 \label{fig:plateau-zerocost}
\end{figure}


\section{Depth-Based Tiebreaking for A*}

\label{sec:depth}

In order to solve zerocost problems, the planner needs to perform an
efficient knowledge-free search within a large, final plateau.
One useful notion which can be used to both understand and control the
search in this situation is the \emph{depth} of a node, which represents
the number of steps (edges in the search space graph) from the entrance
of the plateau.

\textbf{XXX From SoCS draft}
For such situations, they proposed a notion of \emph{depth} within the
plateau, and an idea of diversifying the search over different depths
within a plateau. A depth is an integer value which suggests the
distance from the \emph{entrance} of the plateau (the first state which
entered the plateau, along the path from the initial state). The depth
$d(s)$ of a state $s$ is 0 when $s$ and the parent state $t$ has the
different $(f,h)$ pair (i.e. $f(s) \not = f(t) \lor h(s) \not = h(t)$),
and $d(s)=d(t)+1$ when they are same (i.e. $f(s) = f(t) \land h(s) =
h(t)$) and the parent and the child are in the
same plateau.
\textbf{XXX From SoCS draft}


Given a node $n$,
if its current parent $\parent{n}$ is from the other plateau, i.e.,
$\parent{n}$ has a different $f$-value, or different $h$-value when the
first tiebreaking is present, then $\depth{n} = 0$. Nodes with
$\depth{n} = 0$ correspond to the \emph{entrance} of the plateau.  If $n$
and $\parent{n}$ are in the same plateau i.e.\ share the same $f$ and $h$,
$\depth{n}$ is defined as $\depth{\parent{n}} + 1$.  Based on this
simple notion of depth, we propose three \emph{depth-based
tiebreaking} strategies, where the nodes are inserted into buckets associated with
depths, and upon expansion, the buckets are chosen according to some policy.
``First depth'' (\fd), ``last depth'' (\ld), and ``random depth'' (\rd) 
choose a bucket with the smallest depth,
the largest depth, and a depth randomly selected at each expansion, respectively.

\todo{remove this part if complete plot in \refig{fig:depth-histogram} did
not succeed}
The effectiveness of each of these depth-based policies depends on the
problem instance.  Within
the plateau region, all nodes have the same $f$ and $h$ values, 
% yes, for simplicity, I'm assuming 3-level tiebreaks, ignoring no-h for the time being..
and the goals can be near or far
from the entrance.  In the former case, the
search should be focused around the entrance favoring the smaller depths
(\fd), and the behavior in the plateau should be much like breadth-first. In the
latter case, the planner should greedily explore the various area of the
plateau by preferring largest depth (\ld), much like in
depth-first. 
It may also be possible for a goal to be at an intermediate depth, in which case
\fd could take too much time to reach that
depth, and \ld may greedily pass and miss that depth.
By an adversary argument, \rd, which selects a random depth and has no depth bias would seem to be the safest policy.

Depth-based tiebreaking has no effect when used as a second-level tirebreaking policy with a domain with positive costs only \emph{and} $h$-based first-level tiebreaking policy. This is because most actions result in an updated $h$-value, so almost all nodes have depth 0.
% (with consistent heuristics, \emph{all} actions update $h$ and no nodes have depth $\geq 1$)

\subsubsection{Tiebreaking within Depth Buckets}
% changing from ``third-level'' because we'll also consider that sue depth as the 1st-level policy, e.g., [rd,random] (noh).
Since there can be multiple nodes within the same depth bucket,
a further tiebreaking criterion may be necessary to break ties among them.
We could, for example, apply \lifo or \fifo policies at this level -- 
note that $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$ are equivalent to $[h,\fifo]$ and $[h,\lifo]$, respectively.

However we use a Random Order (\ro) policy, which 
randomly selects an element from the depth bucket selected by the depth-based tiebreaking.
This is because the effectiveness of the tiebreaking behavior within a bucket
can be affected by accidental biases, e.g., names/orders of action schema in the PDDL domain
definition \cite{vallati2015effective}.
%Finding the best action ordering is not the scope of this paper.
Thus, we avoid bias at this level of tiebreaking by using \ro and assess its expected/average
performance.



% Among \fifo, \lifo and \ro, the natural policy is Random Order.
% This is because the effectiveness of the third-level tiebreaking behavior
% is affected by the accidental bias in action ordering in the PDDL domain
% definition.  Recent work \cite{vallati2015effective} showed that the
% planner performance is greatly affected by changing and tuning the action ordering
% (and also variable ordering, but it is irrelevant to the tiebreaking behavior). 
% However, finding the best third-level tiebreaking is not the scope of this paper.
% Thus, focusing on \ro and assess its expected/average
% performance is the most reasonable practice to understand the behavior of second-level,
% depth-based tiebreaking.


\subsection{Evaluating Depth-Based Tiebreaking}
\label{sec:depth-based-evaluation}
We evaluated three 3-level tiebreaking strategies.
%% may not be necessary, since they are straw-mans
% and four 2-level tiebreaking strategies in all.
%REDUNDANT? , i.e., $[f,h,depthStrategy,LFR]$, where the first-level tiebreaking is according to $h$ (break ties in favor of small $h$), the second-level strategy is based on depth and $depthStrategy \in \{\fd, \ld, \rd\}$, and the third level tiebreaking strategy $LFR \in \{\lifo, \fifo, \ro\}$.
% 
In addition to the 35 IPC benchmark domains with 1104 instances used in
the previous set of experiments, we used 28 zerocost domains with 620
instances. For randomized strategies, we
show the coverage (mean $\pm$ sd) on
10 independent runs.

\begin{table*}[htb]
 {
 \centering
 \input{tables/aaai16-robustnesscheck-mands/aaai16prelim3/1-nofd.tex}
 \caption{
 Full version of the bottom line of \reftbl{depth} showing 
 the experiments on the IPC benchmark instances using \mands heuritics.
 Each cell shows the coverage of the domain solved with 5 min, 2GB.
 As in the original \reftbl{depth}, we highlighted the best results in
 \textbf{boldface} only when the maximum pairwise coverage difference $\mit{MaxDiff}>2$.
 }
 \label{mands-ipc-full}
 }
\end{table*}


\begin{table*}[htb]
 {
 \centering
 \input{tables/aaai16-robustnesscheck/zerocost/1-nofd.tex}
 \caption{
 Full version of the lower half of \reftbl{depth} showing 
 the experiments on the Zerocost instances using \lmcut heuritics.
 Each cell shows the coverage of the domain solved with 5 min, 2GB.
 As in the original \reftbl{depth}, we highlighted the best results in
 \textbf{boldface} only when the maximum pairwise coverage difference $\mit{MaxDiff}>2$.
 }
 \label{lmcut-zerocost-full}
 }
\end{table*}


% This comparison below may be useful in a future version of the paper, but not necessary in this version.
%% First, we compared $[h,\ld,\lifo]$ and $[h,\fd,\fifo]$
%% with $[h,\lifo]$ and $[h,\fifo]$, respectively, in order to see
%% the extra cost of managing the depth-based buckets.
%% The node evaluation order of $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$
%% are exactly the same as $[h,\fifo]$ and $[h,\lifo]$.
%% This is because:
%% (1) $[h,\lifo]$ expands the most recently evaluated/inserted
%% states, and (2) the depth increases monotonically within the same $[f,h]$,
%% thus (3) $[h,\lifo]$ always expands the largest depth. (Similar logic
%% applies to $[h,\fifo]$.)
%% % 
%% % yet these results are useful in assessing the extra cost of managing the
%% % depth-based buckets.
%% As expected, the performances of $[h,\ld,\lifo]$ and
%% $[h,\fd,\fifo]$ are slightly worse than $[h,\lifo]$ and
%% $[h,\fifo]$, respectively, due to the cost of managing the depth-based buckets.

We compared 
$[h,\fd,\ro]$, $[h,\ld,\ro]$, and $[h,\rd,\ro]$. These all use 
$h$ as the first-level tiebreaking criterion, one of \fd, \ld, \rd as
the depth-based 2nd-level tiebreaking criterion, and finally,
\ro as the 3rd-level criterion.
Since these configurations are randomized, we run each configuration with 10 different random seeds.
To see whether differences among the mean coverages were statistically significant,
% of $[h,\ld,\ro]$, $[h,\rd,\ro]$,
we applied the non-parametric Wilcoxon's signed-rank test.
% ``non-parametric'' means ``normal distribution not assumed
%Wilcoxon test,
%a non-parametric significance testing method applicable to
%the populations in which normal distribution cannot be assumed.

\reftbl{tbl:depth} shows the coverage (mean $\pm$ sd),
along with the rightmost columns showing the 
Wilcoxon test $p$ values  for  $[h,\rd,\ro]$ vs. 3 other strategies.
%The results depend on the domains, but in many domains, 
In many domains,
the performance was significantly affected by 2nd-level tiebreaking, and
$[h,\rd,\ro]$ dominated the others. 
Although $[h, \ld, \ro]$ and $[h,\rd,\ro]$ performed similarly on most domains, 
the performance of $[h,\rd,\ro]$ in some
domains are notable (e.g., \pddl{Cybersec}, \pddl{Woodworking-cut}). 
The standard deviation of $[h,\rd,\ro]$ coverage tends to be smaller
than that of $[h,\ld,\ro]$, indicating that $[h,\rd,\ro]$ is robust with respect to random seeds.
$[h,\fd,\ro]$ is mostly dominated by $[h,\rd,\ro]$ and $[h,\ld,\ro]$,
except in \pddl{Scanalyzer-analyze}.
% 2015/9/13 -- let's try not including the following analysis in this submission -- due to space, and also too complicated, without sufficient payoff.
% We no longer need the ``depth as explanation of LIFO/FIFO'' story, because  the ``random is good'' depth-based methods [h,rd,ro]  story is simpler.

%% \todo{move this to the final section after reviewing the action ordering}
%% % removed \fifo
%% Finally, we answer two following concerns regarding \lifo final-level
%% tiebreaking criteria which appear in $[h,\lifo]$ and
%% $[h,\ld,\lifo]$. The evaluation in the earlier sections contains
%% two open questions: (1) Do the action orderings affect the performance of \lifo? 
%% (2) Doesn't \lifo benefit from its efficient low-level memory access pattern (high
%% probability of hitting the cache), not by the search efficiency?
%% They are both rejected because the
%% coverage of $[h,\ld,\lifo]=[h,\lifo]$ is not significantly
%% different from $[h,\ld,\ro]$, i.e.,
%% $859,857 \in [863.5-8.9,863.5+8.9]$,
%% despite the difference in the third-level tiebreaking (\lifo vs \ro).
%% % 
%% It means that the
%% performance of $[h,\lifo]$($=[h,\ld,\lifo]$) was not caused by the final-level
%% \lifo, but instead by the implicit second-level tiebreaking LastDepth.
%% %% remove
%% % Besides, this problem is not important now that RandomDepth
%% % is outperforming LastDepth-based tiebreaking strategy.
%% % 
%% With the similar logic, we can claim that the bad performance of
%% $[h,\fd,\fifo]$ and $[h,\fifo]$ can be attributed to its the
%% inherent second-level FirstDepth, and not to the third-level \fifo.
%% %% Unfortunately, 829,828 is not \in 816.7 +- 2.2.
%% %% this can be changed if we rerun _random with O(1) random deletion.

\subsubsection{Depth-Based Tiebreaking Without Considering $h$}

In \refsec{sec:h-necessary}, we showed that $[\lifo]$ tiebreaking (without considering $h$) is
sufficient for the standard IPC benchmarks -- the performance of $[\lifo]$, $[h,\lifo]$, and $[h,\fifo]$ are comparable.
\reftbl{tbl:depth} shows that $[\rd,\ro]$, which randomly selects an element from a randomly selected depth-bucket, dominates $[h,\fifo]$,
and performs comparably to $[h,\lifo]$.
Although $[\rd,\ro]$ behaves in a less greedy/depth-first manner than $[\lifo]$, 
it explores nodes with high depth sufficiently often so that even if \lifo behavior (seeking nodes that are far from the plateau entrance) is required, $[\rd,\ro]$ will eventually find the solution.
Moreover, there are some domains (\pddl{pipesworld-pushend} and \pddl{woodworking-opt11}) where a the more randomized behavior of $[\rd,\ro]$ is advantageous.
Thus, overall, $[\rd,\ro]$ performs moderately well, and 
\emph{neither $h$ nor \lifo-behavior is necessary in order to obtain performance that is competitive with the standard
tiebreaking strategies}.



%% moved to Table 2

\subsubsection{Is Depth-Based Tiebreaking Necessary?}
% is this the right location -- maybe this should in a discussion section?

We have shown that $[h,\rd,\ro]$ performs well overall, but
one might wonder whether the power of this strategy really comes from depth-based tiebreaking, or from randomness.
\reftbl{tbl:depth} shows that $[h,\ro]$ performs poorly, so clearly, random tiebreaking combined with $h$-based tiebreaking is not sufficient.
The reason that $[h,\ro]$ performs so poorly is that if we select uniformly from the bucket of all open nodes in the plateau, there is a very strong bias for selecting a node with low depth, simply because at any given point during the search in the plateau region, more nodes closer to the plateau entrance (i.e., lower depth) will have been generated.
By randomly selecting a depth bucket, $[h,\rd,\ro]$ explicitly eliminates this bias for selecting nodes for low depth.

% COMMENTED OUT: random-h is too weak, because if we have an admissible heuristic, the adversary can't fool h.
% One might also wonder whether the power of $[h,\rd,\ro]$ comes from having multiple levels of randomness, and not from the notion of depth.
% This is not the case -- multiple levels of randomness would not suffice to capture the power of $[h,\rd,\ro]$ due to the following reason:
% Consider another possible randomized strategy, $[random-h,\ro]$, which first picks a random $h$-bucket, 
% and then picks a random element from that bucket.
% When the final plateau of [f,h] is small, tiebreaking strategies do not significantly affect performance.
% However, when the final plateau of [f,h] is large, then $[random-h,\ro]$ will behave similarly to $[h,\ro]$, because almost all nodes in the search space have the same h-value, and we have shown that $[h,\ro]$ performs poorly on domains with large plateaus, i.e., domains with zero-cost-actions., compared to $[h,\rd,\ro]$.
% Thus, multiple levels of randomness alone do not account for the success of $[h,\rd,\ro]$, and the notion of depth buckets seems necessary.


\subsubsection{Search Behavior Within a Plateau}

To understand the behavior of depth-based policies, we plotted the histogram of
the depths of search nodes opened by
the most successful depth-based strategy, $[h,\rd,\ro]$, as well as 
the standard $[h,\fifo]$, $[h,\lifo]$ strategies
in the final plateau, plateau($f^*,0$) until the solution is found.
% 
Although $[h,\fifo]$ and $[h,\lifo]$ do not operate with an explicit notion of ``depth'', 
they are equivalent to $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$, respectively,
%so we recorded the depths according to these depth-based equivalents of $[h,\fifo]$ and $[h,\lifo]$.
so we recorded and plotted the depths according to  $[h,\fd,\fifo]$ and $[h,\ld,\lifo]$.


\refig{fig:depth-histogram} shows the result
on
 \pddl{Openstacks-opt11} p10 (left) and
 \pddl{Woodworking-cut} p04 (right).
 % and \pddl{psr-small-open} p48 (right)
In both instances, 
% \pddl{openstacks} and \pddl{Woodworking-cut}, 
we observed that the depth-first behavior of $[h,\lifo]$ results in 
deeper search, missing the key branch at intermediate depths.
On the other hand, the breadth-first behavior of $[h,\fifo]$ often gets stuck spending an excessive amount of time searching around the plateau entrance.
$[h,\rd,\ro]$ is balancing the search at various depths, which results in successfully solving more problems within the time limit (\reftbl{tbl:depth}). %to avoid confusion, avoiding word ``coverage'' here because coverage could refer to search algorithm ``covering'' the search space.

% The figure also illustrates the behavior of RandomDepth: Although it
% randomly selects from the buckets,
% a new depth is found only when the largest-depth bucket is selected,
% resulting in a decreasing curves.
% Finding the optimal balance is an interesting avenue of
% future work.

\begin{figure}[tb]
 \centering \relsize{-3}
 \hfill
 \includegraphics{tables/aaai16-log-rd/aaai16prelim3/depth-histogram-openstacks-opt11-strips-p10.pdf}
 \hfill
 \includegraphics{tables/aaai16-log-rd/2zerocost/depth-histogram-woodworking-cut-p04.pdf}
 \hfill
 % \includegraphics{tables/aaai16-log-rd/2zerocost/depth-histogram-psr-small-open-p48.pdf}
 \caption{Number of nodes ($y$-axis) expanded per depth ($x$-axis) in
 the final plateau for 
 % (in left-to-right order)
 \pddl{Openstacks} p10 
 (left)
 and
 \pddl{Woodworking-cut} p04
 (right)
 %  and
 % \pddl{psr-small-open} p48
 with different tiebreakings.
 % Axes are logarithmic.
 }
 \label{fig:depth-histogram}
\end{figure}

\subsubsection{Comparison With $\varepsilon$-Cost Transformation}

\begin{table}[tb]
 \centering
 \begin{tabular}{|c|c|c||c|c|}
  \hline
  Domain & $[h,\fifo]/\varepsilon$ &  $[h,\lifo]/\varepsilon$ &  $[h,\fd,\ro]$ &  $[h,\rd,\ro]$ \\
  \hline
  \lmcut Zerocost & 261 & 259 & 257.4\spm{}2.0  &  \textbf{294.2\spm{}2.3} \\
  \hline
  \mands Zerocost & 282 & 282 & 274.0\spm{}0.9  &  \textbf{310.2\spm{}2.1} \\
  \hline
 \end{tabular}
 \caption{Comparison of  depth-based tiebreaking methods vs. standard $[h,\fifo]$ and $[h,lifo]$ methods applied to $\varepsilon$-cost-transformed versions of the problem instances}
 \label{tbl:epsilon}
\end{table}

An alternative approach to addressing the large plateaus in zero-cost domains is
to eliminate plateaus by introducing artificial gradients in the search space.
For example, the cost of all zero-cost actions can be replaced by a small $\varepsilon\ll 1$, where 
$\varepsilon$ is chosen such that the optimal cost for the result of  this \emph{$\varepsilon$-cost transformation} (``$\varepsilon$-transformation'') is the same as the cost of the optimal solution to the original domain with zero costs when the $\varepsilon$-transformed costs are mapped back to 0.

We evaluated the $[h,\fifo]/\varepsilon$ and $[h,\lifo]/\varepsilon$ strategies, which are the standard $[h,\fifo]$ and $[h,\lifo]$ tiebreaking strategies applied to  the $\varepsilon$-transformed version of the problems.
Since Fast Downward  only supports integer costs, we implemented/simulated the transformation by multiplying the non-zero costs by $10^6$, and assigning cost 1 to zero-cost actions -- in effect,  $\varepsilon=10^{-6}$.
\reftbl{tbl:epsilon} shows that $[h,\fifo]$ and $[h,\lifo]$ with $\varepsilon$-transformation
 perform comparably to $[h,\fd,\ro]$, but are outperformed by $[h,\rd,\ro]$.
% 
The similarity in performance between $\varepsilon$-transformation and $[h,\fd,\ro]$ can be explained by the fact that  OPEN is sorted according to  $f(n)+k(n)\varepsilon$,
where $k(n)$ is a number of zero-cost actions in the path to node $n$,
while expansion order of FirstDepth is equivalent to $f(n)+\depth{n}\varepsilon$.
($\depth{n}\leq k(n)$ because $k(n)$ accounts zero-cost actions also in non-final plateaus).
% 
One advantage of the $\varepsilon$-transformation is that it can be implemented by transforming the input problem and does not require implementation of depth-based buckets in the search algorithm.
On the other hand, there are two issues with the $\varepsilon$-transformation:
(1) $\varepsilon$ must be chosen carefully -- admissibility is lost  when $k(n)\varepsilon\approx 1$, and
(2) the number of possible $g$ and $f$ values becomes very large, making it difficult to use efficient $O(1)$ array-based implementation of the OPEN list and requiring the use of a heap-based $O(\log n)$ OPEN list.
% it makes array-based $O(1)$ OPEN-list consume too much memory
% because the queue contains too many different key values, 
% or it forces
% In contrast, depth can be directly implemented with just another level of nested arrays.

\subsubsection{Comparison to Multi-Heuristic Tiebreaking with PLUSONE Cost Type}



\section{Related Work}
\label{sec-4}

Previous work on escaping search space plateaus has focused on
non-admissible search.  DBFS \cite{imai2011novel} % is a technique which
adds stochastic backtracking to Greedy Best First Search (GBFS) to avoid
being misdirected by the heuristic function. Type based bucket
\cite{xie14type} classifies the plateau of GBFS according to the
$[g,h]$ pair and distributes the effort.  Marvin \cite{Coles07} learns plateau-escaping macros
from the Enhanced Hill Climbing phase of the FF planner
\cite{Hoffmann01}, and the use of these macros is inadmissible.
\citeauthor{Hoffmann05} gives a detailed analysis of the
structure of the search spaces of satisficing planning (\citeyear{Hoffmann05,Hoffmann11}).
\cite{benton2010g} proposes inadmissible technique for temporal planning
where short actions 
% are hidden behind long actions and
do not increase makespan. 
\cite{cushing2010cost} investigates ``$\varepsilon$-cost
traps''($\varepsilon=\frac{\min cost}{\max cost}$),  showing that (non-admissibly) treating all actions as unit cost sometimes finds an optimal plan quickly.
\cite{wilt2011cost} also analyzes inadmissible distance-to-go estimates.
% 
To our knowledge, 
plateaus have not been previously investigated for cost-optimal planning with admissible search.
Admissible and inadmissible search differ significantly in how non-final plateaus (plateaus with $f < f^*$) are treated:
Inadmissible search can skip or escape plateaus whenever possible, while
admissible search cannot, unless it
is the final plateau ($f=f^*$, $h=0$) and a solution is found. %it directly finds a solution.

%In their work on combining multiple heuristics in a planner, 
% \citeauthor{RogerH10} (\citeyear{RogerH10}) considered a tiebreaking approach which works as follows:
% When combining two heuristics, one of the
% heuristics is used as the primary criterion, % for guiding the search,
% and the second heuristic is used to break ties among nodes with the same primary
% heuristic value.
% While this did not perform well in their work on satisficing planning, 
% additional policy using a secondary heuristic
% for cost-optimal search is an interesting direction for future work.


The PLUSONE %\footnote{This term is used on the Fast Downward website.} XXfootnote takes too much space
cost-type (or distance-to-go) is a non-admissible search technique in the Fast Downward/LAMA planner
\cite{richter2010lama} which increases all action costs by 1.
% By eliminating zero-cost actions, this behaves similar to our $[h,\fd,\ro]$ tiebreaking.
%Using PLUSONE, three successive
%applications of zero-cost operators have cost 3, and two
%applications have cost 2, and smaller cost is preferred, just as
%\astar always expands the node with smaller $f$-value.
This technique explicitly targeted zero-cost actions,
and resulted in significantly better performance in the IPC-6
satisficing track \cite[p.137, Sec. 3.3.2]{richter2010lama}.
%\todo*{citation}
% There's a long discussion of Openstacks in \cite{richter2010lama}, p.167-169, but I can't find PLUSONE anywhere. Maybe it's called something else in the paper?  Maybe \richter2010lama is the wrong citation??
Unlike PLUSONE, depth-based tiebreaking is admissible.
%because unlike PLUSONE, action costs are not modified.  
Also, unlike PLUSONE, depth-based tiebreaking does not necessarily favor smaller depth over larger depth.
LAMA prefers smaller cost (including the increased cost),
which biases the search toward nodes with fewer zero-cost actions on their path.
This bias is similar to the $[h,\fd,\ro]$ policy,
the worst performer among all depth-variants in our experiments (\reftbl{depth}).
The best depth-based methods are  $[h,\ld,\ro]$ and $[h,\rd,\ro]$,
which do not prefer smaller depth.

% It's not clear what these techniques have in common, except that they are all orthogonal to heuristics,
% If that's the case, then there's no need to cite them in this paper -- there's no reason why these particular techniques
% are more relevant to this paper than hundreds of other techniques that are orthogonal to heuristics.
%% In admissible planning,
%% \emph{Symmetry Breaking}
%% \cite{Fox1998,pochter2011exploiting,domshlak2013symmetry} is the search
%% technique that tries to prune the states with symmetric
%% paths. \emph{Partial Order Reduction}
%% % , \emph{Strong Stubborn Sets} and \emph{Expansion Core} are
%% is also a technique which prunes the
%% intermediate states that reach to the same goal using the different
%% orders of same actions. \emph{Dominance Pruning} \cite{hall2013faster} is a
%% technique which prunes a state if it can be proven to be worse than the other nodes.
%% % 
%% These are usually not considered an attempt to improve the heuristic
%% estimates, however, in terms of \emph{Path-dependent globally admissible
%% heuristics} \cite{karpas2012optimal}, a class of heuristics which is
%% admissible only on a particular optimal path, generalizes the above
%% techniques as assigning an infinite cost to some nodes on the other optimal paths.
%% % 
%% % From a slightly different category, Pathmax \cite{mero1984heuristic} and
%% % Bidirectional Pathmax \cite{felner2011inconsistent} are the techniques
%% % which converts an inconsistent heuristics into non-decreasing,
%% % consistent heuristics.
%% Thus, in a broad term, all of these methods are the
%% attempts to improve the heuristic estimates.
%% % Although in some particular
%% % case they may be able to return a perfect heuristics, they are still not
%% % always a perfect heuristics, implying that the plateau is unavoidable.
%% In contrast, our tiebreaking techniques aims specifically at the case
%% where the plateau is encountered and the planners are forced to run a
%% knowledge-free search.

%% $LA^*$ \cite{stern2010look} extends \astar by performing a
%% cost-bounded depth-first \emph{lookahead} from each node as it is generated.
%% Under the lookahead cost bound $k=0$ ($LA^*_0$ in their notation),
%% all children with the same $f$-value are expanded.
%% The tiebreaking among the same $f$ is not documented either
%% in its main $A^*$ expansion nor in its DFS lookahead.


\section{Conclusion}

In this paper, we evaluated standard tiebreaking
strategies for \astar.
We showed that contrary to conventional wisdom, tiebreaking based on the heuristic value is not necessary to achieve good performance, and proposed
a new framework for defining tiebreaking policies based on \emph{depth}.
We showed that a depth-based, randomized strategy $[h,\rd,\ro]$, which uses the heuristic value, but explicitly avoids depth and ordering biases present in previous methods,
significantly outperforms previous strategies on domains with zero-cost actions, 
including practical application domains with resource optimization objectives in the IPC benchmarks.
% and slightly outperforms previous strategies on benchmark problems without zero-cost actions.
%We have shown that our $[h,\rd,\ro]$ strategy is successful because the randomized depth bucket selection explicitly avoids the depth bias that was present in previous methods
The proposed approach is highly effective on domains where zero-cost actions create large plateau regions where all nodes have the same $f$ and $h$ costs
and the heuristic function provides no useful guidance.
% We argued that such domains arise naturally when considering resource optimization problems.
%It also avoids the effect of action ordering in the domain definition,
%providing a robust behavior.
 % when the distribution of optimal solutions is not uniform within the open list.
% We also showed that this nonuniform distribution still appears when we have almost-perfect % heuristics.
%% Our method differs from the pruning techniques because we do not prune
%% any states, nor from the other general improvements to the heuristic
%% accuracy because we just change the evaluation order within the same
%% $f$, yet it address the fundamental problems in the heuristic forward
%% search. 
%% % 


%While we focused on randomized policies because plateaus, by definition do not provide useful heuristic information, 
%a direction for future work is development of deterministic variants.

%% not much details of the idea were presented in this paper. Also, I
%% don't want it to be copied by someone;;
% on-line adaptation methods that exploit search space neighborhood structure
% in order to adjust the tiebreaking policies.

\section{Background: Tiebreaking Strategy for GBFS}

\label{sec:gbfs}

\section{Notations and Backgrounds for \\Diversified Algorithms}

We first define some notation and the terminology used throughout the
rest of the paper.
$h(s)$ denotes the heuristic estimate from the current state to the
goal state.
$g(s)$ is the current shortest path cost from the initial state to the
current state.
$f(s)=g(s)+h(s)$ is the estimate of the resulting cost of the path
containing the current state.
We omit the argument $(s)$ unless necessary.

A \emph{sorting strategy} of a best first search algorithm is a strategy
which tries to select a single node from the OPEN list.
Sorting strategies are denoted as $[\text{criterion}_1, \text{criterion}_2, ..., \text{criterion}_k]$,
which means: From the OPEN list, first, select a set of nodes using $\text{criterion}_1$.
If there are still multiple nodes remaining in the set, then break ties
using $\text{criterion}_2$ and so on,
until a single node is selected.
The \emph{first-level sorting policy} of a strategy is
$\text{criterion}_1$, the \emph{second-level sorting policy} is
$\text{criterion}_2$, and so on.
%% the word frontier is no longer used in the later text.
% \emph{final frontier} is the set of open nodes with $f^*$.
Note that this corresponds to the command line option format of Fast
Downward \cite{Helmert2006}.

Using this notation, \astar without any tiebreaking strategy can be
denoted as BFS with $[f]$, and \astar which breaks ties according to $h$
value is denoted as $[f,h]$. Similarly, GBFS is denoted as 
$[h]$.  Unless stated otherwise, we assume the nodes are sorted in the
increasing order of the key value, and a BFS always selects the smallest
key value.



The sorting strategy may fail to select a single node. In such cases, a
search algorithm must decide which node to expand by the
\emph{last-resort} tiebreaking strategy, which is one of FIFO
(First-In-First-Out), LIFO (Last-In-First-Out) or RAND (random
ordering).  Trivially, these strategies are able to select a single node
from the set of nodes.  Throughout the paper, we show the last-resort
tiebreaking in the subscript such as $[f,h]_{\lifo}$, and we imply LIFO
when it is omitted.

% A \emph{plateau} is a set of nodes in OPEN with both the same $f$ and same $h$ costs.
% A plateau whose nodes have $f$-cost $f_p$ and $h$-cost $h_p$ is denoted as
% $\plateau{f_p,h_p}$.
% An  \emph{entrance} to a $\plateau{f_p,h_p}$ is a node $n \in \plateau{f_p,h_p}$, whose current parent is not a member of $\plateau{f_p,h_p}$.
% The \emph{final plateau},  is the plateau containing the solution found by the search algorithm.
% In \astar using admissible heuristics, the final plateau is  $\plateau{f^*,0}$.

\section{Backgrounds}

\todo{unrelated -- interesting but too ambitious?}
Heuristic errors consist of two major components called \emph{precision}
and \emph{accuracy}. Both terms are defined based on the distribution of
the heuristic estimates compared to the true distance to the goal $h^*$,
but has a key difference as follows: \emph{accuracy} accounts for the
difference of means, while \emph{precision} accounts for the deviation
from the true distance. The notion was proposed in the early days of
literature for investigating the performance of probabilistic heuristic
function \cite{pearl1984heuristics}, but is largely forgotten in the
current search community. \citeauthor{pearl1984heuristics}
concluded that, for satsificing search, the key characteristics which
determines the performance of inadmissible heuristics is
\emph{precision}, rather than \emph{accuracy}. Assume we have an
inadmissible heuristic function which always overestimates the true
distance $h^*$ by a constant error $e$ --- the guidance provided by
function $h^*(s)+e$ is not much different from that of $h^*(s)$
itself. This is because it changes the accuracy but does not change
the precision of the heuristics.

KBFS(k) \cite{Korf??} is an early attempt on alleviating the problem of
GBFS. It expands $k$ nodes at a time in order to prevent the search
algorithm from getting stuck in the heuristic trap. KBFS provided an
interesting observation to GBFS --- KBFS(1) is equivalent to GBFS, and
KBFS($\infty$) is equivalent to Breadth-First Search.

Alternation OPEN List \cite{RogerH10} is a technique to combine multiple
heuristic functions during the search in order to improve the robustness
of the search algorithm. Nodes are simultaneously stored and sorted into the
multiple independent OPEN lists with different sorting strategies, and
it alternates among the OPEN lists when it expands a new node.
We denote an alternating OPEN list as $\mit{alt}(X_1,X_2,\ldots)$ where
each $X_i$ is a sorting strategy.

$\epsilon$-greedy GBFS \cite{valenzano2014comparison} is a variation of GBFS
which selects a random node in the OPEN list at a certain fixed
probability $\epsilon <1$ given as a parameter. When the random
exploration takes place, the entire nodes in OPEN list are treated equally, and
there is no explicit criteria for characterising the nodes.
This is conceptually equivalent to the weighted version of the alternation
open list using $[h]_{\fifo}$ and $[\ ]_{\ro}$ (no sorting criteria) with weights
$1-\epsilon$ and $\epsilon$. We denote such a weighted alternation open
list as $\mit{alt}(w_1X_1,w_2X_2,\ldots)$ where each $w_i$ is a weight
for a sorting strategy $X_i$. Now $\epsilon$-greedy GBFS corresponds to
$\mit{alt}((1-\epsilon)[h]_{\fifo},\epsilon [\ ]_{\ro})$.

While the exploration phase of $\epsilon$-greedy GBFS does not have any method to detect the bias
between the nodes,
Type-GBFS \cite{xie14type} does this by running the 
classification of the nodes. The nodes are categorized into buckets
(called ``type bucket''), each associated with a specific vector of key
values, such as $[g,h]$ for each state. On each explorative
expansion, the search algorithm selects a random node in a random
bucket, which avoids the cardinality bias --- the search nodes
may be more concentrated in a particular bucket, and exploration done by
$\epsilon$-greedy fails to explore the variety of search space, unlike
Type-GBFS.

Type-GBFS categorizes the nodes in type buckets, but does not sort the
buckets with the key vector. Thus, we denote such a random
selection among buckets as $\brackets{\ldots}$ where $\ldots$ is a
classification criteria, e.g., $\brackets{g,h}$ denotes the type buckets
whose keys are the vector $[g,h]$.

In their paper, the method was evaluated under a
configuration that the explorative expansion and the exploitative
expansion (standard GBFS) alternates. 
Thus, we can write this algorithm as $\mit{alt}([h], \brackets{g,h}_{\ro})$.
% This also corresponds to the case of $\epsilon$-greedy with $\epsilon=0.5$.
% 
They empirically show that
this configuration results in larger coverage and that it
expands much broader variety of nodes in the explorative
expansion phase.

\begin{table}[htbp]
 \centering
 \setlength{\tabcolsep}{0.2em}
 % \begin{tabular}{|l|l|}
 \begin{align*}
  \mbox{\astar without tiebreaking}         &: [f]   \\
  \mbox{\astar, break ties for smaller $h$} &: [f,h] \\
  \mbox{Standard GBFS}                      &: [h]   \\
  \mbox{GBFS+Alternation (2 heuristics)}    &: \mit{alt}([h_1],[h_2])   \\
  \mbox{$\epsilon$-greedy GBFS}             &: \mit{alt}((1-\epsilon)[h], \epsilon [\ ]_{\ro}) \\
  \mbox{Type-GBFS, type = $[g,h]$}          &: \mit{alt}(\quad       [h],\quad \brackets{g,h}_{\ro}) \\
  \mbox{$\epsilon$-greedy Type-GBFS}        &: \mit{alt}((1-\epsilon)[h], \epsilon\brackets{g,h}_{\ro}) \\
  \mbox{\astar + $h$ tiebreaking + depth}   &: [f,h]_{\brackets{\mit{\scriptsize depth}}} \\
  \mbox{GBFS + depth}                       &: [h]_{\brackets{\mit{\scriptsize depth}}} \\
 \end{align*}
 % \end{tabular}
 \caption{Various search algorithms using the notation in this paper}
\end{table}

%% less priority. remove?
% DBFS \cite{imai2011novel} is also an algorithm which diversifies the
% search based on $g$ and $h$ values, but with several key differences from
% above two algorithms: First, the explorative selection is not uniformly
% random, but is subject to a particular distribution function defined by
% $h, g, h_{min}$ and $g_{max}$. Second, it uses a local search with
% a bounded number of expansions equal to $h(s)$, which dynamically balances the exploration
% and exploitation --- it does more GBFS when $h$ is large (far
% from the goal), and less GBFS near the goal ($h$ is small).



% The diversification based on the depth can be considered as an instance
% of last-resort tiebreaking, since the depth is used \emph{after} the
% sorting strategy selects a set of nodes.
% % 
% We can also view the depth-based diversification as a classification of
% the nodes into type-based buckets with depth as a single key value.
% Thus, we call this framework as \emph{typed-sorting strategy}, a mix of
% sorting strategy and type-based buckets, denoted as $[\mbox{sorting
% strategy}]_{\brackets{\mbox{\small type vector}}}$.
% % 
% For example, \astar using $h$ as the first tiebreaking criteria and
% depth as a diversification method can be expressed as
% $[f,h]_{\brackets{d}}$. 
% % _{\fifo}
% % The reason \fifo is present
% % after $\brackets{d}$ is that when multiple nodes are in the same depth, a
% % single node is selected in a FIFO order.
% % Trivially, $[\ ]_{\brackets{X}}$ is equivalent to $\brackets{X}$ and
% % $[X]_{\brackets{\ }}$ is equivalent to $[X]$.


\section{Depth-based Tiebreaking for GBFS}

%\citeauthor{Korf1985depth} uses $h$-based tiebreaking in the context of WA*
%\cite{korf1993linear} 
% 
% (g-based tiebreaking, p69, for GBFS:) With all the weight on h, meaning
% that g is used only for tie-breaking among nodes with equal h values,
% 
% (p73:) to break ties in favor of nodes closest to the initial state.  
% ** not sure how/where to put this..


Compared to \astar, to our knowledge, there are currently no
well-established tiebreaking policy for GBFS. GBFS does not use $f$ and
$g$ value during the search process.  The search by GBFS is solely
guided by the heuristic value $h$: It always expands the node with the
smallest $h$ value, and hence the analogy from \astar e.g.\ sorting the
nodes with $f$ and breaking ties according to $h$ is not possible.

As a consequence, except for diversification,
search enhancement for GBFS have been achieved by
modifying the heuristic function itself.  This includes not only using the
different heuristic functions, but also lazy evaluation,
preferred operators and PLUSONE/ONE cost type.
 
Lazy evaluation is a technique which derives the heuristic value of a
state from its parent. This sacrifices the informativeness of the
heuristics against the effort of computing each heuristic function.
 
Preferred operator (helpful action in \cite{Hoffmann01}) marks some
operators to be promising when it improved the least cost estimate in the
previous node expansion. Marked nodes are put in a special queue
which is expanded more often, which is equivalent to temporarily
increasing the priority of the particular nodes.
 
PLUSONE cost type is a technique which adds a cost of 1 to each edge
cost, which also affects the heuristic value. Similarly, ONE cost type
treats all actions to have a unit cost.  ONE cost type is used in
the first GBFS iteration of LAMA, and PLUSONE cost type is used in the
second GBFS iteration of LAMA (followed by WA*).

We instead consider the use of the depth-based tiebreaking policy, which
is able to identify the relative location of the current state in the
plateau.  In this section, we evaluate the effect of depth-based
tiebreaking on Eager GBFS, and also compare the effect
against various search enhancements stated above.

\subsection{Comparison against GBFS}

We compared the performance of 
($G$) the standard GBFS
$[h]$,
($G_d$) GBFS using depth-based diversification
$[h]_{\relsize{-2}\brackets{d}}$,
($T$) Type-GBFS
$alt([h],\brackets{g,h})$,
($T_d$) Type-GBFS using depth-based diversification
$alt([h]_{\brackets{d}},\brackets{g,h})$,
($T^d$) Type-GBFS using depth-based type bucket
$alt([h],\brackets{g,h,d})$,
($T_d^d$) Type-GBFS using both depth-based diversification and depth-based type bucket
$alt([h]_{\brackets{d}},\brackets{g,h,d})$.

Since the effect of depth could be heuristic-dependent, we tested three
heuristics as $h$:
FF heuristics\cite{Hoffmann01}, Causal Graph (CG) heuristics \cite{Helmert2006}, Context Enhanced
Additive (CEA) heuristics\cite{helmert2008unifying}.
%% not included --- its is a pseudo heuristics anyways
% , Landmark-Count (LC) heuristics\cite{richter2008landmarks}



% In order to remove the effect of randomness of the algorithm, we
% implemented a deterministic version of Type-based queue for Type-GBFS
% which, instead of selecting a bucket at random, iterates over the
% buckets in a reverse order that each bucket is introduced.
% Similarly, the diversification based on the depth is not randomized but
% is implemented as a loop-based implementation.

Results are shown in \reftbl{eager-results}. Overall, depth offers
improvements to all of CEA, CG and FF heuristics. Thus, we conjecture
that the effect of depth-based diversification is heuristic-independent.

We also tested the effect of lazy (deferred) evaluation of the
heuristic functions. As explained in the previous section, lazy
evaluation can be considered as a form of modifying the heuristic
function by sacrificing the accuracy for the node expansion rate.
As expected, depth-based diversification offers the similar speedup as
in the case of eager evaluation.

Another dimension we should consider in evaluating the depth
diversification is the use of PLUSONE which treats all
action costs as the original value plus 1, or ONE cost type which treats
all actions as the unit cost.

% \newcommand{\htitle}[1]{\multicolumn{#1}{c|}{CEA} & \multicolumn{#1}{|c|}{CG} & \multicolumn{#1}{|c|}{FF}}
\newcommand{\etitle}[2]{ \multicolumn{#1}{|c||}{Eager} & \multicolumn{#1}{|c|#2}{Lazy}}
\newcommand{\htitle}[2]{\multicolumn{#1}{c|}{CEA} & \multicolumn{#1}{|c|}{CG} & \multicolumn{#1}{|c|#2}{FF}}
\newcommand{\titles}[3]{
&\etitle{#1}{#3} \\
\hline
&\htitle{#2}{|} #3 &\htitle{#2}{}\\
\hline
}
\newcommand{\bi}[1]{\textbf{\Large #1}}

\begin{table*}[htbp]
 \setlength{\tabcolsep}{0.1em}
 % \setlength{\tabcolsep}{0.05em}
 % \relsize{-1}
\centering
\begin{tabular}{|l*{2}{*{3}{|cc}|}*{2}{*{3}{|cc}|}}
\hline
&\etitle{6}{|} & \etitle{6}{}\\
\hline
&\htitle{2}{|} & \htitle{2}{|} &\htitle{2}{|} & \htitle{2}{}\\
\hline
 & g & G & g & G & g & G & g & G & g & G & g & G & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt\\
\hline
coverage & 189 & \bi{193} & 174 & \bi{183} & 166 & 167 & 139 & \bi{172} & 137 & \bi{144} & 146 & \bi{162} & \bi{203} & 200 & 203 & \bi{210} & \bi{217} & 215 & 157 & \bi{173} & 165 & \bi{179} & 178 & \bi{212}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
lvtr & 1 & \bi{3} & 3 & \bi{5} & 0 & 0 & 1 & \bi{4} & 1 & \bi{4} & 0 & 0 & 1 & \bi{3} & 3 & 3 & 0 & 0 & 1 & \bi{3} & 1 & \bi{4} & 0 & 0\\
flrt & 4 & 4 & 0 & 0 & 7 & 7 & 6 & 6 & 0 & 0 & \bi{8} & 4 & 7 & 7 & 2 & 2 & 9 & 9 & 6 & 7 & 2 & 2 & 8 & 9\\
nmys & 7 & 7 & 7 & 7 & 6 & \bi{8} & 8 & 8 & 9 & 9 & 5 & \bi{7} & 9 & 9 & \bi{16} & 14 & 16 & 15 & 11 & 11 & 14 & 15 & 15 & 16\\
pnst & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
prcp & 15 & 15 & 15 & 15 & 5 & 5 & 12 & 12 & 11 & 11 & 0 & 0 & 15 & 15 & 15 & 15 & 7 & 7 & 11 & 11 & 10 & 10 & 6 & 6\\
prkn & 0 & 1 & 12 & 13 & 15 & 14 & 2 & \bi{4} & 3 & \bi{11} & 14 & \bi{19} & 3 & 2 & 7 & \bi{9} & \bi{12} & 8 & 1 & 0 & 3 & 4 & 15 & 16\\
pgsl & 19 & 19 & 20 & 20 & 19 & 19 & 19 & 19 & 20 & 19 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 19 & 20 & 20 & 20 & 20\\
scnl & 17 & 17 & 17 & 17 & 14 & 14 & 17 & 17 & 17 & 17 & 15 & 14 & 17 & 17 & 17 & 17 & 16 & 16 & 17 & 17 & 17 & 17 & 17 & 17\\
skbn & 12 & 12 & 14 & 14 & 18 & 17 & 10 & 11 & 15 & 15 & 18 & 17 & 15 & 16 & 16 & 17 & 18 & 18 & 16 & 16 & 13 & \bi{16} & 18 & 18\\
tdyb & 16 & 17 & 14 & \bi{18} & 15 & 14 & 16 & 17 & 14 & \bi{17} & 14 & 13 & 16 & 16 & 19 & 19 & 16 & 16 & 16 & 17 & 20 & 20 & 14 & \bi{16}\\
trns & 7 & 7 & 9 & \bi{11} & 0 & 0 & 3 & \bi{5} & 7 & 8 & 0 & 0 & 7 & 7 & 11 & 11 & 0 & 0 & 4 & 5 & 9 & 8 & 0 & 0\\
vstl & 3 & 3 & 3 & 3 & 5 & 5 & 3 & 3 & 3 & 3 & 5 & 4 & 4 & 4 & 4 & 5 & 6 & 5 & 4 & 4 & 5 & 5 & 4 & \bi{6}\\
wdwr & 10 & 10 & 10 & 10 & 12 & 12 & 2 & 3 & 1 & 1 & 10 & 11 & 12 & 11 & 12 & 13 & 15 & 15 & 3 & 4 & 1 & 1 & 7 & \bi{13}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 & 2 & 0 & 0 & 0 & 0 & 0 & 0\\
cvdv & 6 & 6 & 7 & 7 & 6 & 6 & 4 & \bi{7} & 7 & 7 & 6 & 6 & 6 & 7 & 7 & 7 & 7 & 7 & 7 & 7 & 8 & 8 & 7 & 7\\
chld & 2 & 2 & 2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \bi{2} & 0 & \bi{3} & 0 & 0 & 0 & 2 & 1 & 6 & 5 & 2 & 2\\
ctyc & 20 & 20 & 0 & \bi{2} & 0 & 0 & 1 & \bi{20} & 0 & 0 & 0 & 0 & 20 & 20 & 1 & 1 & 18 & \bi{20} & 1 & \bi{15} & 0 & 0 & 1 & \bi{10}\\
flrt & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 & 0 & 0 & 3 & 3 & \bi{5} & 3 & 2 & 1 & \bi{5} & 3 & 3 & 2 & 2 & 2 & 3 & 3\\
gd-s & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
hkng & 17 & 16 & 15 & 14 & 16 & \bi{18} & 17 & 17 & \bi{16} & 13 & 12 & \bi{14} & 16 & 16 & 20 & 20 & 20 & 20 & 16 & 15 & 18 & 19 & 18 & 18\\
mntn & 16 & 16 & 16 & 16 & 11 & 12 & 0 & 0 & 0 & 0 & 4 & \bi{7} & 16 & 16 & 16 & 16 & 13 & 14 & 7 & 7 & 7 & 7 & 9 & 10\\
pnst & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
prkn & 0 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 3 & \bi{11} & 0 & 0 & 0 & 0 & 2 & 2 & 0 & 0 & 0 & 0 & 1 & \bi{8}\\
ttrs & 3 & 4 & 2 & 2 & 3 & 3 & 1 & \bi{4} & 2 & 2 & 1 & \bi{3} & 2 & 2 & 6 & \bi{12} & 2 & \bi{4} & 1 & 2 & 2 & \bi{9} & 3 & \bi{6}\\
thgh & 11 & 11 & 4 & 5 & 11 & 10 & 12 & 12 & \bi{6} & 4 & 7 & \bi{9} & 9 & 8 & 5 & 5 & 12 & 13 & 9 & 9 & 5 & 5 & 10 & 11\\
trns & 1 & 0 & \bi{3} & 1 & 0 & 0 & \bi{3} & 0 & \bi{5} & 2 & 0 & 0 & 1 & 1 & 1 & \bi{3} & 0 & 0 & 1 & 1 & 2 & 2 & 0 & 0\\
vstl & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\hline
\end{tabular}
\caption{Results of 5 min, 4Gb experiments, comparing the variants with and without depths:}%
 % (g): GBFS $[h]$,
 % (G): GBFS with depth based diversification $[h]_\{d\}$.
 % Left side shows the result of eager evaluation, and the right side shows
 % the result of lazy evaluation.
 % ,
 % (gt): $alt([h],\brackets{g,h})$,
 % (gT): $alt([h],\brackets{g,h,d})$,
 % (Gt): $alt([h]_{\brackets{d}},\brackets{g,h})$,
 % (GT): $alt([h]_{\brackets{d}},\brackets{g,h,d})$
 % }
\end{table*}

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{0.1em}
\begin{tabular}{lll|ccc|ccc}
 &  &  & Eager & Eager & Eager & Lazy & Lazy & Lazy\\
 &  &  & IPC7 & IPC8 & sum & IPC7 & IPC8 & sum\\
\hline
ce & g & F & 112 & 70 & 182 & 116 & 54 & 170\\
ce & G & F & 113 & 70 & 183 & 119 & 48 & 167\\
ce & gt & F & 120 & 67 & 187 & 125 & 67 & 192\\
ce & gT & F & 120 & 67 & 187 & 125 & 66 & 191\\
ce & Gt & F & 120 & \bi{77} & 197 & 128 & 62 & 190\\
ce & GT & F & 121 & \bi{77} & 198 & 129 & 62 & 191\\
cg & g & F & 126 & 54 & 180 & 110 & 37 & 147\\
cg & G & F & 132 & 55 & 187 & 118 & 36 & 154\\
cg & gt & F & 139 & 63 & 202 & 122 & 49 & 171\\
cg & gT & F & 138 & 63 & 201 & 121 & 49 & 170\\
cg & Gt & F & \bi{142} & 63 & \bi{205} & 129 & 56 & 185\\
cg & GT & F & \bi{142} & 63 & \bi{205} & 128 & 56 & 184\\
ff & g & F & 110 & 49 & 159 & 110 & 48 & 158\\
ff & G & F & 110 & 54 & 164 & 117 & 45 & 162\\
ff & gt & F & 130 & 71 & 201 & \bi{137} & \bi{75} & \bi{212}\\
ff & gT & F & 129 & 71 & 200 & 136 & \bi{75} & 211\\
ff & Gt & F & 134 & 68 & 202 & 132 & 59 & 191\\
ff & GT & F & 135 & 70 & \bi{205} & 133 & 59 & 192\\
\hline
ce & g & L & 111 & 78 & 189 & 99 & 40 & 139\\
ce & G & L & 115 & 78 & 193 & 109 & 63 & 172\\
ce & gt & L & 126 & 77 & 203 & 110 & 47 & 157\\
ce & gT & L & 127 & 76 & 203 & 114 & 45 & 159\\
ce & Gt & L & 127 & 73 & 200 & 114 & 59 & 173\\
ce & GT & L & 125 & 75 & 200 & 116 & 54 & 170\\
cg & g & L & 124 & 50 & 174 & 101 & 36 & 137\\
cg & G & L & 133 & 50 & 183 & 115 & 29 & 144\\
cg & gt & L & 142 & 61 & 203 & 115 & 50 & 165\\
cg & gT & L & 141 & 57 & 198 & 119 & 41 & 160\\
cg & Gt & L & \bi{145} & 65 & 210 & 122 & 57 & 179\\
cg & GT & L & \bi{145} & 59 & 204 & 122 & 48 & 170\\
ff & g & L & 116 & 50 & 166 & 110 & 36 & 146\\
ff & G & L & 115 & 52 & 167 & 109 & 53 & 162\\
ff & gt & L & 135 & 82 & \bi{217} & 124 & 54 & 178\\
ff & gT & L & 127 & 79 & 206 & 130 & 46 & 176\\
ff & Gt & L & 130 & \bi{85} & 215 & 137 & \bi{75} & \bi{212}\\
ff & GT & L & 133 & 74 & 207 & \bi{140} & 70 & 210\\
\end{tabular}
\end{table}

\begin{table*}[htbp]
 \setlength{\tabcolsep}{0.1em}
 % \setlength{\tabcolsep}{0.05em}
 % \relsize{-1}
\centering
\begin{tabular}{|l*{2}{*{3}{|cc}|}*{2}{*{3}{|cc}|}}
\hline
&\etitle{6}{|} & \etitle{6}{}\\
\hline
&\htitle{2}{|} & \htitle{2}{|} &\htitle{2}{|} & \htitle{2}{}\\
\hline
 % & e & e & e & e & e & e & l & l & l & l & l & l & e & e & e & e & e & e & l & l & l & l & l & l\\
 % & ce1 & ce1 & cg1 & cg1 & ff1 & ff1 & ce1 & ce1 & cg1 & cg1 & ff1 & ff1 & ce1 & ce1 & cg1 & cg1 & ff1 & ff1 & ce1 & ce1 & cg1 & cg1 & ff1 & ff1\\
 & g & G & g & G & g & G & g & G & g & G & g & G & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt & gt & Gt\\
\hline
IPC7 & 118 & 118 & 140 & \bi{143} & \bi{142} & 139 & 99 & \bi{117} & 113 & \bi{134} & 112 & \bi{143} & 130 & 130 & 153 & 154 & \bi{166} & 157 & 106 & \bi{121} & 124 & \bi{146} & 135 & \bi{156}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 10 & 10 & 0 & 0 & 0 & 0 & 2 & 2\\
lvtr & 8 & 8 & 8 & 9 & 10 & 10 & 10 & 10 & 9 & 8 & 8 & \bi{12} & 8 & 8 & 8 & 9 & 10 & 10 & 5 & \bi{8} & 7 & \bi{9} & 4 & \bi{11}\\
flrt & 3 & 3 & 0 & 0 & 3 & 4 & 3 & 3 & 0 & 0 & 3 & 3 & 5 & 5 & 2 & 2 & 8 & 7 & 5 & 5 & 2 & 2 & 6 & 6\\
nmys & 7 & 7 & 7 & 7 & 6 & \bi{8} & 8 & 8 & 9 & 9 & 4 & \bi{7} & 9 & 9 & \bi{16} & 14 & 16 & 15 & 11 & 11 & 14 & 15 & 15 & 16\\
pnst & 13 & 12 & 13 & 13 & 15 & 15 & 0 & \bi{15} & 0 & \bi{14} & 0 & \bi{20} & 11 & 11 & 11 & 11 & 13 & 13 & 0 & \bi{11} & 1 & \bi{12} & 4 & \bi{9}\\
prcp & 20 & 20 & 20 & 19 & 20 & 20 & 11 & 11 & 11 & 11 & 11 & 11 & 18 & 18 & 18 & 19 & 20 & 20 & 12 & 13 & 11 & 12 & 14 & 14\\
prkn & 0 & \bi{2} & 12 & 13 & \bi{15} & 11 & 2 & \bi{4} & 3 & \bi{11} & 14 & \bi{19} & 3 & 2 & 7 & \bi{9} & \bi{12} & 8 & 1 & 0 & 3 & 4 & 15 & 16\\
pgsl & 20 & 20 & 20 & 20 & 19 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
scnl & 17 & 17 & 17 & 17 & 14 & 14 & 17 & 17 & 17 & 17 & 12 & 13 & 16 & 16 & 17 & 17 & 15 & 15 & 17 & 17 & 17 & 17 & 17 & 17\\
skbn & 3 & 3 & 13 & 12 & 18 & 17 & 3 & 3 & 15 & 14 & 18 & 17 & 10 & 10 & 17 & 17 & 18 & 17 & 10 & 9 & 15 & \bi{17} & 18 & 18\\
tdyb & 16 & 17 & 14 & \bi{18} & \bi{15} & 13 & 16 & 17 & 14 & \bi{17} & 14 & 13 & 16 & 16 & 19 & 19 & 16 & 15 & 16 & 17 & 20 & 20 & 14 & \bi{16}\\
trns & \bi{7} & 5 & 12 & 11 & 0 & 0 & 4 & 5 & \bi{11} & 9 & 0 & 0 & 6 & \bi{8} & 13 & 12 & 0 & 0 & 3 & \bi{5} & 8 & \bi{12} & 0 & 0\\
vstl & 3 & 3 & 3 & 3 & 5 & 5 & 3 & 3 & 3 & 3 & 5 & 4 & 4 & 4 & 4 & 4 & 6 & 5 & 4 & 4 & 5 & 5 & 4 & \bi{6}\\
wdwr & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 1 & 1 & 1 & 2 & \bi{4} & 4 & 3 & 1 & 1 & 2 & 2 & 2 & 1 & 1 & 1 & 2 & \bi{5}\\
\hline
IPC8 & 62 & 62 & 60 & \bi{64} & 73 & 73 & 36 & \bi{50} & 39 & \bi{48} & 54 & \bi{93} & \bi{57} & 55 & 76 & \bi{79} & 80 & 79 & 44 & \bi{53} & 66 & \bi{74} & 66 & \bi{92}\\
\hline
brmn & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \bi{4} & 2 & 0 & 0 & 0 & 0 & 0 & 0\\
cvdv & 6 & 6 & 7 & 7 & 7 & 7 & 4 & \bi{7} & 7 & 7 & 6 & 7 & 6 & 6 & 7 & 7 & 7 & 7 & 6 & 7 & 7 & 8 & 7 & 7\\
chld & 2 & 2 & 2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \bi{2} & 0 & \bi{3} & 0 & 0 & 0 & 2 & 1 & 6 & 5 & 2 & 2\\
ctyc & 2 & 2 & 0 & 1 & 0 & 0 & 0 & \bi{2} & 0 & 0 & 0 & 0 & 4 & 5 & 1 & 1 & 3 & 3 & 1 & \bi{9} & 0 & 0 & 0 & \bi{7}\\
flrt & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 & 0 & 0 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 1 & 1 & 2 & 2\\
gd-s & 0 & 0 & 0 & 0 & \bi{19} & 17 & 0 & 0 & 0 & 0 & 20 & 20 & 0 & 0 & 8 & 9 & 16 & 15 & 0 & 0 & 11 & 11 & 15 & \bi{17}\\
hkng & 17 & 16 & 15 & 14 & 16 & \bi{18} & 17 & 17 & \bi{16} & 13 & 12 & \bi{14} & 16 & 16 & 20 & 20 & 20 & 20 & 16 & 15 & 18 & 19 & 18 & 18\\
mntn & 16 & 16 & 16 & 16 & 11 & 12 & 0 & 0 & 0 & 0 & 4 & \bi{7} & 16 & 16 & 16 & 16 & 13 & 13 & 7 & 7 & 7 & 7 & 9 & 10\\
pnst & 0 & 0 & 0 & 0 & 4 & 4 & 0 & \bi{3} & 0 & \bi{3} & 0 & \bi{20} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & \bi{6}\\
prkn & 0 & 2 & 1 & 1 & 2 & 1 & 0 & 1 & 0 & 1 & 3 & \bi{11} & 0 & 0 & 0 & 0 & 1 & 2 & 0 & 0 & 0 & 0 & 1 & \bi{8}\\
ttrs & 4 & 3 & 12 & \bi{15} & 1 & 2 & 1 & \bi{5} & 7 & \bi{17} & 0 & \bi{3} & 1 & 1 & 13 & \bi{15} & 2 & 2 & 1 & 3 & 9 & \bi{15} & 2 & \bi{4}\\
thgh & 12 & 11 & 4 & 5 & 11 & 10 & 12 & 12 & \bi{6} & 4 & 7 & \bi{9} & 9 & 8 & 5 & 5 & 12 & 13 & 9 & 9 & 5 & 5 & 10 & 11\\
trns & 1 & 2 & 3 & 3 & 0 & 0 & 0 & 1 & 3 & 3 & 0 & 0 & 1 & 1 & 1 & \bi{4} & 0 & 0 & 0 & 0 & 2 & 2 & 0 & 0\\
vstl & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\hline
\end{tabular}
\caption{Results obtained by treating each action to have a unit cost
 during heuristic calculation.
 5 min, 4Gb experiments, comparing the variants with
 and without depths:
 % (g): GBFS $[h]$,
 % (G): GBFS with depth based diversification $[h]_\brackets{d}$.
 Left side shows the result of eager evaluation, and the right side shows
 the result of lazy evaluation.
 % ,
 % (gt): $alt([h],\brackets{g,h})$,
 % (gT): $alt([h],\brackets{g,h,d})$,
 % (Gt): $alt([h]_{\brackets{d}},\brackets{g,h})$,
 % (GT): $alt([h]_{\brackets{d}},\brackets{g,h,d})$
 }
\end{table*}


% \subsection{Comparison against Lazy Evaluation}

% Although the policy was originally designed for optimising
% \astar search with admissible heuristics, the core idea of depth would
% not be much affected by the difference between \astar and GBFS.

\subsection{Comparison against LAMA}

LAMA \cite{richter2010lama} is a \sota planner which is a winner of
IPC2011. It has numerous search enhancements including Lazy Evaluation,
Multi-heuristic search, Preferred Operators and PLUSONE cost type.

LAMA runs a GBFS followed by WA* with decreasing weights, and works in
an anytime fasion. However, this is due to the context of the
competition setting where the task also includes finding a better plan.
Since this paper focuses on GBFS, we only consider 
the coverage within the resource constraint. Thus, in the following
experiments, we do not run the successive iterations of WA* in LAMA.

The first iteration (GBFS) of LAMA is expressed as
$alt([\mit{ff}],\pref{[\mit{ff}]},[\mit{lc}],\pref{[\mit{lc}]})$, where $\mit{ff}$
denotes the FF heuristics, $\mit{lc}$ denotes the Landmark-Count heuristics,
and $\pref{X}$ denotes the preferred operator queue with sorting
strategy $X$.

We compare this base LAMA with the type-based version of LAMA and their
variants using depths.
We followed the best configuration suggested by \citeauthor{xie14type} (\citeyear{xie14type})
for Type-GBFS, which uses the type vector $\brackets{g,\mit{ff}}$.
Due to the multiple enhancements, the configurations are fairly complicated:

\begin{eqnarray}
  alt([\mit{ff}],\pref{[\mit{ff}]},[\mit{lc}],\pref{[\mit{lc}]},\brackets{g,\mit{ff}}) \\
  alt([\mit{ff}]_\brackets{d},\pref{[\mit{ff}]_\brackets{d}},[\mit{lc}]_\brackets{d},\pref{[\mit{lc}]_\brackets{d}},\brackets{g,\mit{ff}}) \\
  alt([\mit{ff}],\pref{[\mit{ff}]},[\mit{lc}],\pref{[\mit{lc}]},\brackets{g,\mit{ff},d}) \\
  alt([\mit{ff}]_\brackets{d},\pref{[\mit{ff}]_\brackets{d}},[\mit{lc}]_\brackets{d},\pref{[\mit{lc}]_\brackets{d}},\brackets{g,\mit{ff},d}) 
\end{eqnarray}

% _\brackets{d}

\begin{table}[htbp]
 \setlength{\tabcolsep}{0.2em}
\centering
\begin{tabular}{l|cccc||cccc}
 & F & F & F & F & L & L & L & L\\
 & g & G & gt & Gt & g & G & gt & Gt\\
\hline
IPC7 & \bi{223} & 220 & 224 & 224 & 210 & \bi{214} & \bi{224} & 219\\
\hline
brmn & 15 & 16 & 16 & 16 & 15 & 14 & \bi{16} & 14\\
lvtr & 14 & \bi{17} & 16 & 17 & 18 & 18 & 16 & \bi{18}\\
flrt & 3 & 2 & 4 & 4 & 3 & 3 & 4 & 4\\
nmys & 11 & 10 & 12 & 12 & 6 & \bi{9} & \bi{12} & 8\\
pnst & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
prcp & \bi{20} & 18 & 16 & 17 & 14 & 14 & 16 & \bi{18}\\
prkn & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
pgsl & 20 & 19 & 20 & 20 & 20 & 20 & 20 & 20\\
scnl & 17 & 17 & 17 & 17 & 17 & 17 & 17 & 17\\
skbn & 16 & 15 & 16 & 16 & 15 & 15 & 16 & 17\\
tdyb & 16 & 15 & \bi{17} & 15 & 13 & 14 & \bi{17} & 13\\
trns & 11 & 11 & 10 & 10 & 10 & 10 & 10 & 10\\
vstl & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
wdwr & 20 & 20 & 20 & 20 & 19 & 20 & 20 & 20\\
\hline
IPC8 & 111 & \bi{125} & 112 & \bi{117} & 111 & \bi{121} & 114 & \bi{120}\\
\hline
brmn & 8 & \bi{10} & 9 & 8 & \bi{9} & 6 & 9 & 8\\
cvdv & 7 & 7 & 6 & 7 & 6 & 7 & 6 & 6\\
chld & 0 & \bi{10} & 2 & \bi{6} & 3 & 3 & 2 & 3\\
ctyc & 1 & 0 & 5 & 4 & 2 & \bi{4} & 5 & 5\\
flrt & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2\\
gd-s & 20 & 20 & 20 & 20 & 20 & 20 & 20 & 20\\
hkng & 15 & \bi{17} & 15 & 15 & 14 & 15 & 15 & 16\\
mntn & 1 & 1 & 6 & 6 & 1 & 1 & 6 & 7\\
pnst & 17 & 17 & 15 & \bi{17} & 16 & \bi{18} & 16 & 15\\
prkn & 9 & 9 & 6 & 6 & 9 & 10 & 7 & 8\\
ttrs & 2 & 2 & 2 & 1 & 2 & \bi{4} & 2 & 2\\
thgh & 14 & 15 & 14 & 15 & 13 & \bi{15} & 14 & \bi{17}\\
trns & 2 & 2 & 1 & \bi{3} & 2 & 3 & 1 & 1\\
vstl & 13 & 13 & \bi{9} & 7 & 12 & 13 & 9 & 10\\
\hline
\end{tabular}
\caption{Lama results.}
\end{table}



\section{Related Work}

\cite{schulte2014balancing}

\cite{auer2002finite}
