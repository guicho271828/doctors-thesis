\clearpage 
\section{Discussion}
\label{sec:discussion}

One observation that can be made from the experiments in the previous
sections is that \textbf{optimizing search can be seen as a series of
cooperative satisficing searches in the plateaus of an increasing order
of $f$}.

Similar concept is common in SAT/IP/CP model-based sequential / temporal
planning, except they are not ``cooperative''. In model-based
planning, a planning problem is converted to a corresponding constraint
satisfaction problem with a finite horizon $t$ (plan length /
makespan). The search starts from the horizon 0
and tests if the problem is satisfiable. If not, then it increases the
horizon and retests the same problem with additional constraints for
horizon $t+1$. In the optimizing forward heuristic search such as
\astar, the concept of horizon corresponds to the $f$ value, which is a
lower bound of the problem being solved.

The key difference in the \astar-based optimal planning from the model-based planning is
that the information is transmitted between different horizons:
In \astar, nodes that are generated by the smaller
$f$ layer will be ``sent'' to the larger $f$ layer through the global OPEN
list, while the current model-based methods prove the satisfiability of
different horizons independently -- in each iteration of the search,
they have to generate a new set of variables for each horizon, and the
underlying CSP solvers are forced to start the search from the scratch.

Our notion of \emph{admissible sorting criteria} dictates that, the
search within the same $f$ plateau can be a satisfiable search. In fact,
if we focus on the second or later sorting criteria in the standard criteria
$[f,h,\fifo]$ for optimizing search, i.e. $[f,h,\fifo] \rightarrow [h,\fifo]$, this is exactly
the same configuration as a GBFS using \fifo last-resort tiebreaking. It
means that within the plateau of the same $f$, $[f,h,\fifo]$ is
performing a satisficing GBFS.
From the same standpoint, the reason for the poor performance of $[f,\fifo]$
is clear: If we ignore the first sorting criteria, it is $[\fifo]$,
which is a pure satisficing breadth-first search in the plateau.
Also, the good performance of $[f^{\lmcut},\ffo,\fifo]$ is also clear:
If we ignore the first sorting criteria, it is $[\ffo,\fifo]$,
and by itself $\ffo$ is known to be a \sota inadmissible heuristic
function for satisficing forward search.

Although we evaluated only one \sota satisficing configuration $\ffo$ in
the experiments, it does not preclude the possibility of applying yet
more variety of satisficing planning techniques to optimal search, such as lazy-evaluation
or preferred operators in LAMA, depth-first probe in Probe \cite{LipovetzkyG11}, or
random-walk strategy in Arvand \cite{nakhost2009monte}, or Type-based
exploration in Type-GBFS \cite{xie14type}.
% Future work on this direction should be evaluated in the context of
% future International Planning Competitions.

The new view can also yield another observation if we use the same logic
in an opposite direction: We import techniques not only from satisficing
to optimizing, but also from optimizing to satisficing.
In the experiments, we showed that the depth improved the distance-to-go \ff heuristic $\ffo$
used for \textbf{satisficing search within a plateau}. A natural extension
to this idea is that the depth metric can also enhance the performance of
$\ffo$ used for \textbf{satisficing search in general}.

We provide preliminary results on the IPC8 satisficing track
instances. We tested GBFS using the distance-to-go variations of three
\sota inadmissible heuristics for satisficing search: FF heuristics
 \cite{Hoffmann01}, Causal Graph (CG) heuristics \cite{Helmert2006} and
Context Enhanced Additive (CEA) heuristics\ \cite{helmert2008unifying}.
For each heuristics, we tested eager and lazy search, with and without
the depth metric.  Tests are conducted under 5 min, 4GB
resource constraint.

In Eager search, depth metric
improved the performance of $\cgo$ ($60\rightarrow $ \textbf{64}), but no
improvement was observed in $\ceo$ ($62\rightarrow 62$)
and $\ffo$ ($73\rightarrow 73$). In Lazy search, depth metric
improved the performance of all three heuristics
($\cgo$: $36\rightarrow $ \textbf{50}, 
 $\ceo$: $39\rightarrow $ \textbf{48}, 
 $\ffo$: $54\rightarrow $ \textbf{93}). This is reasonable
because lazy search forces each node to derive the heuristic value from
its parent, and it makes more nodes to have the same heuristic value,
increasing the size of a plateau.

% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-gbfs}
%  \caption{
%  Coverages under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo last-resort
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  (g): GBFS with $[\hh]$ sorting criteria.
%  (G): GBFS with depth based diversification $[\hh,\depth]$.
%  }
%  \label{tbl:gbfs}
% \end{table}

% We also tested each combination on Type-GBFS, a recent \sota enhancement
% to GBFS. The results in \reftbl{tbl:type-gbfs} show that the depth
% metric also improves the performance of these configurations. Furthermore, we tested LAMA and
% Type-LAMA with and without depth metric. LAMA is an old \sota
% satisficing planner combining various satisficing enhancements such as
% Lazy-evaluation, distance-to-go estimates, multi-heuristic search and
% preferred operator queues. Type-LAMA is a newer \sota planner and an
% extension of LAMA using Type-GBFS, and it has performed the best among non-portfolio
% planners in IPC8 satisficing track. In \reftbl{tbl:lama}, we observed
% that the depth metric also improved the performance of LAMA and Type-LAMA.
% 
% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-type-gbfs}
%  \caption{
%  Coverages of Type-GBFS under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo last-resort
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  In each expansion, Type-GBFS alternates standard GBFS and Type-based exploration using $[g,\hh]$.
%  The sorting criteria of the GBFS part of (gt) is $[\hh]$, while (Gt) uses $[\hh,\depth]$.
%  }
%  \label{tbl:type-gbfs}
% \end{table}
% 
% \begin{table}[htbp]
%  % \setlength{\tabcolsep}{0.1em}
%  \centering
%  \input{tables/9-lama}
%  
%  \caption{ Coverages of satisficing planners LAMA (winner of IPC7, old \sota)
%  and Type-LAMA (non-portfolio winner of IPC8, newer \sota) under 5 min, 4GB
%  experiments, comparing the performance between the original and the
%  depth-enhanced variants. All configurations run the first GBFS
%  iteration only, apply \fifo last-resort tiebreaking (we omit it from
%  the description below), apply lazy evaluation and use distance-to-go synergy
%  heuristics $\ffo / \hat{h}^{\text{LMcount}}$.
%  % 
%  LAMA alternates between four OPEN lists: an open list of $[\ffo]$, a
%  preferred operator queue of $\ffo$, an open list of
%  $[\hat{h}^{\text{LMcount}}]$, and a preferred operator queue of
%  $\hat{h}^{\text{LMcount}}$.  In contrast, Type-LAMA alternates
%  between five OPEN lists: In addition to the 4 queues in LAMA, it has a
%  type-based exploration queue using $[g,\ffo]$.  The depth is applied
%  only to the first queue, i.e. $[\ffo] \rightarrow [\ffo,\depth]$, and
%  is not applied to the other queues. In both LAMA and Type-LAMA, depth
%  metric improves the coverage.}
%  \label{tbl:lama}
% \end{table}

In the past, optimizing search
techniques and satisficing search
techniques used to be
developed rather separately. However,
these results open up a new opportunity to break the boundary between
optimal search and satisficing search. In fact, inspired by the new
view that \textbf{optimal search is a sequence of satisficing
search}, we successfully imported the optimal search technique
(depth-based diversification) to the satisficing search, and vise versa
(use of $\ffo$ heuristics in optimal search).
There is a large avenue for future work in 
intermixing more techniques in the two diverged fields.
