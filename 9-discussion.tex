\clearpage 
\section{Discussion}
\label{sec:discussion}

One observation that can be made from the experiments in the previous sections is that \textbf{optimizing search
can be seen as a series of satisficing searches on each plateau}. In this view, the problem of tiebreaking can be
reduced to a satisficing search.

Our notion of \emph{admissible sorting strategy} dictates that the
search within the same $f$ plateau can be an arbitrary satisfiable search. For example,
if we ignore the first sorting criterion in the standard admissible strategy
$[f,h,\fifo]$, we get $[h,\fifo]$, which is exactly
the same configuration as a GBFS using \fifo default tiebreaking. It
means that within the plateau of the same $f$, $[f,h,\fifo]$ is
performing a satisficing GBFS.
As another example, the reason for the poor performance of $[f,\fifo]$
is clearly that it is running $[\fifo]$,
a pure satisficing breadth-first search, in the plateau.
Furthermore, the good performance of $[f^{\lmcut},\ffo,\fifo]$ is also clear:
If we ignore the first sorting criterion, it is a GBFS with $[\ffo,\fifo]$,
and $\ffo$ is by itself known to be a \sota inadmissible heuristic
function for satisficing forward search.

Similar concept is common in SAT/IP model-based sequential / temporal planning
\cite{rintanen2012planning,van2005optiplan}, but in a slightly different sense.  In model-based planning, a
planning problem is converted to a corresponding constraint satisfaction problem with a finite horizon $t$ (plan
length / makespan). The search starts from the horizon 0 and tests if the problem is satisfiable. If not, then it
increases the horizon and retests the same problem with additional constraints for a new horizon $t+1$. In the
forward heuristic search such as \astar, the concept of horizon corresponds to the $f$ value, which is a lower
bound of the solution cost.

The key difference in the \astar-based optimal planning from the model-based planning is
that the information is transmitted between different horizons:
In \astar, nodes that are generated in the smaller
$f$ layer will be ``sent'' to the larger $f$ layer through the global OPEN
list, while the current model-based methods prove the satisfiability of
different horizons independently -- in each iteration of the search,
they have to generate a new instance of a SAT/IP problem, and the
underlying model-based solvers are forced to start the search from the scratch.

More precisely, each iteration of \astar only requires to test the satisfiability in the space of particular
$f$ while each iteration of model-based solvers tests the satisfiability in the space of all nodes $0<f(n)<t$
($t$ is a horizon).  This latter behavior also connects model-based approaches to Iterative Deepening \astar
\cite{korf1985depth} where the search is restarted from the scratch on each iteration, forgetting the past search
effort in order to ensure the linear space usage.
% 
\todo*{A more standard interpretation of the connectin between SAT/IP/CSP planning vs A* is that SAT/IP/CSP are
doing iterated deepening, where each iteration seeks a satisficing solution, like IDA*. }
% 
\todo*{In fact, exploring the application of ``IDA* = series of satisficing seraches'' seems like an interesting
direction for future work, e.g., how to simulate depth-based tiebreaking (node ordering) in IDA*? IDA* is useful
for domains where memory limitations are the bottleneck, so keeping the depth buckets in memory may not be
possible. More broadly, linear space, best-first search including RBFS}

This entire view shows an interesting direction for future work.
Although we evaluated only one \sota satisficing configuration $\ffo$ in
the experiments, it does not preclude the possibility of applying yet
more variety of satisficing planning techniques to optimal search, such as lazy-evaluation
or preferred operators in LAMA, depth-first probe in Probe \cite{LipovetzkyG11}, or
random-walk strategy in Arvand \cite{nakhost2009monte}, or Type-based
exploration in Type-GBFS \cite{xie14type}.
% Future work on this direction should be evaluated in the context of
% future International Planning Competitions.

\subsection{Depth Diversification for Satisficing Search}

However, how promising is this view, or hypothesis, actually? In order to give more soundness to this future
direction, we conducted another set of experiments. In the previous experiments, we showed that the distance-to-go
\ff heuristic $\ffo$ for \textbf{satisficing search within a plateau} was improved by the depth diversification
$\depth$.
% 
A natural extension to this idea is that the depth metric can also enhance the performance of $\ffo$ used for
\textbf{satisficing search in general}.
% 
Our claim is that this \emph{should} work if our observation is correct, and if it is, it becomes another
testimonial that our future direction (importing satisficing techniques to optimal search) is promising.
This is different from a simple claim like ``X worked in optimizing search, so it should also work in satisficing search''.
\todo*{``exporting from optimizing to satisficing'' and ``exporting from satisficing to optimizing'' are not symmetric. The latter is interesting and surprising, the former, not so much. --- changed the tone, emphasized the purpose}

We provide preliminary results on the 280 IPC8 satisficing track
instances. We tested GBFS using the distance-to-go variations of three
\sota inadmissible heuristics for satisficing search: FF heuristics
 \cite{Hoffmann01}, Causal Graph (CG) heuristics \cite{Helmert2006} and
Context Enhanced Additive (CEA) heuristics\ \cite{helmert2008unifying}.
For each heuristics, we tested eager and lazy search, with and without
the depth metric.  Tests are conducted under 5 min, 4GB
resource constraint.

In Eager search, depth metric
improved the performance of $\cgo$ ($60\rightarrow $ \textbf{64}), but no
improvement was observed in $\ceo$ ($62\rightarrow 62$)
and $\ffo$ ($73\rightarrow 73$). In Lazy search, depth metric
improved the performance of all three heuristics
($\cgo$: $36\rightarrow $ \textbf{50}, 
 $\ceo$: $39\rightarrow $ \textbf{48}, 
 $\ffo$: $54\rightarrow $ \textbf{93}). This is reasonable
because lazy search forces each node to derive the heuristic value from
its parent, and it makes more nodes to have the same heuristic value,
increasing the size of a plateau.

% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-gbfs}
%  \caption{
%  Coverages under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo default
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  (g): GBFS with $[\hh]$ sorting strategy.
%  (G): GBFS with depth based diversification $[\hh,\depth]$.
%  }
%  \label{tbl:gbfs}
% \end{table}

% We also tested each combination on Type-GBFS, a recent \sota enhancement
% to GBFS. The results in \reftbl{tbl:type-gbfs} show that the depth
% metric also improves the performance of these configurations. Furthermore, we tested LAMA and
% Type-LAMA with and without depth metric. LAMA is an old \sota
% satisficing planner combining various satisficing enhancements such as
% Lazy-evaluation, distance-to-go estimates, multi-heuristic search and
% preferred operator queues. Type-LAMA is a newer \sota planner and an
% extension of LAMA using Type-GBFS, and it has performed the best among non-portfolio
% planners in IPC8 satisficing track. In \reftbl{tbl:lama}, we observed
% that the depth metric also improved the performance of LAMA and Type-LAMA.
% 
% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-type-gbfs}
%  \caption{
%  Coverages of Type-GBFS under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo default
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  In each expansion, Type-GBFS alternates standard GBFS and Type-based exploration using $[g,\hh]$.
%  The sorting strategy of the GBFS part of (gt) is $[\hh]$, while (Gt) uses $[\hh,\depth]$.
%  }
%  \label{tbl:type-gbfs}
% \end{table}
% 
% \begin{table}[htbp]
%  % \setlength{\tabcolsep}{0.1em}
%  \centering
%  \input{tables/9-lama}
%  
%  \caption{ Coverages of satisficing planners LAMA (winner of IPC7, old \sota)
%  and Type-LAMA (non-portfolio winner of IPC8, newer \sota) under 5 min, 4GB
%  experiments, comparing the performance between the original and the
%  depth-enhanced variants. All configurations run the first GBFS
%  iteration only, apply \fifo default tiebreaking (we omit it from
%  the description below), apply lazy evaluation and use distance-to-go synergy
%  heuristics $\ffo / \hat{h}^{\text{LMcount}}$.
%  % 
%  LAMA alternates between four OPEN lists: an open list of $[\ffo]$, a
%  preferred operator queue of $\ffo$, an open list of
%  $[\hat{h}^{\text{LMcount}}]$, and a preferred operator queue of
%  $\hat{h}^{\text{LMcount}}$.  In contrast, Type-LAMA alternates
%  between five OPEN lists: In addition to the 4 queues in LAMA, it has a
%  type-based exploration queue using $[g,\ffo]$.  The depth is applied
%  only to the first queue, i.e. $[\ffo] \rightarrow [\ffo,\depth]$, and
%  is not applied to the other queues. In both LAMA and Type-LAMA, depth
%  metric improves the coverage.}
%  \label{tbl:lama}
% \end{table}

In the past, optimizing search techniques and satisficing search techniques used to be developed rather separately, and there have been only a handful of knowledge migration between them, most of which are abstract ideas such as delete-relaxation, landmarks, causal graphs or pattern database.
Otherwise, the migration is unidirectional, in particular from optimizing to satisficing search, because it is easy or trivial to relax the optimality requirements.
% 
Our results and the new observation, \textbf{optimal search is a sequence of satisficing searches on each plateau},
open up a new opportunity to break this boundary.  We provided the fundamentals of how and why we can import
satisficing search techniques to the optimizing search (e.g. $\ffo$ heuristics in optimal search).  There is a
large avenue for future work in making a migration happen in this novel direction.

