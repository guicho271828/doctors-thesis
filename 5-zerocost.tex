\section{Domains with 0-Cost Actions}
\label{sec:zerocost-domains}
%% best to put openstacks here, considering the connection to the
%% previous section
\pddl{Openstacks}  is a cost
minimization domain introduced in IPC-2006, where the objective is to 
minimize the number of stacks used.
One characteristic of \pddl{Openstacks} is the presence of many  actions which have zero cost because they do not increase the number of stacks. These 0-cost actions create the problem depicted in \refig{fig:plateau-1}.
% Since 0-cost actions corresponds to 0-cost search edges.
% If such actions are present, the neighbors of the goal nodes could be surrounded by the 0-cost edges.
Since 0-cost actions (edges) allow ``free'' transitions between many neighboring nodes,
the number of neighboring nodes sharing the same $h$ also becomes quite large.
This creates huge plateaus that share the same $h$-value, and the standard $h$-based tie-breaking criterion can not provide informative guidance for search within a plateau.\todo*{why mention $f=f^*$ specifically here, instead of ``final plateau'' (f*,0) or just in general all plateaus?}

\begin{figure}[htbp]
  \centering
  \includegraphics{img/astar/plateau-1.pdf}
 \caption{Search space of \astar and its contour according to admissible heuristic $h$. (\textbf{Right}) In domains with only positive-cost actions, $h$-based tie-breaking provides meaningful guidance. (\textbf{Left}) In domains with 0-cost actions, applying an action may not increase the cost of the path and the region with $h=0$ could be quite large. With the same mechanism, other heuristic plateaus (e.g. $h=1$) also become larger. Thus, $h$-based tie-breaking fails to provide meaningful guidance in this space.
  }
 \label{fig:plateau-1}
\end{figure}


%% safe to remove these explanation.
% According to \cite{richter2010lama}, \textbf{??????}
% %Richter talks about the failures on openstacks starting around p.167
% \lmcut \cite{Helmert2009} fails to find a good cost
% partitioning with non-zero values, 
% % A detailed discussion of Openstacks domain and poor performance of landmarks is in \cite{richter10lama}, p.167-169.
% and most edges in the abstraction
% space of M\&S \cite{helmert2007flexible} have zero costs.

% XXX I'm commenting out the paragraphs below because:
% (1) A review of heuristic functions for domain-independent learning is not really
% necessary for this AAAI submission. 
% (2) It's better if this paper is not so strongly associated with the ICAPS community only -- this work applies in general to search with A*, and is not strongly tied to almost-perfect heuristics, lmcut, m&s, etc.

Although most traditional benchmark problems in the planning community and the combinatorial search community do not have 0-cost actions,
we argue that such domains are of an important class of models for cost-minimization problems, i.e.,
assigning 0-costs makes sense from a practical, modeling perspective.
For example, consider the \pddl{driverlog} domain, where the task is to move packages between locations using trucks.
The IPC version of this domain assigns unit costs to all actions. Thus, cost-optimal planning on this domain seeks to minimize the number of steps in the plan.
However, another natural objective function would be the one which minimizes the amount of fuel spent by driving the trucks,
assigning cost 0 to all actions except \pddl{drive-truck} -- we believe that for cost-optimal planning, this is at least as natural as the current IPC model of \pddl{driverlog} in which all actions are unit cost.

% While I agree with the point you're trying to make,
% There is an ugly issue when arguing that current models try to  optimize plan-execution time (i.e., makespan), 
% which is that if we really cared about makespan optimality, we would consider parallel execution of actions whenever possible.
% however, sequential classical planners do not handle parallel actions at all  (recall ACP).
% so arguing this path can only lead to trouble.. Let's try a safer line of argument.
%% For runtime minimization,
%% nonzero positive costs are reasonable because
%% every actions are supposed to consume a fraction of time.
%% However, such formulation is not suitable for general optimization
%% problems.  For example, when you try to minimize the energy consumption
%% by the elevators in \pddl{Elevators} domain, many actions would have 0-cost
%% --- it does not consume electricity for either boarding or leaving the
%% passenger, or moving the elevator down.
%% % 
%% From the practical point of
%% view, cost minimization domains would have wider interest compared to
%% the simple runtime minimization.
%% Also, as shown previously, such domains pose a
%% difficulty to the current heuristic planners due to their large plateaus.

Similarly, for many practical applications, a natural objective is to
optimize the usage of one key consumable resource, e.g., fuel/energy
minimization.  In fact, two of the IPC domains, \pddl{Openstacks} and
\pddl{Cybersec}, which were shown to be difficult for standard tie-breaking
methods in the previous section, both contain many 0-cost actions
and are based on industrial applications: %no textbf here because both \pddl{Cybersec} and \pddl{Openstacks} are highly simplified models, let's not exaggerate their importance
\pddl{Openstacks} models
production planning \cite{fink1999applications} and \pddl{Cybersec}
models Behavioral Adversary Modeling System \cite[minimizing decryption,
data transfer, etc.]{boddy2005course}.

In order to create a benchmark set that better addresses practical interest,
in this paper, we modified various standard domains
into cost minimization domains with many 0-cost actions.
Specifically, each of our ``Zerocost domains'' is same as the standard domain except that all action schema are assigned
cost 0 except for a few (usually one) action schema which consumes some key resource.
The suffixes in the names of these domains indicate the actions with non-zero costs, 
%e.g., \pddl{elevator-up} is a modified elevator
%domain where the \pddl{up} action is assigned non-zero cost (because
%elevators are considered to consume energy only when going \pddl{up}), 
% I believe elevators use some energy when going down as well, so let's not highlight this example.
e.g., \pddl{logistics-fuel} is a modified logistics domain where only actions which consume fuel have non-zero cost.
Most of the transportation-type domains are modified to optimize 
energy usage (\pddl{logistics-fuel}, \pddl{elevator-up} etc.), and  assembly-type domains are modified to minimize resource usage
%% \pddl{floortile-ink} is not shown, so better not to mention it
(\pddl{Woodworking-cut} minimizes wood usage, etc.).
When no action makes sense from practical point of view, we chose an action schema arbitrarily (e.g. \pddl{mprime-succumb}).
We did not
include domains which have only a single action schema, or which already had many 0-cost actions.

We refer to such 28 new domains as \emph{Zerocost domains}.
In detail, they are:
\pddl{airport-fuel} (20), \pddl{blocks-stack} (20), \pddl{depot-fuel} (22), \pddl{driverlog-fuel} (20),
\pddl{elevators-up} (20), \pddl{floortile-ink} (20), \pddl{freecell-move} (20), \pddl{grid-fuel} (5),
\pddl{gripper-move} (20), \pddl{hiking-fuel} (20), \pddl{logistics00-fuel} (28), \pddl{miconic-up} (30),
\pddl{mprime-succumb} (35), \pddl{mystery-feast} (20), \pddl{nomystery-fuel} (20),
\pddl{parking-movecc} (20), \pddl{pathways-fuel} (30), \pddl{pipesnt-pushstart} (20),
\pddl{pipesworld-pushend} (20), \pddl{psr-small-open} (20), \pddl{rovers-fuel} (40),
\pddl{scanalyzer-analyze} (20), \pddl{sokoban-pushgoal} (20), \pddl{storage-lift} (20),
\pddl{tidybot-motion} (20), \pddl{tpp-fuel} (30), \pddl{woodworking-cut} (20),
\pddl{zenotravel-fuel} (20).

While the action costs in the PDDL \emph{domain} definitions are modified,
we did not modified the PDDL \emph{problem} definitions.
Although some domains (specifically, \pddl{blocks}, \pddl{freecell}, \pddl{pipesworld-notankage}, \pddl{miconic}) have fewer instances than the original domain does,
their problem definitions are the evenly sampled subset of the original set of instances.
% \pddl{blocks} original 35 vs 20, \pddl{freecell} 80 vs 20, pipesnt 50 vs 20, \pddl{miconic} 150 vs 30
For example, the original \pddl{miconic} domain has 150 instances, while our version has 30 instances.
These 30 instances are selected evenly from the original set of instances, by picking instances p05, p10, ... p150.
% 
The aim of reducing the number of instances is to avoid the problem of the overall coverage sums being skewed by the domains with a larger number of instances.
Thus, we did not modified the problem definitions at all, only modifying the action costs described in the domain definitions.

\subsection{Difference in Problem Characteristics between IPC and Zerocost Domains}

Domains containing 0-cost operators are known to be difficult for traditional planners \cite{thayer2009using,cushing2010cost,wilt2011cost,thayer2011bounded,richter2011lama}.
Both \citeauthor{cushing2010cost} \citeyear{cushing2010cost} and \citeauthor{wilt2011cost} \citeyear{wilt2011cost} discussed the large ratio between maximum and minimum operator costs can pose challenge to existing planners. However, the common conclusion is the use of plan-length heuristics instead of plan-cost heuristics, which harm the optimality of the solution. The use of plan length heuristics is further discussed in \refsec{sec:distance-to-go}.

While above literature also show some theories on the origin of difficulties, \citeauthor{aghighi2015} \citeyear{aghighi2015,aghighi2016} fully complemented the full theory behind this, using the parameterized complexity analysis of planning domains. It is shown % can't extrapolate too strongly from problem class complexity results to specific instances 
that domains with 0-cost operators form another complexity class that is harder (para-\textbf{NP}-hard) than the domains with strictly positive-cost operators (\textbf{W}[2] complete).
This indicates the inherent difficulty of optimally solving planning problems with 0-cost actions.

Thus it is expected that there would be significant practical performance differences when a domain independent planner solves the original IPC instances and our Zerocost instances.
To our knowledge, an empirical study on such differences over wide range of IPC domains is missing in the literature, while their evaluation took place mainly on % a few %% insulting
puzzle domains: Grid Path Planning, Blastlands, Zenotravel \cite{thayer2009using}, Zenotravel \cite{cushing2010cost}, Sliding Puzzle, Pancake Puzzle, Sliding Puzzle \cite{wilt2011cost}, Dock Robot, Vacuum World, Robot Navigation, Sliding Puzzle\cite{thayer2011bounded}.

Therefore we tested if Zerocost domains actually pose a new challenge to the
standard tie-breaking strategies through experiments. Results using \lmcut and \mands
heuristics are shown in \reftbl{tbl:lmcut-zerocost-std} and
\reftbl{tbl:mands-zerocost-std} (Appendix), respectively. In each table,
the left-hand side shows the results in the original domains, and the right-hand side
shows the Zerocost domains modified from the same
instances on the left-hand side. We excluded domains whose
number of instances in the standard domain differs from the number of instances in the 0-cost version.

For both \lmcut and \mands heuristics, we observed a significant
performance difference between the original IPC domains and the Zerocost
domains. With \lmcut, the coverage in Zerocost domains
was lower in 11 domains while more instances were solved
in 5 domains. With \mands, the coverage in Zerocost domains was lower in 10 domains while
more instances were solved in 3 domains.
\todo*{Can we consolidate the lmcut table mands table comparing the 0-cost vs standard domains?  Doesn't seem important enough for 2 tables --- not critical}
The coverage increase in some domains is not surprising, considering that 0-cost actions also make some suboptimal paths into cost-optimal paths. However, the coverage decreased overall, supporting the literature.

\refig{fig:plateau-zerocost} plots the size of the final plateau of the
Zerocost instances, with \lmcut heuristics and $h$ tie-breaking. In this plot,
each point shows the total number of nodes in $\plateau{f^*,0}$ vs the
total number of nodes with $f\leq f^*$. Compared to \refig{fig:plateau},
most Zerocost instances have larger plateaus even with the help of
$h$ tie-breaking.  Thus, in these cost-minimization problems, the search
strategy within plateaus, i.e., tie-breaking, becomes even more critical
in determining search performance.

% summary data ?

\begin{table}[htbp]
 \centering
 \input{tables/5-std-zero-comparison-lmcut}
 \caption{
 Assessment of the relative difficulty of Zerocost domains vs. their corresponding standard domains, for the standard $[f,h,\fifo]$ strategy.
 Coverage comparison (the number of instances solved) 
 between the original IPC domains and the modified Zerocost domains are shown, 
 using the same planner configuration and experimental setting (5min, 4GB, \lmcut heuristics).
 This table does not include domains where the total number of instances
 in the Zerocost domain  and the original domain differ. 
 }
 \label{tbl:lmcut-zerocost-std}
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics{tables/aaai16-frontier/zerocost/lmcut_frontier-front.pdf}
  \caption{
 The number of nodes in $\plateau{f^*, 0}$ (y-axis), which form
  the final plateau under $h$-based tie-breaking, compared to
 the total number of nodes in the search space (x-axis) with
 $f\leq f^*$ on 620 instances in our \emph{Zerocost domains}.
 The size of final plateaus tends to account for larger portion of the
 entire search space compared to \refig{fig:plateau}.
 This statistics is obtained by running a modified Fast Downward with
 \lmcut which continues searching after the solution is found
 until expanding all nodes with cost $f=f^*$.
 }
 \label{fig:plateau-zerocost}
\end{figure}

\subsection{Discussion on Zerocost Domains}

Note that the difficulty posed by these domains sometimes \emph{cannot}
be tackled by improving the heuristic estimates, or reducing the
underestimation of an admissible heuristic function.  Due to the
existence of 0-cost edges, some non-goal neighbors of a goal node 
% admissibly 
have $h^*=0$. For those nodes,
there is clearly no room for improving the heuristic estimate; Any positive
value causes the heuristics to be inadmissible.
Thus it would be safe to say that this is another instance that
``further improvements in run-time require
changes to other parts of the search algorithm than the heuristic estimator''
 \cite{helmert2008good}.

One approach to improving the search performance in such plateaus
produced by 0-cost edges is to perform an efficient
\emph{knowledge-free} search within plateau; It may reuse the effort
that is already spent to guide the search but without requiring 
additional effort to compute multiple heuristics.
In the next section, we propose and evaluate an implementation of
such a technique. It turns out that introducing a notion of \emph{depth} within a plateau can have
a significant impact on the performance of knowledge-free search, and can also 
provide a good  understanding of the behavior of standard tie-breaking strategies.

\subsection{Completeness of Tie-Breaking Strategies on Zerocost Domains}

The presence of 0-cost edges in the search space affects the completeness of tie-breaking strategies for \astar. 
As long as the search graph is finite, \astar is complete regardless of the tie-breaking strategy.
If the search graph is infinite, and the branching factor is finite, then 
\fifo will always return a solution if one exists.

However, some solvable, infinite search graphs with finite branching factors can contain traps for a \lifo tie-breaking policy -- there may be infinite regions of the search space consisting of nodes connected by 0-cost edges which cause \astar with \lifo tie-breaking to endlessly search this region, never returning to another region of the graph which contains a solution.
Note that this holds in general regardless of whether $h$-based tie-breaking is applied prior to $\lifo$ tie-breaking, since all nodes in such a trap would have the same $h$-value of zero if $h$ is admissible.
The randomized, $\ro$ tie-breaking method is probabilistically complete for solvable problems in the presence of such traps -- since $\ro$ will expand nodes outside the trap with some non-zero probability, it will eventually (in the limit) find the solution.

