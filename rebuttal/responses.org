
# C-c C-e latex export

#+TITLE: Responses to Reviewer Comments for JAIR Submission 5249: "Tie-Breaking Strategies for Cost-Optimal Best First Search"
#+DATE: 2016-11-03
#+AUTHOR: 
#+EMAIL: guicho2.71828@gmail.com
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:nil e:t email:nil f:t inline:t num:t p:nil pri:nil stat:t tags:t tasks:t
#+OPTIONS: tex:t latex:t timestamp:t toc:nil todo:t |:t
#+CREATOR: Emacs 24.5.1 (Org mode 8.2.10)
#+DESCRIPTION:
#+EXCLUDE_TAGS: noexport
#+KEYWORDS:
#+LANGUAGE: en
#+SELECT_TAGS: export

#+OPTIONS: texht:nil
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS:
#+LATEX_HEADER: \usepackage[margin=20mm]{geometry}
#+LATEX_HEADER_EXTRA:


First, thanks very much to all of the reviewers for their detailed and helpful comments.
To address the reviewers' comments, we have modified the paper as described below.
# removed because this could be interpreted as a significantly new material/experimental results
# significantly

To reduce the length of the main portion of the paper, we moved many tables to the Appendix, 
eliminated some tables and consolidated some figures.
Now the paper length excluding references and appendix is 39 pages.
The numberings of the sections, figures and tables have changed due to changes made in response to the reviewers' comments.
# ??
In this response, when disambiguation is required, we use [Revised:X] to indicate that we refer to those figures/tables/sections using
the new numbering system and [Original:X] to indicate the numbers in the original submitted manuscript.

* Reviewer 1

**  1) The definition of plateau can be improved.

# [Don't abbreviate the reviewer's comment, as that forces the editor to open the review file and go
# back-and-forth between the response and the review files.  Minimize the editor's work by quoting the entire,
# relevant comment to which we're replying]

#+BEGIN_QUOTE
The definition of plateau can be improved. The formal definition of
a plateau should include a plateau with respect to some cost
functions. So, you have a plateau with respect to f, plateau(f), a
plateau with respect both g and h, plateau(g,h) etc. This should be
defined at the beginning and this terminology should be later used all
over. Currently, you are not fully formal and consistent on this. As
you say on page 18. a plateau is related to a sorting strategy. Define
this in the beginning. In fact you write the following sentence which
is in fact a definition: "Having the same key values means that n and
m are on the same plateau". Move this to be a definition in one of the
first sections."
#+END_QUOTE

Plateaus are formally defined in the 2nd-to-last paragraph of Section 2, Preliminaries.
However, as the reviewer noted, there were some informal usages of the term "plateau" throughout the paper.
In the revision, we increased the usage of the more precise notation "plateau(f,h)" throughout the paper.

** 2) page 18: "In order to diversify the expansion... " --> This paragraph is very hard to understand

#+BEGIN_QUOTE
page 18: "In order to diversify the expansion... " --> This
paragraph is very hard to understand but it is a very important
paragraph as it gives the pseudo code for your new technique. Please
rewrite it. What is Dc? Is this a counter? Is there one Dc or one for
each depth? Please clarify. Maybe even give an example.

page 20: "round-robin sampling from the available depth buckets as
described above." --> This is a key sentence that might help
understanding what exactly is the diversifying method. I think you
mean you that do a round robin from the deepest available depth to the
shallowest available depth. You must clarify this.
#+END_QUOTE

We rewrote the description and added the pseudocode (Algorithm 2) for depth diversification
in Section [Original:6,Revised:5].
d_c is a counter assigned to each plateau.

** 3) It will be very interesting to see what happens if you factor away the constant time per node.

#+BEGIN_QUOTE
page 22: Table 7.5. It will be very interesting to see what
happens if you factor away the constant time per node. Just compare
the number of nodes expanded for a set of instances that can be solved
by all methods (as you did in the 4.1-4.5 tables). This will tell you
if indeed this is the reason for the negative behavior. This is a
rather major comment. You do not always have to use the 30 minutes
limit in your experiments.
#+END_QUOTE

Thanks for the suggestion. In order to factor away the constant low-level overhead of depth bucket management
which degrades the performance of M&S on IPC domains,
we compared the number of node evaluations between the depth-diversified and standard search method.
We added Figure [Revised:6.2] comparing the cumulative coverage over the number of evaluations.
This shows that the evaluations are almost identical for most IPC instances, meaning that search efficiency in positive cost domains was largely unaffected by depth diversification, as expected.
There were differences in Openstacks (this is also expected since Openstacks has zero-cost actions).

** 4) Section 5: Zerocost domains. I buy all your arguments on zero cost

#+BEGIN_QUOTE
Section 5: Zerocost domains. I buy all your arguments on zero cost
domains. You spend too much effort to validate them. I suggest to
shorten this entire section and the related tables. All your claims
seem reasonable and you do not have to necessarily show all the
numbers.
#+END_QUOTE

As suggested, we shortened Section [Original:5,Revised:4].
We also removed Table [Original:5.2].
(Same results can still be extracted from the other tables in the appendix. See [[R3Q5]] also.)

**  4)  The claims about FIFO in infinite graphs (section 5.3) is trivial.

#+BEGIN_QUOTE
The claims about FIFO in infinite graphs (section 5.3) is trivial. You can shorten it or even delete it.
#+END_QUOTE

In the revised version, we moved the section [Original:5.3] to the end of Section [Original:8,Revised:7],
where it fits better (using the A*-as-sequence-of-SAT framework).

In response to item [[R2Q3]] below from Reviewer 2, 
we formalized some additional completeness results on infinite graphs,
which was also added to this revised section [Original:5.3,Revised7.2].

# Although the proofs are still mostly trivial, the new section improves the flow of the story
# and strengthen the significance of A*-as-sequence-of-SAT.

# Although the completeness material definitely fits better in the new location, 
# the submitted section 5.3 didn't say or imply that 0-cost edges
# induces infinite search spaces, and I don't see any reviewer comment which suggests the
# reviewers thought we made any such claim, so let's not go out of our
# way to mention this (it just makes us look bad).

# It is no longer in section [Original:5,Revised:4] because we noticed that
# infinite search space is irrelevant to having 0-cost edges. 
# We had/gave false impression that 0-cost edges induces an infinite graph, which is not the case.
# Trivially, just changing the cost of edges does not make finite graphs infinite.
# None of our experiments include infinite search space,

# None of our experiments include infinite search space,


** 5) Section 6.1 is trivial.

#+BEGIN_QUOTE
Section 6.1 is trivial. It is easy to see that different "depth"
values only occur in zero domains. I would shorten it or even omit it.
#+END_QUOTE

We formalized and significantly shortened the proof (Theorem 1),
and Section [Original:6.1] has been folded into Section [Revised:5].

** 6) Section 7.1: this section repeats what you said above and ...

#+BEGIN_QUOTE
Section 7.1: this section repeats what you said above and I was
convinced when you said it. You can just report that you observed this
in your experiments and I do not need to see all the exact results.
Consider to omit these experiments and just mention that you have
results that support this trend.
#+END_QUOTE

We moved several non-critical figures [Original:7.3,7.4,7.6] to the appendix: Figures [Revised:A.2,A.3,A.4].
Also, we shorten the text by removing the list improved domains.

** 7) The beginning of Section 8 is also rather trivial.

#+BEGIN_QUOTE
The beginning of Section 8 is also rather trivial. This is the main
rational behind IDA* as you say in the end. I would significantly
shorten it but it should get a subsection index if it stays. It is not
an introduction to your later section 8.1 which I find quite
interesting and more deep and should certainly be kept.
#+END_QUOTE

We shortened the beginning of Section [Original:8,Revised:7],
compared "A*-as-series-of-satisficing-search" to IDA*
and added a paragraph connecting this section
better as an introduction to subsection [Original:8.1,Revised:7.1,7.2].

** minor comments)                                                  :noexport:

We all changed the points being mentioned. Thank you very much.

** minor 1) -- should be "current shortest known path"

#+BEGIN_QUOTE
page 4: "g(n) is the current shortest path cost from the initial node
to the current node." -- should be "current shortest known path"
#+END_QUOTE

Fixed.

** minor 2) -- I did not like this syntax. Give the reference and...

#+BEGIN_QUOTE
page 5: "Holte, 2010, note that since f = g+h....) I did not like this
syntax. Give the reference and then give your comment but not in the
same parenthesis.
#+END_QUOTE

Fixed as suggested.

** minor 3) -- Calling it the  third is misleading...

#+BEGIN_QUOTE
page 21: "the third, depth-diversification criteria." Calling it the
third is misleading. It is actually the second which comes before the
default criterion.
#+END_QUOTE

Depth Diversification is the third strategy
in a sorting strategy [f,h,<d>,*] we used in the experiments.
Instead, we fixed the part "h as the first-level tiebreaking criterion"
into "h as the second-level sorting criterion".

** minor 4) -- The first sections are very short. Maybe they can be one large section...

#+BEGIN_QUOTE
The first sections are very short. Maybe they can be one large section
with different subsections.
#+END_QUOTE

We merged section [Original:2] and [Original:3] into section [Revised:2],

** TODO minor 5) -- Indeed distance-to-go is a term that was used by other... :noexport:

#+BEGIN_QUOTE
Section 9. Indeed distance-to-go is a term that was used by other and
coined Ruml et al. which should be cited and credited for that. But I
think the correct term should be something like
"number-of-hops-to-go". Distance is ambiguous.
#+END_QUOTE

?? Fixed as you suggested.

* Reviewer 2

** 1) Maxim Likhachev's ARA* paper...

#+BEGIN_QUOTE
 Maxim Likhachev's ARA* paper presents an elegant solution to
avoid the final plateau problem for non zero-cost domains. His
algorithm notes the cost of the goal, whenever a new path to goal is
discovered, and concludes the search when the minimum cost of any
state in OPEN becomes greater than or equal to the current goal cost
(f = f*). While this approach is not applicable for 0-cost domains, I
think this merits a discussion and probable inclusion of results in
case of other domains used.
#+END_QUOTE

We added a paragraph describing the relationship to ARA* in Related Work (Section [Original:10,Revised:9]).

ARA* could largely avoid the problem of final plateau if the previous suboptimal searches happen to
have found the optimal solution already (and thus pruning most nodes on f=f*). 
However, ARA* is based on an iterated anytime framework, whereas our work is based on the standard (A*) admissible search.
We point out this difference.


** 2) the amount of data is a bit too much...

#+BEGIN_QUOTE
 While I appreciate the in-depth experimental investigation
presented in this work, i think the amount of data is a bit too much.
For example, 26 plots for number of nodes vs depth is rather
confusing. I like the summarization done for most tables, which points
to the key take-aways. I think the experimental results should be
presented in a more compact fashion, and if needed the detailed
results can be pushed to an appendix (even there, i believe some
compaction will be good). This will also help to reduce the length of
the paper. Currently, it seems too long for the content.
#+END_QUOTE

We moved many tables and plots to the appendix, so the length of the main portion of the paper has been reduced to 37 pages (excluding references and appendix).

** <<R2Q3>> 3) the theory and analysis part... Section 5.3

#+BEGIN_QUOTE
 While the paper presents experimental results in detail, the theory
and analysis part looks weak in my opinion. Most of the analytical
results are presented in an informal manner. For example, 5.3
discusses the completeness of search strategies on ZeroCost domains. I
would suggest that such results should be presented using formal
statements with proofs.
#+END_QUOTE

We moved Section [Original:5.3]
to the end of Section [Original:8,Revised:7] and added more formal statements regarding the completeness 
on infinite graphs. This material was moved because the analysis is most natural 
using the A*-as-sequence-of-SAT framework introduced in Section [Revised:7].

# same as for [1.4b] above, let's not talk about our confusion :-)

# It is no longer in section [Original:5,Revised:4] because we noticed that
# infinite search space is irrelevant to having 0-cost edges.
# We had/gave a false impression that 0-cost edges induces an infinite graph, which is not the case.
# Trivially, just changing the cost of edges does not make finite graphs infinite.
# None of our experiments include infinite search space,

# Still, the new theorems/proofs prove both pedagogical and practical usefullness of the idea
# in Section 8.

** 3) the theory and analysis part... Section 6.1

#+BEGIN_QUOTE
Similarly, the analysis in 6.1 can be more
precise, results in 6.1 can be presented in terms of theorems.
#+END_QUOTE

We have formalized the result (Theorem 1) and made it more precise.

** 4) Sec6, "more nodes will tend to have shallower depth" vs disjoint forest model

#+BEGIN_QUOTE
 In the last paragraph of section 6, it is stated that "more nodes
will tend to have shallower depth than deeper depth" whereas the
analysis in 6.3 assumes a disjoint forest model which i guess
increases the number of nodes with depth. These two assumptions seems
to be in contrast to each other. I think a more formal treatment of
the analysis can allay such confusions for a reader.
#+END_QUOTE

To clarify: According to the /no-exhaustion assumption/ , no depth bucket exhausts due to the expansion.
This implies that there are a sufficiently large number of nodes in depth $d=0$ so that
 depth 0 does not exhaust as a result of expansion.
If FIFO default tiebreaking is used,
it tries to expand all those nodes with depth 0 before expanding any nodes in depth d >= 1.
A similar situation happens at every depth.
Thus, even if the entire graph is a forest model, FIFO causes a heavy bias to expanding nodes with shallow depth.

It's true that there are surely more nodes with larger depth if /all/ nodes in the entire plateau are expanded, which is the case for $f<f^*$.
However, in the final plateau of A*, FIFO expands only a fraction of nodes with depth $d\leq d^*$,
where $d^*$ is the /minimum solution depth/, the smallest depth of the solutions.
Entire nodes above the solution depths ($d>d^*$) are not expanded due to the breadth-first behavior.
During this process, the expanded nodes are biased to the shallower region.
# with a reasonably good heuristic, A* expands only a small fraction of nodes in the search space, and the nodes expanded by A* during the search process are biased to the shallower region 

# In practice,
# the nodes with depth 0 are the nodes that were generated as a result of expanding earlier plateaus,
# i.e. the entire set of frontier nodes which is sufficiently large for FIFO
# to cause pathological behavior.

This has been clarified in the text (Section [Revised:5.2]), and 
for further clarity, we also added Figures 5.2 and 5.3 which illustrate the scenarios.


** 5) I think it will be helpful if the authors include pseudocodes for...

#+BEGIN_QUOTE
 All the strategies proposed are explained in text only. I think it
will be helpful if the authors include pseudocodes for their
algorithms. In fact, i think it will be helpful if the authors present
a basic A* algorithm with default tie-breaking and build upon that for
their strategies. It will create a nice flow in my opinion, and use of
pseudocode will also remove any chance of mis-interpreting the
strategies.
#+END_QUOTE

As suggested, we added pseudo-code for  Best-First search (Algorithm 1), and depth-based tiebreaking (Algorithm 2).


** 6) state/prove the properties of each of these algorithms, especially important ones like completeness

#+BEGIN_QUOTE
 Tied to point 6, i think it would be good to state/prove the
properties of each of these algorithms/strategies, especially
important ones like completeness. The current format leaves a lot of
un-answered questions like does depth-diversification ensure
completeness (for infinite spaces). The answers may be obvious in many
cases, however, i would still prefer if they are explicitly
stated/proved.
#+END_QUOTE

We proved the completeness and its conditions as requested in Section [Revised:8] (See also the response to Question [[R2Q3]]).

** 7) I like the idea of representing A* as a series of satisficing search. Here also, i would suggest inclusion of pseudocode.

#+BEGIN_QUOTE
 I like the idea of representing A* as a series of satisficing
search. Here also, i would suggest inclusion of pseudocode. For
example, A* exhausts an f-plateau before moving on to the next one.
While this is expressed in text, highlighting such properties through
pseudocode may improve a reader's understanding. Similar to earlier
cases, here also the authors can start with a basic pseudocode (for A*
as a series of satisficing searches), and present their strategies on
top of that with formal discussion about the properties.
#+END_QUOTE

Added pseudo code of A*-as-sequence-of-SAT-search, as you suggested.

** 8) distribution of goal depth in the final frontier

#+BEGIN_QUOTE
 I think it will be interesting to find out what is distribution of
goal depth in the final frontier. I believe there will be a strong
correlation between the goal depth and the relative performance of the
strategies (which the authors mention), and it would be good to
analyze this statistically. Similarly, for strategies in section 9, it
would be interesting to find out the correlation between the
performance of different strategies with the accuracy of the
distance-to-go estimates.
#+END_QUOTE

# this is a good set of suggestions, but is a lot of work.
# fortunately, R2 doesn't say we "must" or "should" do these. He just says "would be interesting", "would be good",
# which can usually be safely interpreted as constructive suggestions rather than demands for addition.

We agree that goal depth distribution
and distance-to-goal heuristic accuracy might be strongly correlated with tie-breaking strategy performance.
This poses interesting avenues for future work, 
and may be very useful, for example, in an extension of this work which 
seeks to automatically select a tie-breaking strategy.  
# this may not be the best example, but I'm trying to suggest "future work"  which is a sizable chunk of work where the reviewer's suggested experiments might fit (but is obviously out of scope for this paper, thus we don't have to do the suggested experiments for this paper)
Thanks for these suggestions. 


** 9) Finally, I think it would be nice if we have some infinite spaces in the ZeroCost domains

#+BEGIN_QUOTE
 Finally, I think it would be nice if we have some infinite spaces
in the ZeroCost domains, and understand the impact of different
strategies on them. My hunch is that in many cases people use
fifo/breadth-first exploration to avoid completeness problems, i
believe inclusion of such graphs (or some domains that closely
approximate such behavior) will enhance the analysis.
#+END_QUOTE


# again as with R2.8, he only says "would be nice"..."will enhance", so these can just be 
# taken as helpful comments, not demands for change.
# This comment doesn't any negative connotation -- he doesn't say lack of infinite space experiments is a weakness of the paper. Therefore,  no need to be too defensive, and better to point out that it's out of scope

In this paper, we focused on domain-independent planning in the classical planning framework (specifically, in the STRIPS/SAS+ framework), for which the search spaces are finite.
Zerocost domains were created as variations of standard IPC benchmarks (which are all in this finite-space framework).

Empirical evaluation of tie-breaking strategies on infinite search
spaces is an interesting avenue for future work, but 
since infinite search spaces are beyond the scope of classical planning, this will require
careful design of interesting/practical benchmark domains and solvers.

We agree that completeness can be one good reason for choosing a  fifo tie-breaking strategy.
However, in our survey of papers mentioning tie-breaking strategies, we couldn't find any work 
which specifically mentioned fifo tie-breaking and also handled infinite spaces -- 
the use of fifo which we cite in the paper is by Fast Downward, a classical planner, and as mentioned above, 
infinite search spaces are beyond the scope of the standard classical planning framework, so it's unlikely that the use of FIFO
tie-breaking in FD was motivated by completeness concerns.


** minor comments

#+BEGIN_QUOTE
 I think the abstract needs to be re-written to precisely state the
contribution. In particular i would suggest changing the sentences
after "With this in mind, ..". Somehow it seems that the depth
diversification is the second strategy, which is not the case.
#+END_QUOTE

As suggested we rewrote the sentences after "With this in mind..." to improve clarity.
#  Not sure whether this really improved clarity, but 
#  "Needs to be written" means  "must comply and rewrite", so...

#+BEGIN_QUOTE
 Also, "We proposes" -> "We propose".
#+END_QUOTE

Fixed.

#+BEGIN_QUOTE
 page 27, claim 1 "A Last-In-First-Out ..". Is this a general claim,
or is it tied to the domains you tested on. I think this should be
made clear.
#+END_QUOTE

# "should be made clear" = "must make clear"
We made clear that it was observed on IPC domains.

#+BEGIN_QUOTE
 Section 2, the 4th paragraph can probably be combined with the
second. Also, may be it would be better if you present exact formal
definitions of the terms.
#+END_QUOTE

We have revised Section 2 to be more precise.
We have also added pseudocode for best-first search (Algorithm 1), which should further clarify the meanings of the terms.
# XXX hope this suffices... didn't really comply with "exact formal defs"

#+BEGIN_QUOTE
 I would suggest that you include some pictorial representation of
your analysis in section 6.3. There are several illustrations of A*
layers in other places that are helpful, some such illustration of
your model would be nice.
#+END_QUOTE

As suggested, we have added Figures 5.2 and 5.3 to clarify the analysis in Section [Original:6.3; Revised:5.2]

#+BEGIN_QUOTE
 There are a number of typos and grammar mistakes, please correct
them. For example, "did not modified" -> "did not modify", "new
current parent" -> "current parent", and others.
#+END_QUOTE

We have rechecked and corrected spelling+grammar.


** TODO 1) I think the abstract needs to be re-written to precisely state the :noexport:
** TODO 2) page 27, claim 1 "A Last-In-First-Out ..". Is this a general claim, :noexport:
** TODO 3) Section 2, the 4th paragraph can probably be combined with the :noexport:
** TODO 4) I would suggest that you include some pictorial representation of :noexport:
** TODO 5) There are a number of typos and grammar mistakes, please correct :noexport:
* Reviewer 3

** 1) There are a large number of colourful scatterplots in the paper, most of which would probably be better presented in a different form.

#+BEGIN_QUOTE
 There are a large number of colourful scatterplots in the paper, most
of which would probably be better presented in a different form. For
example, the data in Figure 1.1 is essentially 1-dimensional: what we
are interested in is the distribution or frequency of ratios between
the size of the final plateau and the search space; a histogram or a
cumulative distribution would show this more clearly. Whether colour-
coding it for domains is useful is questionable; there's only a few
points that can be distinguished well enough to identify what domain
they belong to (and even those do not tell the full story, since there
is no way to see where other instances from the same domain fall).

The data in Figures in 4.1, 4.2, 5.2 and 7.1 would similarly benefit
from a more thought-through visual presentation.
#+END_QUOTE

# give the good news first (say "yes" first)
As suggested, we converted Figure [Original:7.1,Revised:A.1] into histograms
comparing the node evaluation ratio, because this is essentially 1-dimensional data and the domain characteristics are not important
in this figure. Thank you for the suggestion.

# then the bad news..
We also considered converting Figures 1.1, 4.1, 4.2 into histograms as suggested.
However, we concluded that they should remain in the present form, because
the color-coded domain information in Figures [Original:4.1,Revised:3.1] and [Original:4.2,Revised:3.2] are 
important for highlighting the domains which are affected by different default criteria.

We acknowledge that these figures are crowded and it's hard to distinguish
many of the domains/points. However, this was the best compromise of
information-vs-space we could come up with, as providing full,
per-domain data would make this paper even longer.

While the domain information in Figure [Original,Revised:1.1] is less
important, and if it was a completely independent figure, it may be a good idea to convert it to a histogram as suggested.
However, Figure [Original,Revised:1.1] is intended to be contrasted against 
Figure [Original:4.2,Revised:3.2] , and as
explained above, we believe Figure [Original:4.2,Revised:3.2] should
remain in its current format because the domain information is important. 
Thus, we'd like to keep Figure [Original,Revised:1.1] as is.
Similarly, we believe Figure [Original:5.2,Revised:4.2] should remain its current format for the same reason.




** 2) The description in the early part of the paper (Sections 1, 3, 4, 5) somewhat convey the false impression that there has been no previous recognition of the challenge that plateaus can create for A* search

 #+BEGIN_QUOTE
  The description in the early part of the paper (Sections 1, 3, 4, 5)
 somewhat convey the false impression that there has been no previous
 recognition of the challenge that plateaus can create for A* search,
 in particular in the presence of zero cost transitions, or attempts to
 address it. There are a number of relevant related works, for example,
 those by Benton et al., and Cushing et al., which are cited somewhere
 in the paper, but do not appear anywhere in the initial discussion nor
 in the related works section. (The SoCS 2011 paper "Cost-Based
 Heuristic Search Is Sensitive to the Ratio of Operator Costs", by
 Christopher Wilt and Wheeler Ruml, may also be relevant.) This should
 be rectified; the previous state of knowledge should be clearly
 established early in the paper.
 #+END_QUOTE

In Section 1, we added a reference to Benton et al 2010 in Section 1 when 0-cost
actions are first mentioned, noting that these induce the g-value
plateaus which are discussed in the Benton et al 2010 paper.

In Section [Revised:4], when zero-cost domains are motivated and described, 
we added the statement that the huge final plateaus are instances of $g$-value plateaus described by Benton et al 2010.

At the beginning of Section [Revised:4.1], we added references to
works which have mentioned the difficulty of 0-cost domains (Thayer et
al 2009, Cushing et al 2010, Wilt et al 2011, Thayer et al 2011,
Richter et al 2011).
We clarify that previously, the issues of zero cost transitions were not directly associated with 
a failure in tie-breaking. Thus, previous work focused on how to modify the main 
evaluation functions (use of distance-to-go functions, inflating the heuristic value)
or to modify the expansion order (e.g. Thayer and Ruml, ICAPS08).

** 3) This applies also to the summary of the authors earlier conference paper.

#+BEGIN_QUOTE
 This applies also to the summary of the authors earlier conference
paper. Rather than the "note" at the end of the introduction (which I
assume the authors intend to remove from the published version of the
paper), the summary of that paper, and the novel contributions this
article makes over it, should be integrated in the presentation.
#+END_QUOTE


We integrated the comparison with our earlier conference paper as a new paragraph at the end of Section 1, in a form similar to those of other recently published JAIR papers.

** 4) The argument in the last paragraph before Section 5.1 and the second paragraph of Section 5.1 do not make sense.

#+BEGIN_QUOTE
 The argument in the last paragraph before Section 5.1 and the second
paragraph of Section 5.1 do not make sense. First, the authors say
they selected subsets of instances of some domains in order to avoid
skewing the results by uneven instance set sizes; but then, these
domains are excluded from the following analysis.
#+END_QUOTE

The paragraphs in the last paragraph before Section [Original:5,Revised:4]
define the set of 28 Zerocost
domains used throughout the rest of the paper, and we explain why for
some domains (specifically, blocks, freecell, pipesworld-notankage,
miconic), we selected subsets of instances in order to avoid skewing
coverage results.

Blocks, freecell, pipesworld-notankage, and miconic were NOT included in the experiment in Table [Original:5.1,Revised:4.1]
because the purpose of that particular experiment was to compare coverages between Zerocost domains and their corresponding original IPC benchmark domains, 
and for this particular purpose, we wanted to avoid confusion (particularly for readers familiar with the IPC instances) by only including
domains where the number of instances in the Zerocost domains is the same as in the IPC benchmark set.

However, the Zerocost versions of Blocks, freecell, pipesworld-notankage, and miconic are used in all of the other experiments in the paper involving Zerocost domains.
(because none of the other experiments involve comparisons between coverage on Zerocost domains and coverage on standard IPC domains).

** <<R3Q5>> 5) Furthermore in Section 5.1, why is the comparison done using the [f,h,fifo] strategy

#+BEGIN_QUOTE
 Furthermore in Section 5.1, why is the comparison done using the
[f,h,fifo] strategy, given that the experiment in Section 4 showed
tie-breaking using "lifo" to be much more efficient?
#+END_QUOTE

We used the [f,h,fifo] strategy in this experiment in Section [Original:5.1,Revised:4.1] because
we use the Fast Downward planner, which is currently one of the most widely used state-of-the-art planners
and Fast Downward uses the [f,h,fifo] tiebreaking strategy by default.
Thus, we believe using the default configuration for Fast Downward is a reasonable choice, since the purpose of the experiment was to demonstrate that Zerocost domains pose a challenge for state-of-the-art planners.

Although not prominently featured in Section [Original:5.1,Revised4:1], 
the results for [f,h,lifo] can be extracted from 
Table [Original:7.2, Revised:A.3] (Zerocost instances) and Table [Original:7.4, Revised:A.5] (IPC instances).
Qualitatively, the results for [f,h,lifo] are similar to that of [f,h,fifo] -- Zerocost instances are "harder" than their corresponding IPC instances.

** 6) In Section 6.2, the authors argue that ... pruning methods ... are somehow equivalent to tie-breaking. This is not accurate.

#+BEGIN_QUOTE
 In Section 6.2, the authors argue that pruning methods such as
symmetry or partial order reduction are somehow equivalent to
tie-breaking. This is not accurate. Although a bias towards some
states may be created by the presence of, for example, symmetries, as
the authors argue, pruning the symmetric states does _more_ than just
"remove the bias". If the states in question have f-values that are
less than the cost of the optimal solution, no form of tie-breaking
will prevent A* from expanding all of them, but symmetry pruning will.
#+END_QUOTE

In Section [Original:6.2,Revised:5.1] we clarified that pruning is a stronger technique
than diversification.

** 7) In Section 7, Table 7.1 shows that there is little consistency in the results

#+BEGIN_QUOTE
 In Section 7, Table 7.1 shows that there is little consistency in the
results, particularly on the benchmark set in which only a few domains
have zero cost actions. Table 7.2 shows that this is the case even on
the Zerocost problem set, when considerd by domain. This is worth more
emphasis in the discussion. While the experiment shows that
depth-based tie-breaking *can* be advantageous, it is by no means
always the case.
#+END_QUOTE

Each tie-breaking strategy has advantages and disadvantages depending on the domain. 
These trade-offs and pathological behaviors are explained in Section [Revised:5], and 
Depth-based tie-breaking is designed to avoid pathological behaviors (Section [Revised:5]).
While this results in strong *overall* performance, other strategies
may perform better on any given  domain.

We added a paragraph before the start of Section [Revised:6.1]
clarifying this point.

** 8) I'm somewhat sceptical about the value of these figures...which of the examples are showing the failure of depth-based tie-breaking strategies.

#+BEGIN_QUOTE
 I'm somewhat sceptical about the value of these figures [Figures in Section [Original:7,Revised:6]. They show
only examples of what can happen on isolated instances. Although such
deep-dives may be useful to explain what is happening in different
cases (particularly given the variance in the results), the volume and
unclear selection of the examples make them less informative. 
#+END_QUOTE 

The purpose of the figures in Section [Original:7.1,Revised:6.1] which
show the number of nodes expanded per depth in the final plateau is
to show how the behaviors of depth diversification and other
strategies follow the theoretical analyses in Sections
[Original:6-7,Revised:5-6]

We have significantly reduced the volume of the figures in Section
[Revised:6.1] by moving the majority of the figures to the Appendix.

#+BEGIN_QUOTE
(For
instance, it is not clear which of the examples are showing the
failure of depth-based tie-breaking compared to default tie-breaking
strategies.)
#+END_QUOTE


In terms of performance measured by the number of expanded nodes,
freecell-move p04 in Figure [Original:7.2, Revised:7.3], mid-right,
is an instance on which lifo solved the problem
with much smaller expansions than depth diversification.
This can also be seen as the coverage difference in Table [Original:7.2, Revised:A.3].

** minor comments                                                  :noexport:

Section 7.1, third paragraph: Typo: "Figures 7.2 - 7.4" should be "7.2
- 7.6".



#+BEGIN_latex
\bibliography{../confs,../journals}
\bibliographystyle{theapa}
#+END_latex


