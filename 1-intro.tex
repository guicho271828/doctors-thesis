
\section{Introduction}
\label{sec:introduction}

Much of the work in the search and planning literature has focused on
reducing the size of this effective search space by developing the more
informative heuristic functions. However, there is a theoretical
limitation in this approach: It is known that the search space grows
exponentially \cite{helmert2008good} even under the optimistic
assumption that we have an \emph{almost-perfect} heuristics, $h^*-c$, a
theoretical heuristic function which always returns an estimate which is
slightly underestimates the true distance to a goal by a small constant
$c$. In order to overcome this difficulty, therefore, we have to develop
a new kind of heuristic-agnostic improvements.

As an instance of such improvement, this paper investigates tiebreaking
strategies for search algorithms. We empirically and theoretically
analyse both optimal and satisficing search.

\subsubparagraph{astar}

From \refsec{sec:astar-background} to \refsec{sec:depth}, we investigate
the tiebreaking strategy used by \astar, the standard search algorithm
for finding an optimal-cost path from an initial state $s$ to some goal
state $g \in G$ in a search space represented as a graph
\cite{hart1968formal}. 

In many problems, the size of the last layer of search, called
\emph{final plateau}, accounts for a significant fraction of the
effective search space of \astar.  \refig{fig:plateau-noh}
(\refpage{fig:plateau-noh}) plots the number of states with $f(n) = f^*$
(y-axis) vs. the number of states with $f(n) \leq f^*$ for 1104 problem
instances from the International Planning Competition (IPC1998-2011),
where $f^*$ is the optimal cost and $f(n)$ is the shortest path cost
from the initial state to a node $n$.  For many instances, a large
fraction of the nodes in the effective search space have $f(n)=f^*$.
In many domains, the points are located very close to the diagonal line
($x=y$), indicating almost all states with $f(n) \leq f^*$ have cost
$f^*$.
% For example, in the \pddl{Openstacks} domain, almost all states with
% $f(n) \leq f^*$ have cost $f^*$ due to the large number of actions with
% cost 0.


% In many problems, the size of the last layer of search (which explores
% the set of nodes with $f(n)=f^*$) accounts for a significant fraction of
% the effective search space of \astar.  \refig{fig:plateau-noh}
% (\refpage{fig:plateau-noh}) plots the
% number of states with $f(n) = f^*$ (y-axis) vs. the number of states with
% $f(n) \leq f^*$ for 1104 problem instances from the International
% Planning Competition (IPC1998-2011).  For many instances, a large
% fraction of the nodes in the effective search space have $f(n)=f^*$.
% For example, in the \pddl{Openstacks} domain, almost all states with
% $f(n) \leq f^*$ have cost $f^*$ due to the large number of actions with
% cost 0.

\begin{figure}[htbp]
  \centering
  \includegraphics{tables/aaai16-frontier/aaai16prelim3/lmcut_frontier_noh-front.pdf}
 \caption{
 The number of nodes with $f=f^*$ (y-axis) compared to the
 total number of nodes in the search space (x-axis) with $f\leq f^*$ on 1104 IPC benchmark problems,
  using modified Fast Downward with \lmcut which 
  generates all nodes with cost $f^*$.
  }
 \label{fig:plateau-noh}
\end{figure}

Therefore, in those majority of IPC problem instances where the size of
the last layer ($f(n)=f^*$) of search is huge, a
\emph{tiebreaking policy} can have a significant impact on the
performance of \astar. Tiebreaking policy is a policy 
for selecting which node to expand among nodes with the same $f$-cost.
It is widely believed that among nodes with the same $f$-cost,
ties should be broken according to $h(n)$, i.e.,
nodes with smaller $h$-values should be expanded first.  While this is a
useful rule of thumb in many domains, it turns out that tiebreaking
requires more careful consideration, particularly for problems where
this tiebreaking does not reduce the size of the plateau.

We first empirically evaluate the existing, commonly used, standard
tiebreaking strategies for \astar.
In the experiments, we show that:
\begin{enumerate}
 \item Last-In-First-Out (\lifo) policy tends to be more efficient
       than a First-In-First-Out (\fifo) policy.
 \item Tiebreaking according to the heuristic value $h$, which
       frequently appears in the heuristic search literature, has little
       impact on the performance as long as a \lifo policy is used.
 \item There are significant performance differences among tiebreaking strategies
       when domains include zero-cost actions. This is true even when
       both of the \lifo and $h$-based tiebreaking are enabled.
\end{enumerate}
While there are relatively few domains with zero-cost actions in the
IPC benchmark set, we argue that zero-cost actions naturally occur in 
practical cost-minimization problems.

In order to solve such problems more efficiently, we propose a new
tiebreaking method based on a notion of \emph{depth} within the plateau,
corresponding to the number of steps a node is from the ``entrance'' to
the plateau.  We empirically show that:
\begin{enumerate}
 \item Depth-based diversification strategy significantly outperforms
       other tiebreaking strategies using the same heuristic function.
 \item Artificial gradient introduced by $\epsilon$-cost conversion or
       PLUS\-ONE cost types does not achieve the performance better than
       our strategy.
 \item $\epsilon$-cost and PLUS\-ONE cost types essentially makes the
       task computationally harder in the context of cost-optimal
       planning, while depth-based diversification does not.
\end{enumerate}

Note that all tiebreaking strategies in this section maintain the
optimality of the search algorithm because they only affect node
expansion order among the nodes with the same $f$-cost.

