
\section{Related Work}

Previous work on escaping search space plateaus has focused on
non-admissible search.  DBFS \cite{imai2011novel} % is a technique which
adds stochastic backtracking to Greedy Best First Search (GBFS) to avoid
being misdirected by the heuristic function. Type based buckets
\cite{xie14type} classify plateaus in GBFS according to the
$[g,h]$ pair and distributes the effort.\footnote{The relationship between Type-GBFS and our work is discussed in detail in \refsec{sec:depth-vs-types}.}  Marvin \cite{Coles07} learns plateau-escaping macros
from the Enhanced Hill Climbing phase of the FF planner
\cite{Hoffmann01}. % (note that use of macros makes the search inadmissible in general). % adding macros to optimal planners doesn't make search inadmissible as long as the original edges in the search graph remain.
\citeauthor{Hoffmann05}  gives a detailed analysis of the
structure of the search spaces of satisficing planning \citeyear{Hoffmann05,Hoffmann11}.

% % duplicated, and not particularly investigating plateau %restoring in response to R3.2
 \citeauthor{benton2010g} \citeyear{benton2010g} proposes inadmissible technique for temporal planning
 where short actions are hidden behind long actions and do not increase makespan.
 \citeauthor{wilt2011cost} \citeyear{wilt2011cost} also analyzes inadmissible distance-to-go estimates.
% 
To our knowledge, plateaus have not been previously investigated for cost-optimal search.
Admissible and inadmissible search differ significantly in how non-final plateaus (plateaus with $f < f^*$) are treated:
Inadmissible search can skip or escape plateaus whenever possible, while
admissible search cannot, unless it is the plateau with $f=f^*$ where the goals can immediately be found.

Some real-time search algorithms like $ARA^*$ \cite{likhachev2008anytime} are able to prune some states in the final plateau using the knowledge acquired in the previous iterations of suboptimal searches. $ARA^*$ uses a sequence of $W\hspace{-0.2em}A^*$ ($[g+wh]$) with decreasing weights $w$, with the final round of iterations being optimal \astar with an uninflated heuristic value (i.e. $w=1$). When $f=g+wh$ reaches the cost of best path found so far by the previous suboptimal iterations, it can safely terminate the search maintaining the current bounded optimality guarantee $w$, that is, $w=1$ in the final iteration. Thus, in an iterated, real-time search setting, this could largely avoid the problem of searching the final plateau if the previous suboptimal searches \emph{happen} to have found the optimal solution already. 

In their work on combining multiple inadmissible heuristics in a planner,
\citeauthor{RogerH10} \citeyear{RogerH10} considered a tie-breaking approach which works as follows:
When combining two heuristics $h_1$ and $h_2$, $h_1$ is used as the primary criterion,
and $h_2$ is used to break ties among nodes with the same $h_1$ --- $[h_1,h_2,\fifo]$.
This did not perform well in their work on satisficing planning compared to the approaches based on alternation queues and Pareto-optimal queue selection.
% 
Since their focus is on how to combine multiple heuristics,
this tie-breaking-based approach is just one instance of various implementations of OPEN lists.
In contrast, this paper provides a focused, in-depth investigation of various tie-breaking strategies,
and shows 
how tie-breaking enables the efficient search on the plateau created by the earlier levels of sorting criteria.

%% already mentioned in the earlier section.
% The PLUSONE %\footnote{This term is used on the Fast Downward website.} XXfootnote takes too much space
% cost-type (or distance-to-go) is a non-admissible search technique in the Fast Downward/LAMA planner
% \cite{richter2010lama} which increases all action costs by 1.
% % By eliminating 0-cost actions, this behaves similar to our $[f,h,\fd,\ro]$ tie-breaking.
% %Using PLUSONE, three successive
% %applications of 0-cost operators have cost 3, and two
% %applications have cost 2, and smaller cost is preferred, just as
% %\astar always expands the node with smaller $f$-value.
% This technique explicitly targeted 0-cost actions,
% and resulted in significantly better performance in the IPC-6
% satisficing track \cite[p. 137, Sec. 3.3.2]{richter2010lama}.
% %\todo*{citation}
% % There's a long discussion of Openstacks in \cite{richter2010lama}, p. 167-169, but I can't find PLUSONE anywhere. Maybe it's called something else in the paper?  Maybe \richter2010lama is the wrong citation??
% PLUSONE cost type makes a heuristic function inadmissible, and since LAMA uses it as the first sorting criterion, it makes the sorting criteria of LAMA inadmissible.

% It's not clear what these techniques have in common, except that they are all orthogonal to heuristics,
% If that's the case, then there's no need to cite them in this paper -- there's no reason why these particular techniques
% are more relevant to this paper than hundreds of other techniques that are orthogonal to heuristics.
%% In admissible planning,
%% \emph{Symmetry Breaking}
%% \cite{Fox1998,pochter2011exploiting,domshlak2013symmetry} is the search
%% technique that tries to prune the states with symmetric
%% paths. \emph{Partial Order Reduction}
%% % , \emph{Strong Stubborn Sets} and \emph{Expansion Core} are
%% is also a technique which prunes the
%% intermediate states that reach to the same goal using the different
%% orders of same actions. \emph{Dominance Pruning} \cite{hall2013faster} is a
%% technique which prunes a state if it can be proven to be worse than the other nodes.
%% % 
%% These are usually not considered an attempt to improve the heuristic
%% estimates, however, in terms of \emph{Path-dependent globally admissible
%% heuristics} \cite{karpas2012optimal}, a class of heuristics which is
%% admissible only on a particular optimal path, generalizes the above
%% techniques as assigning an infinite cost to some nodes on the other optimal paths.
%% % 
%% % From a slightly different category, Pathmax \cite{mero1984heuristic} and
%% % Bidirectional Pathmax \cite{felner2011inconsistent} are the techniques
%% % which converts an inconsistent heuristics into non-decreasing,
%% % consistent heuristics.
%% Thus, in a broad term, all of these methods are the
%% attempts to improve the heuristic estimates.
%% % Although in some particular
%% % case they may be able to return a perfect heuristics, they are still not
%% % always a perfect heuristics, implying that the plateau is unavoidable.
%% In contrast, our tie-breaking techniques aims specifically at the case
%% where the plateau is encountered and the planners are forced to run a
%% knowledge-free search.

\emph{\astar with lookahead} ($AL^*$) \cite{stern2010look} extends \astar by performing a cost-bounded depth-first \emph{lookahead} from each node as it is generated. Upon the normal expansion of a node $n$ in \astar, lookahead search performs a depth-first search with cost bound $f(n)+k$ rooted at $n$. As a special case, under the cost bound $k=0$ ($AL^*_0$ in their notation), depth-first lookahead expands only the children with the same $f$-value.
% There are both commonality and difference in our approach and $AL^*$:
% In terms of commonality, 
$AL^*$, or $AL^*_0$ in particular, is similar to $[f,\lifo]$ in that the lookahead is a depth-first search.
However, there are both conceptual and algorithmic differences: 
First of all, $AL^*_0$ does not specify the intermediate tie-breaking (such as $h$-based tie-breaking) for its main \astar, and depth-first lookahead does not perform best-first expansion, so the tie-breaking is irrelevant. Thus, the problems and the solutions addressed in these approaches are different.
Second, $AL^*$ propagates the maximum and the minimum $f$ values found in the lookahead search, which allows for more pruning.
% wrong, see AAAI10 paper that ``recitify this''
% Finally, when $k>0$ the search becomes inadmissible because it alters the best-first expansion order.

Another relevant line of work, in similar spirit to Zerocost domains, is the Preference Track in the deterministic
part of IPC4 \cite{gerevini2009automatically}. One difference between our Zerocost domains and these domains is
that the latter allows a more complex semantics such as multiplication.
% 
More recently, \shortciteauthor{wray2015multi} \citeyear{wray2015multi} proposed a model called \emph{conditional lexicographic preferences with slack} in the context of planning under uncertainty. 
% 
Lexicographic preferences allow the problem to have multiple preference criteria evaluated individually. The
solution quality is determined by the first preference, breaking ties by the second preference and so on.
% 
Slack refers to a constant amount of error from the optimal value. With slack, one can model a situation where the
goal is to optimize the first preference, but the difference up to some amount is ignored and ties are broken according to 
the second preference.
% 
An example of a planning problem with such lexicographic preferences with slack would be a transportation problem where 
the first optimization objective is the amount of fuel usage, allowing a slack up to 5 liters, and 
the second optimization target is the makespan of the plan.
In this case, a plan with 100 liters of fuel usage and a plan with 105 liters of fuel usage are considered equally preferable in the first criterion, and the better plan is the one with a shorter makespan.
% 
Since slack allows multiple values (e.g. 100 and 105) to have the same preference, it should introduce larger plateaus.
Applying our techniques to problems with slack is an avenue of future work.
