\chapter{Related Work}

Previous work on escaping search space plateaus has focused on
non-admissible search.  DBFS \cite{imai2011novel} % is a technique which
adds stochastic backtracking to Greedy Best First Search (GBFS) to avoid
being misdirected by the heuristic function. Type based buckets
\cite{xie14type} classify plateaus in GBFS according to the
$[g,h]$ pair and distributes the effort.\footnote{The relationship between Type-GBFS and our work is discussed in detail in \refsec{sec:depth-vs-types}.}  Marvin \cite{Coles07} learns plateau-escaping macros
from the Enhanced Hill Climbing phase of the FF planner
\cite{hoffmann01}. % (note that use of macros makes the search inadmissible in general). % adding macros to optimal planners doesn't make search inadmissible as long as the original edges in the search graph remain.
\citeauthor{Hoffmann05}  gives a detailed analysis of the
structure of the search spaces of satisficing planning \citeyear{Hoffmann05,Hoffmann11}.

% % duplicated, and not particularly investigating plateau %restoring in response to R3.2
 \citeauthor{benton2010g} \citeyear{benton2010g} proposes inadmissible technique for temporal planning
 where short actions are hidden behind long actions and do not increase makespan.
 \citeauthor{wilt2011cost} \citeyear{wilt2011cost} also analyzes inadmissible distance-to-go estimates.
% 
To our knowledge, plateaus have not been previously investigated for cost-optimal search.
Admissible and inadmissible search differ significantly in how non-final plateaus (plateaus with $f < f^*$) are treated:
Inadmissible search can skip or escape plateaus whenever possible, while
admissible search cannot, unless it is the plateau with $f=f^*$ where the goals can immediately be found.

Some real-time search algorithms like $ARA^*$ \cite{likhachev2008anytime} are able to prune some states in the final plateau using the knowledge acquired in the previous iterations of suboptimal searches. $ARA^*$ uses a sequence of $W\hspace{-0.2em}A^*$ ($[g+wh]$) with decreasing weights $w$, with the final round of iterations being optimal \astar with an uninflated heuristic value (i.e. $w=1$). When $f=g+wh$ reaches the cost of best path found so far by the previous suboptimal iterations, it can safely terminate the search maintaining the current bounded optimality guarantee $w$, that is, $w=1$ in the final iteration. Thus, in an iterated, real-time search setting, this could largely avoid the problem of searching the final plateau if the previous suboptimal searches \emph{happen} to have found the optimal solution already. 

In their work on combining multiple inadmissible heuristics in a planner,
\citeauthor{RogerH10} \citeyear{RogerH10} considered a tie-breaking approach which works as follows:
When combining two heuristics $h_1$ and $h_2$, $h_1$ is used as the primary criterion,
and $h_2$ is used to break ties among nodes with the same $h_1$ --- $[h_1,h_2,\fifo]$.
This did not perform well in their work on satisficing planning compared to the approaches based on alternation queues and Pareto-optimal queue selection.
% 
Since their focus is on how to combine multiple heuristics,
this tie-breaking-based approach is just one instance of various implementations of OPEN lists.
In contrast, this paper provides a focused, in-depth investigation of various tie-breaking strategies,
and shows 
how tie-breaking enables the efficient search on the plateau created by the earlier levels of sorting criteria.

%% already mentioned in the earlier section.
% The PLUSONE %\footnote{This term is used on the Fast Downward website.} XXfootnote takes too much space
% cost-type (or distance-to-go) is a non-admissible search technique in the Fast Downward/LAMA planner
% \cite{richter2010lama} which increases all action costs by 1.
% % By eliminating 0-cost actions, this behaves similar to our $[f,h,\fd,\ro]$ tie-breaking.
% %Using PLUSONE, three successive
% %applications of 0-cost operators have cost 3, and two
% %applications have cost 2, and smaller cost is preferred, just as
% %\astar always expands the node with smaller $f$-value.
% This technique explicitly targeted 0-cost actions,
% and resulted in significantly better performance in the IPC-6
% satisficing track \cite[p. 137, Sec. 3.3.2]{richter2010lama}.
% %\todo*{citation}
% % There's a long discussion of Openstacks in \cite{richter2010lama}, p. 167-169, but I can't find PLUSONE anywhere. Maybe it's called something else in the paper?  Maybe \richter2010lama is the wrong citation??
% PLUSONE cost type makes a heuristic function inadmissible, and since LAMA uses it as the first sorting criterion, it makes the sorting criteria of LAMA inadmissible.

% It's not clear what these techniques have in common, except that they are all orthogonal to heuristics,
% If that's the case, then there's no need to cite them in this paper -- there's no reason why these particular techniques
% are more relevant to this paper than hundreds of other techniques that are orthogonal to heuristics.
%% In admissible planning,
%% \emph{Symmetry Breaking}
%% \cite{Fox1998,pochter2011exploiting,domshlak2013symmetry} is the search
%% technique that tries to prune the states with symmetric
%% paths. \emph{Partial Order Reduction}
%% % , \emph{Strong Stubborn Sets} and \emph{Expansion Core} are
%% is also a technique which prunes the
%% intermediate states that reach to the same goal using the different
%% orders of same actions. \emph{Dominance Pruning} \cite{hall2013faster} is a
%% technique which prunes a state if it can be proven to be worse than the other nodes.
%% % 
%% These are usually not considered an attempt to improve the heuristic
%% estimates, however, in terms of \emph{Path-dependent globally admissible
%% heuristics} \cite{karpas2012optimal}, a class of heuristics which is
%% admissible only on a particular optimal path, generalizes the above
%% techniques as assigning an infinite cost to some nodes on the other optimal paths.
%% % 
%% % From a slightly different category, Pathmax \cite{mero1984heuristic} and
%% % Bidirectional Pathmax \cite{felner2011inconsistent} are the techniques
%% % which converts an inconsistent heuristics into non-decreasing,
%% % consistent heuristics.
%% Thus, in a broad term, all of these methods are the
%% attempts to improve the heuristic estimates.
%% % Although in some particular
%% % case they may be able to return a perfect heuristics, they are still not
%% % always a perfect heuristics, implying that the plateau is unavoidable.
%% In contrast, our tie-breaking techniques aims specifically at the case
%% where the plateau is encountered and the planners are forced to run a
%% knowledge-free search.

\emph{\astar with lookahead} ($AL^*$) \cite{stern2010look} extends \astar by performing a cost-bounded depth-first \emph{lookahead} from each node as it is generated. Upon the normal expansion of a node $n$ in \astar, lookahead search performs a depth-first search with cost bound $f(n)+k$ rooted at $n$. As a special case, under the cost bound $k=0$ ($AL^*_0$ in their notation), depth-first lookahead expands only the children with the same $f$-value.
% There are both commonality and difference in our approach and $AL^*$:
% In terms of commonality, 
$AL^*$, or $AL^*_0$ in particular, is similar to $[f,\lifo]$ in that the lookahead is a depth-first search.
However, there are both conceptual and algorithmic differences: 
First of all, $AL^*_0$ does not specify the intermediate tie-breaking (such as $h$-based tie-breaking) for its main \astar, and depth-first lookahead does not perform best-first expansion, so the tie-breaking is irrelevant. Thus, the problems and the solutions addressed in these approaches are different.
Second, $AL^*$ propagates the maximum and the minimum $f$ values found in the lookahead search, which allows for more pruning.
% wrong, see AAAI10 paper that ``recitify this''
% Finally, when $k>0$ the search becomes inadmissible because it alters the best-first expansion order.

Another relevant line of work, in similar spirit to Zerocost domains, is the Preference Track in the deterministic
part of IPC4 \cite{gerevini2009automatically}. One difference between our Zerocost domains and these domains is
that the latter allows a more complex semantics such as multiplication.
% 
More recently, \shortciteauthor{wray2015multi} \citeyear{wray2015multi} proposed a model called \emph{conditional lexicographic preferences with slack} in the context of planning under uncertainty. 
% 
Lexicographic preferences allow the problem to have multiple preference criteria evaluated individually. The
solution quality is determined by the first preference, breaking ties by the second preference and so on.
% 
Slack refers to a constant amount of error from the optimal value. With slack, one can model a situation where the
goal is to optimize the first preference, but the difference up to some amount is ignored and ties are broken according to 
the second preference.
% 
An example of a planning problem with such lexicographic preferences with slack would be a transportation problem where 
the first optimization objective is the amount of fuel usage, allowing a slack up to 5 liters, and 
the second optimization target is the makespan of the plan.
In this case, a plan with 100 liters of fuel usage and a plan with 105 liters of fuel usage are considered equally preferable in the first criterion, and the better plan is the one with a shorter makespan.
% 
Since slack allows multiple values (e.g. 100 and 105) to have the same preference, it should introduce larger plateaus.
Applying our techniques to problems with slack is an avenue of future work.



We theorized that we can understand the diversification of GBFS with
respect to two orthogonal error axes of inter-plateau and intra-plateau
errors. Recently, another group of ideas for understanding the GBFS behavior,
namely \emph{high water marks} \cite{wilt2014speedy} and \emph{benches} \cite{heusner2017understanding}, was proposed.
Analyzing the interaction between these ideas and our framework is future work.

While this paper investigated Bond-IP (the variant of Invasion Percolation which fixes random values to edges),
the dual variant which fixes values on nodes is called \emph{Site IP}.
Analysis of SIP is a direction for future work as they could have different fractal characteristics \cite{sheppard1999invasion}.
%Fractal analysis on the search graph is an interesting avenue of future work.
\citeauthor{valenzano2014comparison} \citeyear[Section 4.3]{valenzano2014comparison} evaluated a baseline, knowledge-free heuristic which assigns a random $h$-value to a node.
By itself, this would behave similarly to the $ro$ baseline strategy, if heuristic values are reevaluated for reopened nodes (the default behavior in FastDownward\footnote{\relsize{-1}\url{http://hg.fast-downward.org/file/df227b467100/src/search/search_engines/eager_search.cc\#l202}}).
However, \citeauthor{valenzano2014comparison} disabled node-reopening in all their experimental configurations, which, in effect, fixes the random value for each node and makes them behave similarly to SIP.


\chapter{Conclusion and Future Work}

In this paper, we investigated the cost-optimal search using \astar and the satisficing search based on GBFS.


\begin{comment} % the goals are unimportant
We sought to
(1) shed some light on the importance of tie-breaking in \astar,  %one of the most popular best-first search algorithms, 
(2) improve \astar without modifying its main heuristic function at all, and (3) to
improve \astar by introducing inadmissible techniques. We reached all of these goals successfully: We sought
various possible enhancements and achieved significant performance improvements solely by the tie-breaking
techniques. In detail, the contributions in this paper are the following:
\end{comment}

Our contributions are as follows:
% \begin{enumerate} % It looks bad when an entire section is just an enumerated list, 
 First, we showed that tie-breaking has a significant role in the cost-optimal
       search using \astar. We empirically showed that most  IPC
       benchmark instances have large plateaus with regard to $f$, and most of the
       search effort is spent in the final plateau with $f=f^*$.

 We then showed that  the commonly used tie-breaking policy based on $h$ value fails to
       provide guidance in the plateau when problem instances have 0-cost
       actions and have large plateaus with regard to $h$.
       We empirically showed that most of the search effort can be spent in
       the final plateau with $f=f^*, h=0$ in some domains, and noted that in such
       a plateau, the search is controlled solely by the
       default tie-breaking \fifo, \lifo or \ro.

 We proposed  a new set of benchmark instances for cost-optimal planning, called Zerocost
 domains, which contain many 0-cost actions.
         We showed that Zerocost versions of IPC benchmark domains tend to have larger final plateaus with $f=f^*, h=0$ and pose a new challenge to traditional search algorithms.
  % removed ``strictly harder than'' because ``strictly harder'' has a formal connotation, which is not our contribution.
  % --- yes, and it is also an unproven claim: W[2]\not= Para-NP-hard is not proven yet
       % I do not cite the meysam's paper here because I want to make my contribution clear.

 As one approach to improving search performance in Zerocost domains, we proposed a depth metric
       which measures the distance from the entrance to the
       plateau. Using this metric, we described the pathological
       behaviors of \fifo, \lifo and \ro, proposed a new diversification
       strategy, theoretically and empirically showed that it avoids the
       pathological behavior and achieves a better performance.

We then introduced a new interpretation of cost-optimal \astar search as a series of satisficing
       searches among $f$-cost plateaus of an increasing order of $f$. 
%This opens  many opportunities for unifying work on satisficing search and cost-optimal search, as 
%many techniques which have been developed for 
%       satisficing search can be directly applied to plateau search in   cost-optimal search.
This perspective led to another approach for effective tie-breaking in Zerocost domains, the use of
       inadmissible distance-to-go estimates as part of a multi-heuristics tie-breaking strategy.
       Combination of depth diversification and distance-to-go estimates results in the best overall performance. Although there is an additional cost to compute
       multiple heuristic values, the overhead can be eliminated by a simple
       case-based configuration which only uses multiple heuristics when 0-cost actions are present in the problem instance.

% Another direction for future work is implementing tie-breaking strategies for IDA* and similar linear-space
% strategies like RBFS.
% For example, how do we implement or simulate depth-based tie-breaking with a linear space usage?
% \todo*{In fact, exploring the application of ``IDA* = series of satisficing seraches'' seems like an interesting
% direction for future work, e.g., how to simulate depth-based tie-breaking (node ordering) in IDA*? IDA* is useful
% for domains where memory limitations are the bottleneck, so keeping the depth buckets in memory may not be
% possible. More broadly, linear space, best-first search including RBFS}

Next, in an attempt to improve the satisficing search performance,
we introduced the notion of \emph{Intra}- and
\emph{Inter}-plateau exploration in satisficing heuristic search.
While  previous work on exploration focused on inter-plateau exploration,
we argued that intra-plateau exploration addresses orthogonal issues, and showed that 
the type-based diversification framework originally developed for inter-plateau diversification could be used to unify intra- and inter-plateau diversification.
We then showed empirically that these two modes of diversification have 
orthogonal, complementary effects when implemented as diversification strategies for GBFS, % although "complementary" implies that they can be combined, this is worth explicitly emphasizing
and showed that it is possible to combine intra/inter-plateau diversification, 
resulting in better performance than either class of strategy alone is used.

Next, we showed that type-based diversification is not sufficient for
bias avoidance in graphs where nodes have largely varying number of
neighbors, and proposed IP-diversification, a new breadth-aware
diversification strategy which addresses this issue. We then showed that
IP-diversification can be used as either intra- or inter-plateau
exploration strategy, i.e., IP is a dual-mode diversification strategy
unlike depth-diversification and $\brackets{g,h}$ type-based
diversification, which are specialized for either intra- or
inter-plateau exploration. %"bimodal" can be misinterpreted in the
probability distribution sense of two peaks.  In addition, to our
knowledge, this is the first successful fractal-inspired
planning algorithm.

Finally, we showed that incorporating these two new ideas (performing
both intra/inter-plateau exploration, and IP-diversification) into
FD/LAMA yields state-of-the-art performance on IPC benchmark instances.


Our reformulation of \astar as a sequence of satisficing searches  points to  an interesting direction for future work.
Although we evaluated only one relatively simple, satisficing configuration ($\ffo$) in
the experiments, many techniques which have previously been developed for satisficing planning can be applied
 to enhance tie-breaking (plateau-search) in cost-optimal search, including
lazy evaluation \cite{richter2010lama}, alternating/Pareto open
list \cite{RogerH10}, helpful actions (preferred operators) \cite{hoffmann01},
random walk local search \cite{nakhost2009monte}, macro operators
\cite{Botea2005,ChrpaVM15}, factored planning
\cite{amir2003factored,brafman2006factored,Asai2015} and
exploration-based search enhancements
\cite{valenzano2014comparison,xie14type,Valenzano2016}.

Another direction for future work is to reformulate those
satisficing search algorithms into the simpler blind search algorithms,
instead of trying to embed them directly as the subroutines for optimal search.
This is because many of these methods are ad-hoc and 
integrating them into the standard Best-First Search framework may not be straightforward.
% 
By proposing the inter/intra-plateau framework for understanding the diversification methods for GBFS,
we effectively showed that \emph{satisficing search can be reduced to blind search}
because the methods for either of the two modes of diversification are all knowledge-free, blind search algorithms.
% Similar to the reduction of optimising search into satisficing search,
This inspired us that a less-adhoc way to improve the satisficing search performance
is by simply devising a better blind search algorithm.
IP-based diversification was exactly one such instance.

% Overall, we gradually reduced the optimal search algorithms into a less complicated, primitive algorithms.
