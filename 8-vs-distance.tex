\clearpage
\section{Distance-to-Go Estimates}

\label{sec:distance-to-go}

We next compare our depth diversification to the distance-to-go
estimates in the plateau.  Distance-to-go estimates are the type of
heuristics which treat actions as if they have the unit cost. Even under
the presence of zero-cost actions, those estimates can predict the
number of operations required to reach a goal.
While several papers advocates the benefit of this technique, many of
these claims took place in the context of satisficing planning.
\footnote{Need more complete  survey of previous work on d2go heuristics in best-first search (not just planning) here: Thayer+Ruml ICAPS09,Socs09; connectoins to FOCAL method of Pearl and Kim}

\shortciteauthor{benton2010g} proposed an inadmissible technique for temporal
planning where short actions are hidden behind long actions and do not
increase makespan \cite{benton2010g}. Such actions cause so-called
``g-value plateau'', a similar situation caused by 0-cost actions in
sequential planning.  They implemented an inadmissible heuristic
function combined with distance-to-go estimates on top of
Temporal Fast Downward system.  As stated, their method is not
applicable to the optimizing search.
 
% ,wilt2011cost
Similarly, in sequential satisficing planning,
\shortciteauthor{cushing2010cost} showed that
(non-admissibly) treating all actions as unit cost sometimes finds an
optimal plan quickly \cite{cushing2010cost}.
Although it could find an optimal plan by chance, this does not
guarantee the optimality of the solution.
 
Also, a \sota satisficing planner FD/LAMA2011 incorporates
distance-to-go estimates in its iterated search framework. The first
iteration of LAMA uses distance-to-go estimates combined with various
satisficing search enhancements.

\subsection{Distance-to-Go Estimates for Optimal Planning}

Although previous work on distance-to-go estimates assume the
satisficing context,
there is still a possibility to use the same techniques for admissible search. %the term ``optimal search'' is somewhat controversial because it's not clear what ``optimal'' refers to -- solution cost, search efficiency, etc ?
We say that a sorting strategy is an \emph{admissible sorting strategy}
when best first search using the strategy is guaranteed to return an
optimal solution. 
Clearly, a sorting strategy is admissible if and only if the 
first sorting criterion $f$ is admissible (since $f=g+h$, $h$ must be an admissible heuristic).
%uses an ordinary
%admissible heuristics. 
This means that as long as the first criterion is admissible, the optimality of the solution is not affected by the
subsequent levels of sorting criterion, and therefore
it is possible to use an inadmissible
distance-to-go estimate in the second (or later) level sorting criteria without sacrificing the optimality of the solution
found.

Let $h$ be an admissible heuristic, and
let $\hat{h}$ be a distance-to-go variation of $h$, i.e., $\hat{h}$ uses essentially the same algorithm as $h$, except that while $h$ the actual action costs for the problem domain, $\hat{h}$ treats all action costs as unit cost.
%% redundunt
% Upon computing the estimates, $\hat{h}$ treats all
% actions to have unit costs, while original heuristic function $h$ uses the
% standard action cost.
Since $h$ is admissible, multi-heuristic sorting strategies such as $[g+h,h,\hat{h}]$ or $[g+h,\hat{h}]$
are admissible.

Moreover, we can even use a multi-heuristic strategy which uses an inadmissible heuristic for tiebreaking which is unrelated to the primary, admissible heuristic $h$.
 For example, $[g+h^{\lmcut},\ffo]$ is an admissible sorting strategy
because the first sorting criterion $f=g+h^{\lmcut}$ uses an admissible
\lmcut heuristic. Its second sorting criterion, the distance-to-go FF
heuristics, does not affect the admissibility of this entire sorting strategy.

A potential problem with sorting strategies which use multiple heuristics is the 
the cost of computing additional
heuristic estimates. For example, $[g+h^{\lmcut},\ffo]$ requires more time to evaluate each node compared to a standard tiebreaking strategy such as $[g+h^{\lmcut},h^{\lmcut}]$ because computing the $\ffo$ heuristic incurs significant overhead per node.
When $\hat{h}$, the inadmissible heuristic for tiebreaking is a distance-to-go (unit cost) variant of the primary, admissible heuristic $h$, it may be possible to reduce this overhead to some extent by implementing $h$ and $\hat{h}$ so that they share some of the computation  -- this is a direction for future work.

\subsection{Evaluating Distance-to-go Estimates}

We tested various admissible sorting strategies on IPC domains and Zerocost domains.
% on zerocost domains  where tiebreaking strategies have the large impact.
The configurations are listed in \reftbl{list:distance-configs}. 
In all configurations, the first sorting criterion is the $f=g+h$ value
where $h$ is an admissible heuristic (either \lmcut or \mands) using the actual action-cost based  cost calculation, .
As the second or later sorting criterion,
we tested $\hat{h}$ of original $h$, as well as a distance-to-go variation of FF
heuristic ($\hat{h}^{\ff}$).
% , and a distance-to-go variation of
% GoalCount heuristic ($\hat{h}^{\text{GoalCount}}$) which is added to
% represent an uninformative but fast inadmissible heuristic function with
% least additional overhead.
We also added configurations with the depth metric within
$\plateau{f,\hat{h}^{\text{\ff}}}$.

\begin{table}[htbp]
 \centering
 \[
 \begin{array}{lcll}
  (1)\, [h+g, & h,                           &L] \\\relax
  (2)\, [h+g, & h,     \quad   \hat{h},      &L] \\\relax
  (3)\, [h+g, & \hat{h},                     &L] \\\relax
  (4)\, [h+g, & \hat{h}^{\ff},               &L] \\\relax
  % not include it unless the reviewer complained. 
  % (5)\, [h+g, & \hat{h}^{\text{GoalCount}},  &L] \\\relax
  (5)\, [h+g, & h, \depth, &L] \\\relax
  (6)\, [h+g, & \hat{h}^{\text{FF}}, \depth, &L] \\\relax
 \end{array}  
 \]
 \caption{Configurations compared in this section. $h$ is
 one of $\braces{\lmcut, \mands}$, and $L$ is one of the default
 tiebreaking strategies $\fifo,\lifo,$ or $\ro$. }
 \label{list:distance-configs}
\end{table}

% $[h^{\lmcut}+g,\hat{h}^{\mbox{LMcount}},\fifo]$,

A summary of the results are shown in \reftbl{tbl:dtg-summary}. For
comparison, we also include the results of configurations evaluated in the previous sections.
Detailed per-domain results are shown in
\reftbls{tbl:dtg-lmcut-zero}{tbl:dtg-mands-ipc}.

In Zerocost domains, we see that $\hat{h}$-tiebreaking outperforms $h$-tiebreaking for both \lmcut and \mands. Also,
combining $h$ and $\hat{h}$ can further improve performance when the heuristic is  \lmcut.  The results with/without $\hat{h}$ are comparable when
the main heuristic function $h$ is \mands.  
Yet more surprisingly, using $\ffo$ results in an order of magnitude\todo{??? Order of magnitude? on some particular domain??}
larger coverage in both \lmcut and \mands. 
% Thus, when the depth metric is not used, the best configuration is those
Thus, when the depth diversity criterion  is not used, the best configurations are those
which use $\ffo$.  Finally, adding depth diversity criterion further improves the performance of the $\ffo$-based strategies.
 The coverage increased in both $h=h^\lmcut$ (\fifo: $337\rightarrow 340$, \lifo: $340\rightarrow
342$, \ro: $341\rightarrow 344.3$) and $h=h^\mands$ (\fifo: $336\rightarrow 337$, \lifo: $331\rightarrow
333$). When the default tiebreaking was \ro and the heuristic is \mands, $[f,\ffo,\depth,\ro]$ did not improve
over $[f,\ffo,\ro]$, but the coverage difference was small ($337.9\rightarrow 337.6$) and it is  slightly
more robust (smaller variance: $2.1\rightarrow 1.3$).

For standard IPC benchmark instances, the overhead due to the additional computation of
$\hat{h}$ or $\ffo$ tends to harm the overall performance.
% The only domains consistently enhanced by distance-to-go estimates are \pddl{mprime} using \lmcut,
% \pddl{parcprinter-opt11} using \mands and \pddl{woodworking-opt11} using \mands. Moreover, their improvements are small.
Therefore, the best overall configuration using \lmcut was
$[f,h,\depth,\lifo]$ which uses depth and does not impose the cost of
additional heuristics, and the best result using \mands
was $[f,h,\lifo]$ which impose the least overhead on the fast expansion offered by
\mands heuristics.
% However, 
% zerocost domains in this standard benchmark set (Openstacks and
% Cybersec) has each shown a significant speedup achieved by these distance-to-go estimates
%  (\reftbl{tbl:dtg-lmcut-ipc} and \reftbl{tbl:dtg-mands-ipc}).

The performance degradation in the positive cost domains is not a practical issue,
because we can simply configure the search algorithm to use depth diversification or not  before running the
search, depending on whether the domain contains zerocost actions or not.
Coverage results in \reftbl{tbl:dtg-summary-sum} show the total of
zerocost and benchmark domains. The \emph{dynamic configuration}, which implements this 
switching behavior, achieves the highest coverage.

% While these multi-heuristic strategies did not improve the perfomance in
% the positive cost domains because the final plateaus are small, a simple
% method which 

Overall, these results also strengthen our claim that $h$-based
tiebreaking is not necessarily the ``rule of the thumb'' in some
domains, as already discussed in \refsec{sec:noh}. In zerocost domains,
using a distance-to-go version of an inadmissible heuristic function for
tiebreaking is more effective. Also, combining the depth metric with
such an inadmissible heuristics is also effective.\todo{Maybe we should show dynamic configuration results in the detailed per-domain tables, just so that it's obvious that we can get ``dominant'', state-of-the-art  behavior}.


\begin{table}[htbp]
 \centering
 \input{tables/8-1-summary}
 \caption{
 Summary Results: Coverage comparison (the number
 of instances solved in 5min, 4GB) between several sorting strategies.
 }
 \label{tbl:dtg-summary}
\end{table}

\begin{table}[htbp]
 \centering \input{tables/8-1-summary-sum}
 \caption{ Summary Results:
 Coverage comparison, the total of IPC domains and Zerocost domains (the
 number of instances solved in 5min, 4GB) between several sorting
 strategies, plus a dynamic configuration strategy which selects the
 right behavior checking whether zero-cost actions exist.  }
 \label{tbl:dtg-summary-sum}
\end{table}

\setlength{\tabcolsep}{0.1em}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:lmcut-zerocost-full}}.
 }
 \label{tbl:dtg-lmcut-zero}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:mands-zerocost-full}}.
 }
 \label{tbl:dtg-mands-zero}
 }
\end{table}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-lmcut-ipc}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-mands-ipc} }
\end{table}

