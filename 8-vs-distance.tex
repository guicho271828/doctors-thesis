\clearpage
\section{Distance-to-Go Estimates}

\label{sec:distance-to-go}

Although we showed the benefit of knowledge-free search technique, there is another approach to improving the
search performance in plateaus produced by zerocost domains. The approach we evaluate in this section is one which
enhance the search by combining multiple heuristics, especially inadmissible \emph{distance-to-go} estimates.

% ; This allows the heuristics to be
% inadmissible when it is only used for tiebreaking strategy.

% The obvious
% drawback of this strategy is the cost of additional heuristic
% computation.

% We next compare our depth diversification to the distance-to-go
% estimates in the plateau.  
Distance-to-go estimates are the type of
heuristics which treat actions as if they have the unit cost. Even under
the presence of zero-cost actions, those estimates can predict the
number of operations required to reach a goal.
While several papers advocates the benefit of this technique, many of
these claims took place in the context of satisficing planning.
\todo*{Need more complete  survey of previous work on d2go heuristics in best-first search (not just planning) here: Thayer+Ruml ICAPS09,Socs09; connectoins to FOCAL method of Pearl and Kim}

Except for cases where the target domains are unit-cost by origin, $A^*_\epsilon$ \cite{pearl1982studies} is one of
the earliest algorithms that combines distance-to-go estimates with the cost estimates. It is a bounded-suboptimal
search which expands from the \emph{focal} list, the set of nodes with $f(n)\leq w\cdot f_{\mit{min}}$ where $w$ is
a cost bound in a sense of $\mit{WA}^*$ and $f_{\mit{min}}$ is the minimum $f$ value in the OPEN list.  While $f$
is based on an admissible heuristic function, the nodes in the focal list are expanded in the increasing order of
an inadmissible distance-to-go estimates $\hh$. Thus the search does not follow the best-first order of $f$ and is
not admissible, being only $w$-admissible. One exception is the case of $w=1$ where the focal list is equivalent
to the $f$ plateau and the expansion order in the focal list corresponds to the tiebreaking on plateaus. In our
notation, this algorithm can be written as a BFS with
\[
 [ \lceil \frac{f}{w\cdot f_{\mit{min}}} \rceil, \hh, \mit{default}]
\]
because the focal list ``blur''s $f$ up to $w\cdot f_{\mit{min}}$. For example, when $w=2, f_{\mit{min}}=5$ and
$f(n)=5,9,11$, then $\lceil \frac{f}{w\cdot f_{\mit{min}}} \rceil=1,1,2$ respectively. 
% However, actual implementation may differ because $f_{\mit{min}}$ is updated dynamically.

Continuing this work, \shortciteauthor{thayer2009using} \citeyear{thayer2009using,thayer2011bounded}
evaluated various distance-to-go configurations of Weighted
\astar, Dynamically Weighted \astar \cite{pohl1973avoidance} and $A^*_\epsilon$.
Some configurations use distance-to-go as part of
tiebreaking. However, they focus on bounded-suboptimal search rather than optimal search.
% 
Also, \shortciteauthor{cushing2010cost} \citeyear{cushing2010cost} more eloquently advocated the danger of relying
on cost estimates in satisficing search by investigating ``$\varepsilon$-cost traps'' and other pitfalls caused by
using the cost estimators for search guidance. Again, this work targets satisficing search.
% 
Finally, a \sota satisficing planner FD/LAMA2011 incorporates distance-to-go estimates in its iterated search
framework. The first iteration of LAMA uses distance-to-go estimates combined with various satisficing
search enhancements.

\shortciteauthor{benton2010g} proposed an inadmissible technique for temporal planning where short actions are
hidden behind long actions and do not increase makespan \cite{benton2010g}. Such actions cause so-called ``g-value
plateau'', a similar situation caused by 0-cost actions in sequential planning.  They implemented an inadmissible
heuristic function combined with distance-to-go estimates on top of Temporal Fast Downward system
\cite{eyerich2009using}.  As stated, their method is not applicable to the optimizing search.

%% I couldnt find this in the paper now... 
%  and showing that (non-admissibly) treating all actions as unit cost sometimes finds an optimal plan quickly.
% Although it could find an optimal plan by chance, this does not guarantee the optimality of the solution.

\subsection{Distance-to-Go Estimates for Cost-Optimal Planning}

Although previous work on distance-to-go estimates assume a satisficing context,
there is still a possibility to use the same techniques for cost-optimal search.
We say that a sorting strategy is an \emph{admissible sorting strategy}
when best first search using the strategy is guaranteed to return an optimal solution.
Clearly, a sorting strategy is admissible if and only if the 
first sorting criterion $f$ is admissible (since $f=g+h$, $h$ must be an admissible heuristic).
This means that as long as the first criterion is admissible, the optimality of the solution is not affected by the
subsequent levels of sorting criterion, and therefore it is possible to use an inadmissible distance-to-go estimate
in the second (or later) level sorting criteria without sacrificing the optimality of the solution found.

Let $h$ be an admissible heuristic, and
let $\hat{h}$ be a distance-to-go variation of $h$, i.e., $\hat{h}$ uses essentially the same algorithm as $h$, except that while $h$ uses the actual action costs for the problem domain, $\hat{h}$ treats all action costs as unit cost.
%% redundunt
% Upon computing the estimates, $\hat{h}$ treats all
% actions to have unit costs, while original heuristic function $h$ uses the
% standard action cost.
Since $h$ is admissible, multi-heuristic sorting strategies such as $[g+h,h,\hat{h}]$ or $[g+h,\hat{h}]$
are admissible.

Moreover, we can even use a multi-heuristic strategy which uses an inadmissible heuristic for tiebreaking which is unrelated to the primary, admissible heuristic $h$.
 For example, $[g+h^{\lmcut},\ffo]$ is an admissible sorting strategy
because the first sorting criterion $f=g+h^{\lmcut}$ uses an admissible
\lmcut heuristic. Its second sorting criterion, the distance-to-go FF
heuristics, does not affect the admissibility of this entire sorting strategy.

A potential problem with sorting strategies which use multiple heuristics is the cost of computing additional
heuristic estimates. For example, $[g+h^{\lmcut},\ffo]$ requires more time to evaluate each node compared to a standard tiebreaking strategy such as $[g+h^{\lmcut},h^{\lmcut}]$ because computing the $\ffo$ heuristic incurs significant overhead per node while the results of $h^{\lmcut}$ can be cached.
When $\hat{h}$, the inadmissible heuristic for tiebreaking is a distance-to-go (unit cost) variant of the primary, admissible heuristic $h$, it may be possible to reduce this overhead to some extent by implementing $h$ and $\hat{h}$ so that they share some of the computation  -- this is a direction for future work.

\subsection{Evaluating Distance-to-go Estimates}

We tested various admissible sorting strategies on IPC domains and Zerocost domains.
% on zerocost domains  where tiebreaking strategies have the large impact.
The configurations are listed in \reftbl{list:distance-configs}. 
In all configurations, the first sorting criterion is the $f=g+h$ value
where $h$ is an admissible heuristic (either \lmcut or \mands) using the actual action-cost based  cost calculation.
As the second or later sorting criterion,
we tested $\hat{h}$ of original $h$, as well as a distance-to-go variation of FF
heuristic ($\hat{h}^{\ff}$).
% , and a distance-to-go variation of
% GoalCount heuristic ($\hat{h}^{\text{GoalCount}}$) which is added to
% represent an uninformative but fast inadmissible heuristic function with
% least additional overhead.
We also added configurations with the depth metric within
$\plateau{f,\hat{h}^{\text{\ff}}}$.

\begin{table}[htbp]
 \centering
 \[
 \begin{array}{lcll}
  (1)\, [h+g, & h,                           &L] \\\relax
  (2)\, [h+g, & h,     \quad   \hat{h},      &L] \\\relax
  (3)\, [h+g, & \hat{h},                     &L] \\\relax
  (4)\, [h+g, & \hat{h}^{\ff},               &L] \\\relax
  % not include it unless the reviewer complained. 
  % (5)\, [h+g, & \hat{h}^{\text{GoalCount}},  &L] \\\relax
  (5)\, [h+g, & h, \depth, &L] \\\relax
  (6)\, [h+g, & \hat{h}^{\text{FF}}, \depth, &L] \\\relax
 \end{array}  
 \]
 \caption{Configurations compared in this section. $h$ is
 one of $\braces{\lmcut, \mands}$, and $L$ is one of the default
 tiebreaking strategies $\fifo,\lifo,$ or $\ro$. }
 \label{list:distance-configs}
\end{table}

% $[h^{\lmcut}+g,\hat{h}^{\mbox{LMcount}},\fifo]$,

A summary of the results are shown in \reftbl{tbl:dtg-summary}. For
comparison, we also include the results of configurations evaluated in the previous sections.
Detailed per-domain results are shown in
\reftbls{tbl:dtg-lmcut-zero}{tbl:dtg-mands-ipc}.

\begin{table}[htbp]
 \centering
 \input{tables/8-1-summary}
 \caption{
 Summary Results: Coverage comparison (the number
 of instances solved in 5min, 4GB) between several sorting strategies.
 }
 \label{tbl:dtg-summary}
\end{table}

In Zerocost domains, we see that $\hat{h}$-tiebreaking outperforms $h$-tiebreaking for both \lmcut (e.g. $256\rightarrow 295$ with \fifo) and \mands (e.g. $280\rightarrow 308$ with \fifo).
Also, combining $h$ and $\hat{h}$ can further improve performance when the heuristic is \lmcut (e.g. $295\rightarrow 305$ with \fifo). The results with/without $\hat{h}$ are comparable when the main heuristic function $h$ is \mands.
% 
Yet more surprisingly, using $\ffo$ improved the performance by another factor in both \lmcut
(e.g. $[f,h,\hh,\fifo]:305 \rightarrow [f,\ffo,\fifo]:337$) and \mands 
(e.g. $[f,h,\hh,\fifo]:307 \rightarrow [f,\ffo,\fifo]:336$).
% 
Thus, when the depth diversity criterion  is not used, the best configurations are those
which use $\ffo$.
In detail, following domains are improved by each change:
\begin{itemize}
 \item \textbf{$h^\lmcut \to \hh^\lmcut$}: elevator-up (all), freecell-move (\fifo,\ro), mprime-succumb (all), mystery-feast (\lifo,\ro) parking-movecc (all), pipesworld-pushend (all), scanalyzer-analyze (\lifo,\ro), wood\-working-cut (all). (Compare \reftbl{})
 \item \textbf{$h^\mands \to \hh^\mands$}: elevator-up (all), freecell-move (\fifo,\ro), mprime-succumb (\ro), mystery-feast (\fifo,\lifo) parking-movecc (all), pipesworld-pushend (all), scanalyzer-analyze (all), wood\-working-cut (all), zenotravel-fuel (\lifo,\ro).
 \item \textbf{$h^\lmcut \to h^\lmcut,\hh^\lmcut$}: airport-fuel (\fifo,\ro), mprime-succumb (\fifo,\ro), parking-movecc (\lifo), pipesworld-pushend (\fifo), scanalyzer-analyze (all).
 \item \textbf{$h^\lmcut,\hh^\lmcut \to \ffo$}: blocks-stack (all), freecell-move (all), hiking-fuel (all), miconic-up (all), mprime-succumb (all), parking-movecc (all), pipesworld-pushend (all), sokoban-pushgoal (all), tidybot-motion (all), tpp-fuel (\ro).
 \item \textbf{$h^\mands,\hh^\mands \to \ffo$}: airport-fuel (all), elevator-up (all), freecell-move (all), miconic-up (all), mprime-succumb (all), parking-movecc (all), pipesnt-pushstart (all), scanalyzer-analyze (all), sokoban-pushgoal (all), tpp-fuel (\ro).
\end{itemize}
 
Adding the depth diversity criterion further improves the performance of the $\ffo$-based strategies,
 although the impact was small.
The coverage increased in both
 $h=h^\lmcut$ (\fifo: $337\rightarrow 340$, \lifo: $340\rightarrow 342$, \ro: $341\rightarrow 344.3$) and
 $h=h^\mands$ (\fifo: $336\rightarrow 337$, \lifo: $331\rightarrow 333$).
Improvement was observed in the following domains:
\begin{itemize}
 \item \textbf{\lmcut}: mprime-succumb (\lifo, \ro), storage-lift (\ro), tidybot-motion (\fifo), tpp-fuel (\fifo, \ro).
 \item \textbf{\mands}: mprime-succumb (\lifo, \ro), tpp-fuel (\fifo).
\end{itemize}
When the default tiebreaking was \ro and the heuristic is \mands, $[f,\ffo,\depth,\ro]$ have small degradation
over $[f,\ffo,\ro]$, but the difference was fractional ($337.9\rightarrow 337.6$) and $\depth$ made the performance slightly more robust (smaller standard deviation: $2.1\rightarrow 1.3$).

For the standard IPC benchmark instances, the overhead due to the additional computation of
$\hat{h}$ or $\ffo$ tends to harm the overall performance.
% The only domains consistently enhanced by distance-to-go estimates are \pddl{mprime} using \lmcut,
% \pddl{parcprinter-opt11} using \mands and \pddl{woodworking-opt11} using \mands. Moreover, their improvements are small.
Therefore, the best configuration using \lmcut was
$[f,h,\depth,\lifo]$ which uses depth and does not impose the cost of
additional heuristics, and the best result using \mands
was $[f,h,\lifo]$ which imposes no overhead including the depth.

If we look further into the detail, we observed the following:
In \pddl{Cybersec}, distance-to-go variants (e.g. $[f^\lmcut,\ffo,\lifo]$:5) improve upon the standard strategy (e.g. $[f^\lmcut,h^\lmcut,\lifo]$:3), but does not improve upon depth (e.g. $[f,h,\depth,\lifo]$: 12). When $h=h^\mands$, all coverages are zero. Overheads by $\ffo$ also slightly degrade the performance in Openstacks (e.g. $[f^\lmcut,h^\lmcut,\lifo]$:18, $[f^\lmcut,\ffo,\lifo]$:17, $[f^\lmcut,h^\lmcut,\depth,\lifo]$: 18; Also, $[f^\mands,h^\mands,\lifo]$:19, $[f^\mands,\ffo,\lifo]$:18, $[f^\mands,h^\mands,\depth,\lifo]$: 19). Thus, in these two domains, although there are some positive effects in the guidance by $\ffo$ or $\hh$, additional overheads by those distance-to-go heuristics outweighed the merit.
 
In the positive-cost domains (IPC domains except \pddl{Openstacks} and \pddl{Cybersec}), $\hat{h}$ or $\ffo$
only harms the overall performance due to the overhead.
When the primary heuristics is \lmcut, we do not observe significant difference between single-heuristics strategies except for the fractional difference in the configurations using \ro.
When it is \mands, $[f^\mands,h^\mands,\lifo]$ slightly gains advantage over other default tiebreaking strategies; It also outperforms the depth-based variants as we already discussed in \refsec{sec:depth-based-evaluation}.
%  (\reftbl{tbl:dtg-lmcut-ipc} and \reftbl{tbl:dtg-mands-ipc}).

{
\setlength{\tabcolsep}{0.1em}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:lmcut-zerocost-full}}.
 }
 \label{tbl:dtg-lmcut-zero}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:mands-zerocost-full}}.
 }
 \label{tbl:dtg-mands-zero}
 }
\end{table}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-lmcut-ipc}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-mands-ipc} }
\end{table}
}

\clearpage
\subsection{Simple Dynamic Configuration for Overall Performance}

The performance degradation by the multi-heuristic strategy in positive cost domains is not of a practical issue.
This is because we can consider a simple case-based configuration scheme which selects a multi-heuristic strategy when there are any zerocost actions in the domain, and a single-heuristic strategy otherwise.

Since such a check has only a negligible impact on the total runtime, we can simulate and estimate the results of such configurations without running it.
Coverage results in \reftbl{tbl:dtg-summary-sum} show the total coverage of
zerocost and benchmark domains. The bottom two rows, labeled as \emph{dynamic configuration},
are such estimated results of the switching behavior, and it achieves the highest coverage.

\begin{table}[htbp]
 \centering \input{tables/8-1-summary-sum}
 \caption{
 % 
 Summary Results: Coverage comparison, the total of IPC domains and Zerocost domains (the number of instances
 solved in 5min, 4GB) between several sorting strategies, plus a dynamic configuration strategy.  $[f,h,\fifo],
 [f,h,\ro], [f,\hh,\cdot], [f,h, \hh,\cdot], [f,\ffo,\cdot]$ are not shown because they achieve smaller coverage.
 % 
 }
 \label{tbl:dtg-summary-sum}
\end{table}

In standard IPC instances, the domains with zero-cost actions are \pddl{Cybersec} and \pddl{Openstacks} only. They are solved in a multi-heuristic sorting strategy while other domains are solved in the best performing single-heuristic strategy. In Zerocost instances, all domains are solved in multi-heuristic sorting strategy.
\todo*{Maybe we should show dynamic configuration results in the detailed per-domain tables, just so that it's obvious that we can get ``dominant'', state-of-the-art  behavior --- results are simulated, not actually implemented. Thus the total results should be fine. However, I added exactly which domains were zero-cost.}.

% While these multi-heuristic strategies did not improve the perfomance in
% the positive cost domains because the final plateaus are small, a simple
% method which 


Overall, these results also strengthen our claim that $h$-based
tiebreaking is not necessarily the ``rule of the thumb'' in some
domains, as already discussed in \refsec{sec:noh}. In zerocost domains,
using a distance-to-go version of an inadmissible heuristic function for
tiebreaking is more effective. Also, combining the depth metric with
such an inadmissible heuristics is also effective.
