\clearpage
\section{Distance-to-Go Estimates}

\label{sec:distance-to-go}

We next compare our depth diversification to the distance-to-go
estimates in the plateau.  Distance-to-go estimates are the type of
heuristics which treat actions as if they have the unit cost. Even under
the presence of zero-cost actions, those estimates can predict the
number of operations required to reach a goal.
While several papers advocates the benefit of this technique, many of
these claims took place in the context of satisficing planning.
\todo*{Need more complete  survey of previous work on d2go heuristics in best-first search (not just planning) here: Thayer+Ruml ICAPS09,Socs09; connectoins to FOCAL method of Pearl and Kim}

Except for cases where the target domains are unit-cost by origin, $A^*_\epsilon$ \cite{pearl1982studies} is one of
the earliest algorithms that combines distance-to-go estimates with the cost estimates. It is a bounded-suboptimal
search which expands from the \emph{focal} list, the set of nodes with $f(n)\leq w\cdot f_{\mit{min}}$ where $w$ is
a cost bound in a sense of $\mit{WA}^*$ and $f_{\mit{min}}$ is the minimum $f$ value in the OPEN list.  While $f$
is based on an admissible heuristic function, the nodes in the focal list are expanded in the increasing order of
an inadmissible distance-to-go estimates $\hh$. Thus the search does not follow the best-first order of $f$ and is
not admissible, being only $w$-admissible. One exception is the case of $w=1$ where the focal list is equivalent
to the $f$ plateau and the expansion order in the focal list corresponds to the tiebreaking on plateaus. In our
notation, this algorithm can be written as a BFS with
\[
 [ \lceil \frac{f}{w\cdot f_{\mit{min}}} \rceil, \hh, \mit{default}]
\]
because the focal list ``blur''s $f$ up to $w\cdot f_{\mit{min}}$. For example, when $w=2, f_{\mit{min}}=5$ and
$f(n)=5,9,11$, then $\lceil \frac{f}{w\cdot f_{\mit{min}}} \rceil=1,1,2$ respectively. 
% However, actual implementation may differ because $f_{\mit{min}}$ is updated dynamically.

Continuing this work, \shortciteauthor{thayer2009using} evaluated various distance-to-go configurations of Weighted
\astar, Dynamically Weighted \astar \cite{pohl1973avoidance} and $A^*_\epsilon$
\citeyear{thayer2009using,thayer2011bounded}. Some configurations use distance-to-go as part of
tiebreaking. However, they focus on bounded-suboptimal search rather than optimal search.
% 
Also, \shortciteauthor{cushing2010cost} \citeyear{cushing2010cost} more eloquently advocated the danger of relying
on cost estimates in satisficing search by investigating ``$\varepsilon$-cost traps'' and other pitfalls caused by
using the cost estimators for search guidance. Again, this work targets satisficing search.
% 
Finally, a \sota satisficing planner FD/LAMA2011 incorporates distance-to-go estimates in its iterated search
framework. The first iteration of LAMA uses distance-to-go estimates combined with various satisficing
search enhancements.

\shortciteauthor{benton2010g} proposed an inadmissible technique for temporal planning where short actions are
hidden behind long actions and do not increase makespan \cite{benton2010g}. Such actions cause so-called ``g-value
plateau'', a similar situation caused by 0-cost actions in sequential planning.  They implemented an inadmissible
heuristic function combined with distance-to-go estimates on top of Temporal Fast Downward system
\cite{eyerich2009using}.  As stated, their method is not applicable to the optimizing search.

%% I couldnt find this in the paper now... 
%  and showing that (non-admissibly) treating all actions as unit cost sometimes finds an optimal plan quickly.
% Although it could find an optimal plan by chance, this does not guarantee the optimality of the solution.

\subsection{Distance-to-Go Estimates for Cost-Optimal Planning}

Although previous work on distance-to-go estimates assume a satisficing context,
there is still a possibility to use the same techniques for cost-optimal search.
We say that a sorting strategy is an \emph{admissible sorting strategy}
when best first search using the strategy is guaranteed to return an optimal solution.
Clearly, a sorting strategy is admissible if and only if the 
first sorting criterion $f$ is admissible (since $f=g+h$, $h$ must be an admissible heuristic).
This means that as long as the first criterion is admissible, the optimality of the solution is not affected by the
subsequent levels of sorting criterion, and therefore it is possible to use an inadmissible distance-to-go estimate
in the second (or later) level sorting criteria without sacrificing the optimality of the solution found.

Let $h$ be an admissible heuristic, and
let $\hat{h}$ be a distance-to-go variation of $h$, i.e., $\hat{h}$ uses essentially the same algorithm as $h$, except that while $h$ uses the actual action costs for the problem domain, $\hat{h}$ treats all action costs as unit cost.
%% redundunt
% Upon computing the estimates, $\hat{h}$ treats all
% actions to have unit costs, while original heuristic function $h$ uses the
% standard action cost.
Since $h$ is admissible, multi-heuristic sorting strategies such as $[g+h,h,\hat{h}]$ or $[g+h,\hat{h}]$
are admissible.

Moreover, we can even use a multi-heuristic strategy which uses an inadmissible heuristic for tiebreaking which is unrelated to the primary, admissible heuristic $h$.
 For example, $[g+h^{\lmcut},\ffo]$ is an admissible sorting strategy
because the first sorting criterion $f=g+h^{\lmcut}$ uses an admissible
\lmcut heuristic. Its second sorting criterion, the distance-to-go FF
heuristics, does not affect the admissibility of this entire sorting strategy.

A potential problem with sorting strategies which use multiple heuristics is the 
the cost of computing additional
heuristic estimates. For example, $[g+h^{\lmcut},\ffo]$ requires more time to evaluate each node compared to a standard tiebreaking strategy such as $[g+h^{\lmcut},h^{\lmcut}]$ because computing the $\ffo$ heuristic incurs significant overhead per node while the results of $h^{\lmcut}$ can be cached.
When $\hat{h}$, the inadmissible heuristic for tiebreaking is a distance-to-go (unit cost) variant of the primary, admissible heuristic $h$, it may be possible to reduce this overhead to some extent by implementing $h$ and $\hat{h}$ so that they share some of the computation  -- this is a direction for future work.

\subsection{Evaluating Distance-to-go Estimates}

We tested various admissible sorting strategies on IPC domains and Zerocost domains.
% on zerocost domains  where tiebreaking strategies have the large impact.
The configurations are listed in \reftbl{list:distance-configs}. 
In all configurations, the first sorting criterion is the $f=g+h$ value
where $h$ is an admissible heuristic (either \lmcut or \mands) using the actual action-cost based  cost calculation.
As the second or later sorting criterion,
we tested $\hat{h}$ of original $h$, as well as a distance-to-go variation of FF
heuristic ($\hat{h}^{\ff}$).
% , and a distance-to-go variation of
% GoalCount heuristic ($\hat{h}^{\text{GoalCount}}$) which is added to
% represent an uninformative but fast inadmissible heuristic function with
% least additional overhead.
We also added configurations with the depth metric within
$\plateau{f,\hat{h}^{\text{\ff}}}$.

\begin{table}[htbp]
 \centering
 \[
 \begin{array}{lcll}
  (1)\, [h+g, & h,                           &L] \\\relax
  (2)\, [h+g, & h,     \quad   \hat{h},      &L] \\\relax
  (3)\, [h+g, & \hat{h},                     &L] \\\relax
  (4)\, [h+g, & \hat{h}^{\ff},               &L] \\\relax
  % not include it unless the reviewer complained. 
  % (5)\, [h+g, & \hat{h}^{\text{GoalCount}},  &L] \\\relax
  (5)\, [h+g, & h, \depth, &L] \\\relax
  (6)\, [h+g, & \hat{h}^{\text{FF}}, \depth, &L] \\\relax
 \end{array}  
 \]
 \caption{Configurations compared in this section. $h$ is
 one of $\braces{\lmcut, \mands}$, and $L$ is one of the default
 tiebreaking strategies $\fifo,\lifo,$ or $\ro$. }
 \label{list:distance-configs}
\end{table}

% $[h^{\lmcut}+g,\hat{h}^{\mbox{LMcount}},\fifo]$,

A summary of the results are shown in \reftbl{tbl:dtg-summary}. For
comparison, we also include the results of configurations evaluated in the previous sections.
Detailed per-domain results are shown in
\reftbls{tbl:dtg-lmcut-zero}{tbl:dtg-mands-ipc}.

In Zerocost domains, we see that $\hat{h}$-tiebreaking outperforms $h$-tiebreaking for both \lmcut (e.g. $256\rightarrow 295$ with \fifo) and \mands (e.g. $280\rightarrow 308$ with \fifo). Also,
combining $h$ and $\hat{h}$ can further improve performance when the heuristic is  \lmcut (e.g. $295\rightarrow 305$ with \fifo).  The results with/without $\hat{h}$ are comparable when
the main heuristic function $h$ is \mands.  
% 
Yet more surprisingly, using $\ffo$ improved the performance by another factor in both \lmcut
(e.g. $[f,h,\hh,\fifo]:305 \rightarrow [f,\ffo,\fifo]:337$) and \mands 
(e.g. $[f,h,\hh,\fifo]:307 \rightarrow [f,\ffo,\fifo]:336$).
% 
Thus, when the depth diversity criterion  is not used, the best configurations are those
which use $\ffo$.
% 
Finally, adding depth diversity criterion further improves the performance of the $\ffo$-based strategies.
 The coverage increased in both $h=h^\lmcut$ (\fifo: $337\rightarrow 340$, \lifo: $340\rightarrow
342$, \ro: $341\rightarrow 344.3$) and $h=h^\mands$ (\fifo: $336\rightarrow 337$, \lifo: $331\rightarrow
333$). When the default tiebreaking was \ro and the heuristic is \mands, $[f,\ffo,\depth,\ro]$ did not improve
over $[f,\ffo,\ro]$, but the coverage difference was small ($337.9\rightarrow 337.6$) and $\depth$ made the performance slightly more robust (smaller variance: $2.1\rightarrow 1.3$).

For standard IPC benchmark instances, the overhead due to the additional computation of
$\hat{h}$ or $\ffo$ tends to harm the overall performance.
% The only domains consistently enhanced by distance-to-go estimates are \pddl{mprime} using \lmcut,
% \pddl{parcprinter-opt11} using \mands and \pddl{woodworking-opt11} using \mands. Moreover, their improvements are small.
Therefore, the best configuration using \lmcut was
$[f,h,\depth,\lifo]$ which uses depth and does not impose the cost of
additional heuristics, and the best result using \mands
was $[f,h,\lifo]$ which impose the least overhead on the fast expansion offered by
\mands heuristics.
% However, 
% zerocost domains in this standard benchmark set (Openstacks and
% Cybersec) has each shown a significant speedup achieved by these distance-to-go estimates
%  (\reftbl{tbl:dtg-lmcut-ipc} and \reftbl{tbl:dtg-mands-ipc}).

The performance degradation in the positive cost domains is not a practical issue,
because we can simply configure the search algorithm to use depth diversification or not  before running the
search, depending on whether the domain contains zerocost actions or not.
Coverage results in \reftbl{tbl:dtg-summary-sum} show the total of
zerocost and benchmark domains. The \emph{dynamic configuration}, which implements this 
switching behavior, achieves the highest coverage.

% While these multi-heuristic strategies did not improve the perfomance in
% the positive cost domains because the final plateaus are small, a simple
% method which 

Overall, these results also strengthen our claim that $h$-based
tiebreaking is not necessarily the ``rule of the thumb'' in some
domains, as already discussed in \refsec{sec:noh}. In zerocost domains,
using a distance-to-go version of an inadmissible heuristic function for
tiebreaking is more effective. Also, combining the depth metric with
such an inadmissible heuristics is also effective.\todo{Maybe we should show dynamic configuration results in the detailed per-domain tables, just so that it's obvious that we can get ``dominant'', state-of-the-art  behavior}.


\begin{table}[htbp]
 \centering
 \input{tables/8-1-summary}
 \caption{
 Summary Results: Coverage comparison (the number
 of instances solved in 5min, 4GB) between several sorting strategies.
 }
 \label{tbl:dtg-summary}
\end{table}

\begin{table}[htbp]
 \centering \input{tables/8-1-summary-sum}
 \caption{ Summary Results:
 Coverage comparison, the total of IPC domains and Zerocost domains (the
 number of instances solved in 5min, 4GB) between several sorting
 strategies, plus a dynamic configuration strategy which selects the
 right behavior checking whether zero-cost actions exist.  }
 \label{tbl:dtg-summary-sum}
\end{table}

\setlength{\tabcolsep}{0.1em}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:lmcut-zerocost-full}}.
 }
 \label{tbl:dtg-lmcut-zero}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:mands-zerocost-full}}.
 }
 \label{tbl:dtg-mands-zero}
 }
\end{table}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-lmcut-ipc}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-mands-ipc} }
\end{table}

