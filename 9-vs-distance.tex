\clearpage
\section{Tie-Breaking Using Distance-to-Go Estimates}

\label{sec:distance-to-go}
In the previous section, we proposed a view of cost-optimal search as a series of satisficing searches on each $f$-cost plateau, and argued that 
the problem of tiebreaking can be reduced to a satisficing search.
In this section, we use this insight to propose another approach to improving the
search performance in plateaus produced by zerocost domains --
using inadmissible \emph{distance-to-go} estimates (heuristics) as a tiebreaking criterion within an admissible A* search.

% ; This allows the heuristics to be
% inadmissible when it is only used for tiebreaking strategy.

% The obvious
% drawback of this strategy is the cost of additional heuristic
% computation.

% We next compare our depth diversification to the distance-to-go
% estimates in the plateau.  
Distance-to-go estimates are a class of
heuristics which treat all actions as if they have the unit cost. Even under
the presence of zero-cost actions, those estimates can predict the
number of operations required to reach a goal.
While several papers advocate the benefit of this technique, the preivious work has focused on 
distance-go-to estimates in the context of satisficing planning.
\todo*{Need more complete  survey of previous work on d2go heuristics in best-first search (not just planning) here: Thayer+Ruml ICAPS09,Socs09; connectoins to FOCAL method of Pearl and Kim}

Except for cases where the target domains are unit-cost by origin, {\bf [don't understand previous clause -- are you saying that in cases where the target domains are originally unit-cost, there were d2go estimates before  $A^*_\epsilon$ ??]}
$A^*_\epsilon$ \cite{pearl1982studies} is one of
the earliest algorithms that combines distance-to-go estimates with the cost estimates. It is a bounded-suboptimal
search which expands from the \emph{focal} list, the set of nodes with $f(n)\leq w\cdot f_{\mit{min}}$ where weight $w$ serves as a suboptimality bound, similar to weighted \astar, 
 and $f_{\mit{min}}$ is the minimum $f$ value in the OPEN list.  While $f$
is based on an admissible heuristic function, the nodes in the focal list are expanded in increasing order of
an inadmissible distance-to-go estimates $\hh$. Thus, the search does not follow the best-first order of $f$ and is
not admissible, being only $w$-admissible. One exception is the case of $w=1$ where the focal list is equivalent
to the $f$ plateau and the expansion order in the focal list corresponds to the tiebreaking on plateaus. In our
notation, this algorithm can be written\footnote{
However, an actual implementation may differ due to dynamic updates to $f_{\mit{min}}$.}
as a BFS with
\[
 [ \lceil \frac{f}{w\cdot f_{\mit{min}}} \rceil, \hh, \mit{default}]
\]
where \textit{default} is one of \fifo, \lifo or \ro.
This is because the focal list ``blur''s $f$ up to $w\cdot f_{\mit{min}}$.
For example, when $w=2, f_{\mit{min}}=5$ and
$f(n)=5,9,11$, then $\lceil \frac{f}{w\cdot f_{\mit{min}}} \rceil=1,1,2$ respectively. 

Continuing this line of work, \shortciteauthor{thayer2009using} \citeyear{thayer2009using,thayer2011bounded}
evaluated various distance-to-go configurations of Weighted
\astar, Dynamically Weighted \astar \cite{pohl1973avoidance} and $A^*_\epsilon$.
Some configurations use distance-to-go as part of
tiebreaking while they focus on bounded-suboptimal search rather than cost-optimal search.
% 
\shortciteauthor{cushing2010cost} \citeyear{cushing2010cost} pointed out the danger of relying  % neutral tone
on cost estimates in a satisficing search by investigating ``$\varepsilon$-cost traps'' and other pitfalls caused by
cost estimators for search guidance. % Again, this work targets satisficing search. %''satisficing search'' appears in previous sentence.
% 
Finally, a \sota satisficing planner FD/LAMA2011 incorporates distance-to-go estimates in its iterated search
framework. The first iteration of LAMA uses distance-to-go estimates combined with various satisficing
search enhancements.

In temporal planning, \shortciteauthor{benton2010g} proposed an inadmissible technique where short actions are
hidden behind long actions and do not increase makespan \cite{benton2010g}. Such actions cause so-called ``g-value
plateau'', a similar situation caused by 0-cost actions in sequential planning.  They implemented an inadmissible
heuristic function combined with distance-to-go estimates on top of Temporal Fast Downward system
\cite{eyerich2009using}.  As stated, their method is not applicable to the cost-optimal search.

%% I couldnt find this in the paper now... 
%  and showing that (non-admissibly) treating all actions as unit cost sometimes finds an optimal plan quickly.
% Although it could find an optimal plan by chance, this does not guarantee the optimality of the solution.

\subsection{Embedding Distance-to-Go Estimates in Admissible Search}

Although previous work on distance-to-go estimates assume a satisficing context,
there is still a possibility to use the same techniques for cost-optimal search.
We say that a sorting strategy is an \emph{admissible sorting strategy}
when Best First Search using the strategy is guaranteed to return a cost-optimal solution.
Clearly, a sorting strategy is admissible if and only if the 
first sorting criterion $f$ is admissible (since $f=g+h$, $h$ must be an admissible heuristic).
This means that as long as the first criterion is admissible, the optimality of the solution is not affected by the
subsequent levels of sorting criteria, and therefore, it is possible to use an inadmissible distance-to-go estimate
in the second (or later) level sorting criteria without sacrificing the optimality of the solution found.

Let $h$ be an admissible heuristic, and
let $\hat{h}$ be a distance-to-go variation of $h$, i.e., $\hat{h}$ uses essentially the same algorithm as $h$, except that while $h$ uses the actual action costs for the problem domain, $\hat{h}$ treats all action costs as unit cost.
%% redundunt
% Upon computing the estimates, $\hat{h}$ treats all
% actions to have unit costs, while original heuristic function $h$ uses the
% standard action cost.
Since $h$ is admissible, multi-heuristic sorting strategies such as $[g+h,h,\hat{h}]$ or $[g+h,\hat{h}]$
are admissible.

Moreover, we can even use a multi-heuristic strategy which uses an inadmissible heuristic for tiebreaking which is unrelated to the primary, admissible heuristic $h$.
 For example, $[g+h^{\lmcut},\ffo]$ is an admissible sorting strategy
because the first sorting criterion $f=g+h^{\lmcut}$ uses an admissible
\lmcut heuristic. Its second sorting criterion, the distance-to-go FF
heuristics \cite{Hoffmann01}, does not affect the admissibility of this entire sorting strategy.

A potential problem with sorting strategies which use multiple heuristics is the cost of computing additional
heuristic estimates. For example, $[g+h^{\lmcut},\ffo]$ requires more time to evaluate each node compared to a standard tiebreaking strategy such as $[g+h^{\lmcut},h^{\lmcut}]$ because computing the $\ffo$ heuristic incurs significant overhead per node while the results of $h^{\lmcut}$ can be reused by a caching mechanism.
When the inadmissible heuristic for tiebreaking is $\hat{h}$, i.e. a distance-to-go (unit cost) variant of the primary, admissible heuristic $h$, it may be possible to reduce this overhead to some extent by implementing $h$ and $\hat{h}$ so that they share some of the computation  -- this is a direction for future work.

\subsection{Evaluating Distance-to-go Estimates}

We tested various admissible sorting strategies on IPC domains and Zerocost domains.
% on zerocost domains  where tiebreaking strategies have the large impact.
The configurations are listed in \reftbl{list:distance-configs}. 
In all configurations, the first sorting criterion is the $f=g+h$ value
where $h$ is an admissible heuristic (either \lmcut or \mands) using the actual action-cost based  cost calculation.
As the second (and third) criteria,
we used $\hat{h}$, the distanc-to-go version tested  of the original heuristic function $h$ , as well as a distance-to-go variation of FF
heuristic ($\hat{h}^{\ff}$).
% , and a distance-to-go variation of
% GoalCount heuristic ($\hat{h}^{\text{GoalCount}}$) which is added to
% represent an uninformative but fast inadmissible heuristic function with
% least additional overhead.
We also added configurations with the depth metric within
$\plateau{f,\hat{h}^{\text{\ff}}}$.

\begin{table}[htbp]
 \centering
 \[
 \begin{array}{lcll}
  (1)\, [h+g, & h,                           &L] \\\relax
  (2)\, [h+g, & h,     \quad   \hat{h},      &L] \\\relax
  (3)\, [h+g, & \hat{h},                     &L] \\\relax
  (4)\, [h+g, & \hat{h}^{\ff},               &L] \\\relax
  % not include it unless the reviewer complained. 
  % (5)\, [h+g, & \hat{h}^{\text{GoalCount}},  &L] \\\relax
  (5)\, [h+g, & h, \depth, &L] \\\relax
  (6)\, [h+g, & \hat{h}^{\text{FF}}, \depth, &L] \\\relax
 \end{array}  
 \]
 \caption{Configurations compared in this section. $h$ is
 one of $\braces{\lmcut, \mands}$, and $L$ is one of the default
 tiebreaking strategies $\fifo,\lifo,$ or $\ro$. }
 \label{list:distance-configs}
\end{table}

% $[h^{\lmcut}+g,\hat{h}^{\mbox{LMcount}},\fifo]$,

A summary of the results is shown in \reftbl{tbl:dtg-summary}. For
comparison, we also include the results of configurations evaluated in the previous sections.
Detailed per-domain results are shown in
\reftbls{tbl:dtg-lmcut-zero}{tbl:dtg-mands-ipc}.

\begin{table}[htbp]
 \centering
 \input{tables/8-1-summary}
 \caption{
 Summary Results: Coverage comparison (the number
 of instances solved in 5min, 4GB) between several sorting strategies.
 }
 \label{tbl:dtg-summary}
\end{table}

In Zerocost domains, we see that $\hat{h}$-tiebreaking outperforms $h$-tiebreaking for both \lmcut (e.g. $256\rightarrow 295$ with \fifo) and \mands (e.g. $280\rightarrow 308$ with \fifo).
Also, combining $h$ and $\hat{h}$ can further improve performance when the heuristic is \lmcut (e.g. $295\rightarrow 305$ with \fifo).
The results of combining $h$ and $\hh$ was comparable to $\hh$ when the main heuristic function $h$ is \mands.
% 
Yet more surprisingly, using $\ffo$ further improved the performance for both \lmcut
(e.g. $[f,h,\hh,\fifo]:305 \rightarrow [f,\ffo,\fifo]:337$) and \mands 
(e.g. $[f,h,\hh,\fifo]:307 \rightarrow [f,\ffo,\fifo]:336$).
% 
Thus, when the depth diversity criterion  is not used, the best configurations are those
which use $\ffo$.
In detail, following domains are improved by each change:
\begin{itemize}
 \item \textbf{$h^\lmcut \to \hh^\lmcut$}: \pddl{elevator-up} (all), \pddl{freecell-move} (\fifo,\ro), \pddl{mprime-succumb} (all), \pddl{mystery-feast} (\lifo,\ro) \pddl{parking-movecc} (all), \pddl{pipesworld-pushend} (all), \pddl{scanalyzer-analyze} (\lifo,\ro), \pddl{wood\-working-cut} (all). (Compare \reftbl{tbl:lmcut-zerocost-full} and \reftbl{tbl:dtg-lmcut-zero}.)
 \item \textbf{$h^\mands \to \hh^\mands$}: elevator-up (all), \pddl{freecell-move} (\fifo,\ro), \pddl{mprime-succumb} (\ro), \pddl{mystery-feast} (\fifo,\lifo) \pddl{parking-movecc} (all), \pddl{pipesworld-pushend} (all), \pddl{scanalyzer-analyze} (all), wood\-working-cut (all), \pddl{zenotravel-fuel} (\lifo,\ro). (Compare \reftbl{tbl:mands-zerocost-full} and \reftbl{tbl:dtg-mands-zero}.)
 \item \textbf{$\hh^\lmcut \to h^\lmcut,\hh^\lmcut$}: \pddl{airport-fuel} (\fifo,\ro), \pddl{mprime-succumb} (\fifo,\ro), \pddl{parking-movecc} (\lifo), \pddl{pipesworld-pushend} (\fifo), \pddl{scanalyzer-analyze} (all).
 \item \textbf{$\hh^\mands \to h^\mands,\hh^\mands$}: comparable.
 \item \textbf{$h^\lmcut,\hh^\lmcut \to \ffo$}: \pddl{blocks-stack} (all), \pddl{freecell-move} (all), \pddl{hiking-fuel} (all), \pddl{miconic-up} (all), \pddl{mprime-succumb} (all), \pddl{parking-movecc} (all), \pddl{pipesworld-pushend} (all), \pddl{sokoban-pushgoal} (all), \pddl{tidybot-motion} (all), \pddl{tpp-fuel} (\ro).
 \item \textbf{$h^\mands,\hh^\mands \to \ffo$}: \pddl{airport-fuel} (all), elevator-up (all), \pddl{freecell-move} (all), \pddl{miconic-up} (all), \pddl{mprime-succumb} (all), \pddl{parking-movecc} (all), \pddl{pipesnt-pushstart} (all), \pddl{scanalyzer-analyze} (all), \pddl{sokoban-pushgoal} (all), \pddl{tpp-fuel} (\ro).
\end{itemize}
 
Adding the depth diversity criterion further improves the performance of the $\ffo$-based strategies,
 although the impact was small.
The coverage increased in both
 $h=h^\lmcut$ (\fifo: $337\rightarrow 340$, \lifo: $340\rightarrow 342$, \ro: $341\rightarrow 344.3$) and
 $h=h^\mands$ (\fifo: $336\rightarrow 337$, \lifo: $331\rightarrow 333$).
Improvement was observed in the following domains:
\begin{itemize}
 \item \textbf{\lmcut}: \pddl{mprime-succumb} (\lifo, \ro), \pddl{storage-lift} (\ro), \pddl{tidybot-motion} (\fifo), \pddl{tpp-fuel} (\fifo, \ro).
 \item \textbf{\mands}: \pddl{mprime-succumb} (\lifo, \ro), \pddl{tpp-fuel} (\fifo).
\end{itemize}
When the default tiebreaking was \ro and the heuristic is \mands, $[f,\ffo,\depth,\ro]$ performed slightly worse than 
$[f,\ffo,\ro]$, but the difference was very small  ($337.9\rightarrow 337.6$) and $\depth$ made the performance slightly more robust (smaller standard deviation: $2.1\rightarrow 1.3$).

For the standard IPC benchmark instances, the overhead due to the additional computation of
$\hat{h}$ or $\ffo$ tends to harm the overall performance.
% The only domains consistently enhanced by distance-to-go estimates are \pddl{mprime} using \lmcut,
% \pddl{parcprinter-opt11} using \mands and \pddl{woodworking-opt11} using \mands. Moreover, their improvements are small.
Therefore, the best configuration using \lmcut was
$[f,h,\depth,\lifo]$ which uses depth and does not impose the cost of
additional heuristics, and the best result using \mands
was $[f,h,\lifo]$ which imposes no overhead including the depth.

If we look further into the detail, we observed the following:
In \pddl{Cybersec}, distance-to-go variants (e.g. $[f^\lmcut,\ffo,\lifo]$:5) improve upon the standard strategy (e.g. $[f^\lmcut,h^\lmcut,\lifo]$:3), but does not improve upon depth (e.g. $[f,h,\depth,\lifo]$: 12). When $h=h^\mands$, all coverages are zero. Overheads by $\ffo$ also slightly degrade the performance in \pddl{Openstacks} (e.g. $[f^\lmcut,h^\lmcut,\lifo]$:18, $[f^\lmcut,\ffo,\lifo]$:17, $[f^\lmcut,h^\lmcut,\depth,\lifo]$: 18; Also, $[f^\mands,h^\mands,\lifo]$:19, $[f^\mands,\ffo,\lifo]$:18, $[f^\mands,h^\mands,\depth,\lifo]$: 19). Thus, in these two domains, although there are some improvements in search efficiency due to the guidance by $\ffo$ or $\hh$, the runtime overhead of computing the  distance-to-go heuristics outweighed the merit.
 
In the domains with only positive cost actions (all IPC domains except \pddl{Openstacks} and \pddl{Cybersec}), $\hat{h}$ or $\ffo$
only harms the overall performance due to the overhead.
When the primary heuristics is \lmcut, we do not observe a significant difference between single-heuristics strategies except for the fractional difference in the configurations using \ro.
When the primary heuristic is  \mands, $[f^\mands,h^\mands,\lifo]$ performs slightly better than  other default tiebreaking strategies; It also outperforms the depth-based variants as we already discussed in \refsec{sec:depth-based-evaluation}.
%  (\reftbl{tbl:dtg-lmcut-ipc} and \reftbl{tbl:dtg-mands-ipc}).


% sentences below were moved from section which proposes f*SAT -- is this the right location?
The reason for the good performance of $[f^{\lmcut},\ffo,\fifo]$ is not surprising:
$\ffo$ is by itself known to be a powerful inadmissible heuristic  % let's avoid using \sota to describe relatively ``old'' heuristics like ff (where ``relatively old'': 10yrs).
function for satisficing GBFS, and 
if we ignore the first sorting criterion, $[f^{\lmcut},\ffo,\fifo]$ is a GBFS with $[\ffo,\fifo]$.

\pagebreak[3]

Thus, to recapitulate, our conclusions are the follows:
{\bf [XXXTODO: this looks like a powerpoint slide, and also has too much bf. Convert to a table]}
\begin{itemize}
 \item When the \textbf{primary heuristics is \lmcut}, the best performer under
       \begin{itemize}
        \item \textbf{Zerocost domains} is $[f,\ffo,\depth,\ro]$.
        \item \textbf{Zerocost IPC domains (\pddl{Cybersec}, \pddl{Openstacks})} is $[f,h,\depth,\lifo]$.
        \item \textbf{Positive-cost IPC domains} is $[f,h, \text{any default tiebreaking}]$ or $[f,h, \depth, \text{any default tiebreaking}]$.
       \end{itemize}
 \item When the \textbf{primary heuristics is \mands}, the best performer under
       \begin{itemize}
        \item \textbf{Zerocost domains} is $[f,\ffo,\ro]$ or $[f,\ffo,\depth,\ro]$, but the latter has
              a smaller variance.
        \item \textbf{Zerocost IPC domains (\pddl{Cybersec}, \pddl{Openstacks})} is $[f,h,\lifo]$ or depth variants with any default tiebreaking.
        \item \textbf{Positive-cost IPC domains} is $[f,h,\lifo]$.
       \end{itemize}
\end{itemize}

{
\setlength{\tabcolsep}{0.1em}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:lmcut-zerocost-full}}.
 }
 \label{tbl:dtg-lmcut-zero}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-zero-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 620 zerocost instances}. We highlight the best results when the difference between the maximum and the minimum coverage exceeds 2, \emph{including \refig{tbl:mands-zerocost-full}}.
 }
 \label{tbl:dtg-mands-zero}
 }
\end{table}

\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-lmcut}
 \caption{
 Coverage results with \textbf{ \lmcut for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-lmcut-ipc}
 }
\end{table}
\begin{table}[htbp]
 {
 \centering
 \input{tables/8-ipc-mands}
 \caption{
 Coverage results with \textbf{ \mands for computing $f$ and inadmissible distance-to-go heuristics for tiebreaking, on 1104 standard IPC benchmark instances}.
 }
 \label{tbl:dtg-mands-ipc} }
\end{table}
}

\clearpage
\subsection{Simple Dynamic Configuration for Overall Performance}

In practice, the performance degradation when using multi-heuristic strategy in domains with only positive cost actions does not pose a problem.
We can easily avoid the overhead incurred by the distance-to-go heuristics in domains with only positive cost actions by applying the following, simle policy:: 
When solving an instance, if there are any zero-cost actions, use a multi-heuristic strategy.
Otherwise, use a single-heuristic strategy.

Since such a check has negligible impact on the total runtime, we can extrapolate the result of applying this rule based on the previously obtained results.
Coverage results in \reftbl{tbl:dtg-summary-sum} show the total coverage of
zerocost and benchmark domains. The bottom two rows, labeled as \emph{dynamic configuration},
are the extrapolated results when the switching policy is applied -- this dynamic configuratoin achieves the highest overall coverage.

\begin{table}[htbp]
 \centering \input{tables/8-1-summary-sum}
 \caption{
 % 
 Summary Results: Coverage comparison, the total of IPC domains and Zerocost domains (the number of instances
 solved in 5min, 4GB) between several sorting strategies, plus a dynamic configuration strategy.  $[f,h,\fifo],
 [f,h,\ro], [f,\hh,\cdot], [f,h, \hh,\cdot], [f,\ffo,\cdot]$ are not shown because they achieve smaller coverage.
 % 
 }
 \label{tbl:dtg-summary-sum}
\end{table}

When the configuration rule is applied to standard IPC instances, the domains with zero-cost actions are \pddl{Cybersec} and \pddl{Openstacks} only. They are solved using a multi-heuristic strategy while other domains are solved in the best performing single-heuristic strategy. In Zerocost instances, all domains are solved using the multi-heuristic strategy.
\todo*{Maybe we should show dynamic configuration results in the detailed per-domain tables, just so that it's obvious that we can get ``dominant'', state-of-the-art  behavior --- results are simulated, not actually implemented. Thus the total results should be fine. However, I added exactly which domains were zero-cost.}

% While these multi-heuristic strategies did not improve the perfomance in
% the positive cost domains because the final plateaus are small, a simple
% method which 


Overall, these results also strengthen our claim that one should not necessarily rely upon $h$-based
tiebreaking in some
domains, as already discussed in \refsec{sec:noh}. In zerocost domains,
using a distance-to-go version of an inadmissible heuristic function for
tiebreaking is more effective. Also, combining the depth metric with
such an inadmissible heuristics is also effective.
