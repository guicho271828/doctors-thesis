\clearpage 
\section{Viewing \astar as a Series of Satisficing Search Episodes}
\label{sec:discussion}

So far, we have shown that by carefully analyzing search within an $f$-cost plateau,
we were able to develop an effective
{\it knowledge-free}, depth-based tiebreaking method which can significantly improve search performance on domains with zero-cost actions.
We now propose a more general framework which underscores the importance of tiebreaking in \astar.
\textbf{Cost-optimal search
can be seen as a series of satisficing searches on each plateau}. In this view, the problem of tiebreaking can be
reduced to a satisficing search.

First, for the ease of discussion, 
we say that a sorting strategy is an \emph{admissible sorting strategy}
when Best First Search using the strategy is guaranteed to return a cost-optimal solution.
Clearly, a sorting strategy for \astar is admissible if and only if the 
first sorting criterion $f$ is admissible (since $f=g+h$, $h$ must also be an admissible heuristic).
However, the admissibility of later sorting criteria used for tiebreaking is not necessarily.

This means that the search within the same $f$ plateau can be an arbitrary pure\footnote{as opposed to the ``satisficing'' track setting in IPC which also seeks to minimize the plan cost with anytime algorithms} satisficing search without any cost minimization requirement. For example,
if we ignore the first sorting criterion in the standard admissible strategy
$[f,h,\fifo]$, we get $[h,\fifo]$, which is exactly
the same configuration as a GBFS using \fifo default tiebreaking. It
means that within the plateau of the same $f$, $[f,h,\fifo]$ is
performing a satisficing GBFS.
As another example, the reason for the poor performance of $[f,\fifo]$
is clearly that it is running $[\fifo]$,
an uninformed satisficing breadth-first search in the plateau.
{\bf [XXXTODO: move following sentences after d2go experiment data] }
Furthermore, the good performance of $[f^{\lmcut},\ffo,\fifo]$ is also clear:
$\ffo$ is by itself known to be a powerful inadmissible heuristic  % let's avoid using \sota to describe relatively ``old'' heuristics like ff (where ``relatively old'': 10yrs).
function for satisficing GBFS, and 
if we ignore the first sorting criterion, $[f^{\lmcut},\ffo,\fifo]$ is a GBFS with $[\ffo,\fifo]$.

From this perspective, we can reinterpret \astar as follows: \astar expands the nodes in best-first order of $f$ value. When the
heuristic function is admissible, the $f$ values of the nodes expanded by \astar never decreases during the
search process.
Thus, the entire process of \astar can be considered as a series of search episodes on each $\plateau{f}$.
The search on each plateau terminates when the plateau is proven to contain no goal nodes (UNSAT), or when a goal is found (SAT).
When the plateau is UNSAT, then the search continues to the plateau with the next smallest $f$ value.
\refig{fig:astar-sat} illustrates this view.

\begin{figure}[htbp]
 \includegraphics{img/astar/plateau-5.pdf}
 \caption{The concept of \astar as a sequence of satisficing searches.}
 \label{fig:astar-sat}
\end{figure}


This is also somewhat similar to the standard approach to model-based sequential / temporal planning using SAT/IP/CP solvers \cite{kautz1992planning,van2005optiplan}.
% \cite{rintanen2012planning,   Rintanen is state-of-the-art but not a good exemplar for this point, because his solver jumps around various horizons. van2005optiplan} in a slightly different sense.  
In model-based planning, a
planning problem is converted to a corresponding constraint satisfaction problem with a finite horizon $t$ (plan
length / makespan). The search starts from the horizon 0 and tests if the problem is satisfiable. If not, then it
increases the horizon and retests the same problem with additional constraints for a new horizon $t+1$. 
The strategy of iterative search over a sequence of horizons in model-based planning is somewhat analogous to our view of \astar as a sequence of satisficing search over a set of plateaus.



%In forward heuristic search algorithms such as \astar, the concept of horizon corresponds to the $f$ value, which is a lower bound of the solution cost.


% XXX it's not a correct/safe to say that model-based methods solves from scratch on each iteration. In a model-based planners, at iteration  t, a constraint is added to exclude solutions with <t steps/layers (depending on whether layers are sequential/parallel) so that only possible solutions for that horizon are tested, so on the t't hiteration no search effort is wasted searching for solutions <t. This is different from the way IDA* repeats all work on each iteration.

%% A key difference in the \astar-based cost-optimal planning from the model-based planning is
%% that the information is transmitted between different horizons:
%% In \astar, nodes that are generated in the smaller
%% $f$ layer will be ``sent'' to the larger $f$ layer through the global OPEN
%% list, while current model-based methods prove the satisfiability of
%% different horizons independently -- in each iteration of the search,
%% they have to generate a new instance of a SAT/IP problem, and the
%% underlying model-based solvers are forced to start the search from the scratch.

%More precisely, each iteration of \astar only requires testing the satisfiability in the space of particular
%$f$ while each iteration of model-based solvers tests the satisfiability in the space of all nodes $0\leq f(n)\leq t$ ($t$: a horizon).   


%This latter behavior also connects model-based approaches to Iterative Deepening \astar
%\cite{korf1985depth} where the search is restarted from the scratch on each iteration, forgetting the past search
%effort in order to ensure the linear space usage.
%\refig{fig:idastar-sat} illustrates the concept.
% 
%\todo*{A more standard interpretation of the connectin between SAT/IP/CSP planning vs \astar is that SAT/IP/CSP are
%doing iterated deepening, where each iteration seeks a satisficing solution, like IDA*. }
% 

%% \begin{figure}[htbp]
%%  \includegraphics{img/astar/plateau-6.pdf}
%%  \caption{The concept of IDA* and model-based planning as a sequence of satisficing searches.}
%%  \label{fig:idastar-sat}
%% \end{figure}

One may notice the difference between the satisficing search and the search on a plateau.
In fact, the former starts from a single initial node while the latter may start from multiple initial nodes.
For example, in satisficing planning, the search space contains a single start node which corresponds to an initial state.
% 
In contrast, when \astar starts expanding a new current $f$ value $f_{\mit{cur}}$ after expanding all nodes with $f<f_\mit{cur}$,
there may be multiple nodes with $f=f_\mit{cur}$ in the open list.
These nodes are generated as a result of expansions of the parent nodes with $f<f_\mit{cur}$.
% The search in this plateau terminates when the plateau is proven to contain no goal nodes (UNSAT), or some goal is found (SAT).
% When the plateau is UNSAT, then the search continues to the next plateau.
% 
However, the difference is superficial: The latter can be reduced to the former case by introducing a dummy node
which acts as a common parent of all initial nodes. We can thus reformulate the plateau search problem as a satisficing search from the single dummy node.


This view of \astar search as a series of satisficing searches also reminiscent of the behavior of 
iterative deepening \astar \cite{korf1985depth}, which executes a series of satisficing searches with a $f$-cost limit which increases on each iteration. 
However, ``\astar-as a sequence of satisficing search'' differs from IDA* in that IDA*, in order to achieve linear memory usage, repeats previous work on each iteration.

\begin{comment} % If you're still considering submitting tiebreaking for satisficing to a conference, including this subsection can block the conference paper and is a bad idea.
\subsection{Depth Diversification for Satisficing Search}

In order to strengthen the connection between tiebreaking and satisficing search,
we conducted another set of experiments. In the previous experiments, we showed that the distance-to-go
\ff heuristic $\ffo$ for \textbf{satisficing search within a plateau} was improved by the depth diversification
$\depth$.
% 
A natural extension of this idea is that the depth metric could also enhance the performance of $\ffo$ used for
\textbf{satisficing search in general}, which should hold if the search on plateaus and satisficing search are in
fact the same thing.
\todo*{``exporting from optimizing to satisficing'' and ``exporting from satisficing to optimizing'' are not symmetric. The latter is interesting and surprising, the former, not so much. --- changed the tone, emphasized the purpose}

We provide preliminary results on the 280 IPC8 satisficing track
instances. We tested GBFS using the distance-to-go variations of three
inadmissible heuristics for satisficing search: FF heuristics
 \cite{Hoffmann01}, Causal Graph (CG) heuristics \cite{Helmert2006}, and
Context Enhanced Additive (CEA) heuristics\ \cite{helmert2008unifying}.
For each heuristics, we tested eager and lazy search, with and without
the depth metric.  Tests are conducted under 5 min, 4GB
resource constraint.

In Eager search, depth metric
improved the performance of $\cgo$ ($60\rightarrow $ \textbf{64}), but no
improvement was observed in $\ceo$ ($62\rightarrow 62$)
and $\ffo$ ($73\rightarrow 73$). In Lazy search, depth metric
improved the performance of all three heuristics
($\cgo$: $36\rightarrow $ \textbf{50}, 
 $\ceo$: $39\rightarrow $ \textbf{48}, 
 $\ffo$: $54\rightarrow $ \textbf{93}). This is reasonable
because lazy search forces each node to derive the heuristic value from
its parent, and it makes more nodes to have the same heuristic value,
increasing the size of each plateau.

% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-gbfs}
%  \caption{
%  Coverages under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo default
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  (g): GBFS with $[\hh]$ sorting strategy.
%  (G): GBFS with depth based diversification $[\hh,\depth]$.
%  }
%  \label{tbl:gbfs}
% \end{table}

% We also tested each combination on Type-GBFS, a recent \sota enhancement
% to GBFS. The results in \reftbl{tbl:type-gbfs} show that the depth
% metric also improves the performance of these configurations. Furthermore, we tested LAMA and
% Type-LAMA with and without depth metric. LAMA is an old \sota
% satisficing planner combining various satisficing enhancements such as
% Lazy-evaluation, distance-to-go estimates, multi-heuristic search and
% preferred operator queues. Type-LAMA is a newer \sota planner and an
% extension of LAMA using Type-GBFS, and it has performed the best among non-portfolio
% planners in IPC8 satisficing track. In \reftbl{tbl:lama}, we observed
% that the depth metric also improved the performance of LAMA and Type-LAMA.
% 
% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-type-gbfs}
%  \caption{
%  Coverages of Type-GBFS under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo default
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  In each expansion, Type-GBFS alternates standard GBFS and Type-based exploration using $[g,\hh]$.
%  The sorting strategy of the GBFS part of (gt) is $[\hh]$, while (Gt) uses $[\hh,\depth]$.
%  }
%  \label{tbl:type-gbfs}
% \end{table}
% 
% \begin{table}[htbp]
%  % \setlength{\tabcolsep}{0.1em}
%  \centering
%  \input{tables/9-lama}
%  
%  \caption{ Coverages of satisficing planners LAMA (winner of IPC7, old \sota)
%  and Type-LAMA (non-portfolio winner of IPC8, newer \sota) under 5 min, 4GB
%  experiments, comparing the performance between the original and the
%  depth-enhanced variants. All configurations run the first GBFS
%  iteration only, apply \fifo default tiebreaking (we omit it from
%  the description below), apply lazy evaluation and use distance-to-go synergy
%  heuristics $\ffo / \hat{h}^{\text{LMcount}}$.
%  % 
%  LAMA alternates between four OPEN lists: an open list of $[\ffo]$, a
%  preferred operator queue of $\ffo$, an open list of
%  $[\hat{h}^{\text{LMcount}}]$, and a preferred operator queue of
%  $\hat{h}^{\text{LMcount}}$.  In contrast, Type-LAMA alternates
%  between five OPEN lists: In addition to the 4 queues in LAMA, it has a
%  type-based exploration queue using $[g,\ffo]$.  The depth is applied
%  only to the first queue, i.e. $[\ffo] \rightarrow [\ffo,\depth]$, and
%  is not applied to the other queues. In both LAMA and Type-LAMA, depth
%  metric improves the coverage.}
%  \label{tbl:lama}
% \end{table}
\end{comment}

\begin{comment} % Too much excitement. We've already said enough already on this.
In the past, cost-optimal search techniques and satisficing search techniques used to be developed rather separately, and there has been only a handful of knowledge migration between them, most of which are abstract ideas such as delete-relaxation, landmarks, causal graphs or pattern database.
Otherwise, the migration is unidirectional, in particular from cost-optimal to satisficing search, because it is easy or trivial to relax the optimality requirements.
% 
Our results and the new interpretation, \textbf{cost-optimal search is a sequence of satisficing searches on each plateau},
open up a new opportunity to break this boundary.  We provided the fundamentals of how and why we can import
satisficing search techniques to the cost-optimal search (e.g. $\ffo$ heuristics in cost-optimal search).  There is a
large avenue for future work in making a new migration happen.
\end{comment}

