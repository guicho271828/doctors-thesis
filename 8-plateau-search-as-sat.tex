\clearpage 
\section{A New Framework:  \astar as a Series of Satisficing Search Episodes}
\label{sec:discussion}

So far, we have shown that by carefully analyzing search within an $f$-cost plateau,
we were able to develop an effective
{\it knowledge-free}, depth-based tiebreaking method which can significantly improve search performance on domains with zero-cost actions.
We now propose a more general framework which underscores the importance of tiebreaking in \astar.
\textbf{Cost-optimal search
can be seen as a series of satisficing searches on each plateau}. In this framework, the problem of tiebreaking can be
reduced to a satisficing search.

First, for the ease of discussion, 
we say that a sorting strategy is an \emph{admissible sorting strategy}
when Best First Search using the strategy is guaranteed to return a cost-optimal solution.
Clearly, a sorting strategy for \astar is admissible if and only if the 
first sorting criterion $f$ is admissible (since $f=g+h$, $h$ must also be an admissible heuristic).
However, the later sorting criteria used for tiebreaking is not necessarily are not necessarily admissible.

This means that the search within the same $f$ plateau can be an arbitrary  satisficing search\footnote{This refers to any algorithm which seeks a satisficing solution, as opposed to the ``satisficing'' track setting in IPC which also seeks to minimize the plan cost with anytime algorithms} without any cost minimization requirement. For example,
if we ignore the first sorting criterion in the standard admissible strategy
$[f,h,\fifo]$, we have $[h,\fifo]$, which is exactly
the same configuration as a GBFS using \fifo default tiebreaking. This 
means that within a particular $f$-cost plateau, $[f,h,\fifo]$ is
performing a satisficing GBFS.
As another example, the reason for the poor performance of $[f,\fifo]$
is clearly that it is running $[\fifo]$,
an uninformed satisficing breadth-first search in the plateau.

From this perspective, we can reinterpret \astar as follows: \astar expands the nodes in best-first order of $f$ value. When the
heuristic function is admissible, the $f$ values of the nodes expanded by \astar never decreases during the
search process.
Thus, the entire process of \astar can be considered as a series of search episodes on each $\plateau{f}$.
The search on each plateau terminates when the plateau is proven to contain no goal nodes (UNSAT), or when a goal is found (SAT).
When the plateau is UNSAT, then the search continues to the plateau with the next smallest $f$ value.
\refig{fig:astar-sat} illustrates this framework.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.8\linewidth]{img/astar/plateau-5.pdf}
 \caption{The concept of \astar as a sequence of satisficing searches.}
 \label{fig:astar-sat}
\end{figure}

One may notice the difference between the satisficing search and the search on a plateau.
The former starts from a single initial node while the latter may start from multiple initial nodes.
For example, in satisficing planning, the search space contains a single start node which corresponds to an initial state.
% 
In contrast, when \astar starts expanding a new current $f$ value $f_{\mit{cur}}$ after expanding all nodes with $f<f_\mit{cur}$,
there may be multiple nodes with $f=f_\mit{cur}$ in the open list.
These nodes are generated as a result of expansions of the parent nodes with $f<f_\mit{cur}$.
% The search in this plateau terminates when the plateau is proven to contain no goal nodes (UNSAT), or some goal is found (SAT).
% When the plateau is UNSAT, then the search continues to the next plateau.
% 
However, the difference is superficial: The latter can be reduced to the former case by introducing a dummy node
which acts as a common parent of all initial nodes. We can thus reformulate the plateau search problem as a satisficing search from the single dummy node.

This is also somewhat similar to the standard approach to model-based sequential / temporal planning using SAT/IP/CP solvers \cite{kautz1992planning,van2005optiplan}.
% \cite{rintanen2012planning,   Rintanen is state-of-the-art but not a good exemplar for this point, because his solver jumps around various horizons. van2005optiplan} in a slightly different sense.  
In model-based planning, a
planning problem is converted to a corresponding constraint satisfaction problem with a finite horizon $t$ (plan
length / makespan). The search starts from the horizon 0 and tests if the problem is satisfiable. If not, then it
increases the horizon and retests the same problem with additional constraints for a new horizon $t+1$. 
The strategy of iterative search over a sequence of horizons in model-based planning is somewhat analogous to our view of \astar as a sequence of satisficing search over a set of plateaus.

%In forward heuristic search algorithms such as \astar, the concept of horizon corresponds to the $f$ value, which is a lower bound of the solution cost.


% XXX it's not a correct/safe to say that model-based methods solves from scratch on each iteration. In a model-based planners, at iteration  t, a constraint is added to exclude solutions with <t steps/layers (depending on whether layers are sequential/parallel) so that only possible solutions for that horizon are tested, so on the t't hiteration no search effort is wasted searching for solutions <t. This is different from the way IDA* repeats all work on each iteration.

%% A key difference in the \astar-based cost-optimal planning from the model-based planning is
%% that the information is transmitted between different horizons:
%% In \astar, nodes that are generated in the smaller
%% $f$ layer will be ``sent'' to the larger $f$ layer through the global OPEN
%% list, while current model-based methods prove the satisfiability of
%% different horizons independently -- in each iteration of the search,
%% they have to generate a new instance of a SAT/IP problem, and the
%% underlying model-based solvers are forced to start the search from the scratch.

%More precisely, each iteration of \astar only requires testing the satisfiability in the space of particular
%$f$ while each iteration of model-based solvers tests the satisfiability in the space of all nodes $0\leq f(n)\leq t$ ($t$: a horizon).   


%This latter behavior also connects model-based approaches to Iterative Deepening \astar
%\cite{korf1985depth} where the search is restarted from the scratch on each iteration, forgetting the past search
%effort in order to ensure the linear space usage.
%\refig{fig:idastar-sat} illustrates the concept.
% 
%\todo*{A more standard interpretation of the connectin between SAT/IP/CSP planning vs \astar is that SAT/IP/CSP are
%doing iterated deepening, where each iteration seeks a satisficing solution, like IDA*. }
% 

%% \begin{figure}[htbp]
%%  \includegraphics{img/astar/plateau-6.pdf}
%%  \caption{The concept of IDA* and model-based planning as a sequence of satisficing searches.}
%%  \label{fig:idastar-sat}
%% \end{figure}

This view of \astar search as a series of satisficing searches also reminiscent of the behavior of 
iterative deepening \astar \cite{korf1985depth}, which executes a series of satisficing searches with a $f$-cost limit which increases on each iteration. 
However, ``\astar-as a sequence of satisficing search'' differs from IDA* in that IDA*, in order to achieve linear memory usage, repeats previous work on each iteration.

\subsection{Depth Diversification as Satisficing Search}

Within this framework, the implementation of depth diversification can be viewed as a variant of Type-based diversification approach \cite{xie14type} which is specifically tailored toward zero-cost domains.

\citeauthor{xie14type} proposed \emph{type based buckets}, an implementation of the OPEN list which paritions the nodes into buckets according to some set of key values (\emph{types}). They proposed several types, for example $\brackets{1}$, $\brackets{g}$, $\brackets{h}$ or $\brackets{g,h}$. In type-based expansion, at each expansion, a randomly selected node from a randomly selected single bucket is selected. For example, with type $\brackets{g,h}$, a node with $g=5$ and $h=3$ is put into a bucket  $\brackets{5,3}$. This mechanism diversifies the search so that it tries to expand the nodes with various distances from the initial state and various distances from a goal state.

They then proposed Type-based GBFS, which alternates the expansion between normal GBFS with a $[h,\fifo]$ sorting criteria and type-based expansion. This alternating framework addresses a weakness of GBFS: 
GBFS is solely guided by the heuristic function $h$, and heuristic errors in $h$ can easily misguide GBFS to spend all of its time in the wrong part of the search space -- GBFS can become trapped due to heuristic error and cannot recover from the wrong decision until expanding all nodes in that branch.
In the worst case, on infinite graphs, GBFS is not complete because it can be misdirected by the heuristic guidance forever \cite{Valenzano2016}.
In contrast, in type-based GBFS, the alternation with type-based expansion introduces exploratory behavior of nodes with low $g$ and high $h$, offering the possibility of escaping from heuristic error traps.
As a result, type-based GBFS is probabilistically complete on infinite graphs \cite{Valenzano2016}.

Type-based GBFS was primarily evaluated in the context of satisficing search with no consideration of plan quality, and performance is solevely evaluated according to coverage.
This leads to the adaptation of a unit-cost domain model: All action costs are ignored and replaced with unit costs in their experiments in order to boost the coverage. This technique is also used in the first iteration of LAMA2011 \cite{richter2011lama}. 

% (i.e., finding either a goal node or exhausting the plateau)

In our new framework of \astar as a sequence of satisficing searches, depth diversification after $h$-tiebreaking ($[f,h,\depth]$) can be viewed as the combination of (1) an implicit transformation of all edge costs within a single $\plateau{f,h}$ to unit-costs, and (2) a pure type-based exploration within that plateau.
 
The notion of \emph{depth} counts the number of zero-cost actions, which does not change the $f$ value and $h$
value, on the path from the entrance to the current plateau to the current node.  Thus, 
depth-diversification treats  the problem of finding an exit from a particular plateau as a unit-cost satisficing search problem
-- the depth is analogous to a $g$-value calculated with unit costs,  and the satisficing search restricted to a particular plateau.
%% Also, depth diversification puts the nodes in a particular depth into the corresponding depth bucket, then
%% diversifies the search among various depth buckets in a round-robin fashion (in this paper) or by a random
%% selection (conference version of this paper \cite{Asai2016}). If the depth corresponds to the unit-cost $g$-value
%% in each $\plateau{f,h}$, then the implementation-level mechanism for diversification is equivalent to
%% $\brackets{g}$, a type bucket of a single key value $g$. Thus, depth
%% diversification can be said to be using a type bucket of $\depth$ (modulo random/deterministic difference).

Depth diversification for tiebreaking in admissible \astar has a different purpose and context from Type-GBFS for satisficing search,
and is novel in the following aspects.
First, it is focused on finding a satisficing plan \emph{within a single plateau} and on solving \emph{domains with zero-cost actions} which is strictly harder than those without them. 
%Also, the role is limited to each plateau with the same $f$ and $h$ because nodes are put in the depth buckets only after being sorted by $f$ and $h$, 
In contrast, type buckets are global --- type buckets have no preceding sorting criteria, and all open nodes are stored in these buckets.

Nevertheless, the close relationship between depth diversification for admissible \astar and Type-GBFS for satisficing search shows that if we apply our framework of \astar as a series of satisficing searches, we can directly use ideas which have been previously proposed for satisficing search within each $f$-cost plateau search.
In the next section, we present another instance of this general approach.

\begin{comment} % excessive and controversial claims
Despite all this, however, 
This the new view is so powerful that it unifies the two algorithms that have been developed separately for different purposes.
In the past, cost-optimal search techniques and satisficing search techniques used to be developed rather separately, and there has been only a handful of knowledge migration between them, most of which are abstract ideas such as delete-relaxation, landmarks, causal graphs or pattern database. % you seem to be claiming that these are not concrete algorithms, and that in contrast, \astar-as-series-of-satisficing-search allows direct import of concrete algorithms. However, as the type-gbfs vs depth comparison shows, the transfer is not trivial, and one can argue that the relationship between type-gbfs<g> vs depth is not much closer than the relationship between the FF heuristic and a pure admissible delete-relaxation heuristic.
Otherwise, the migration is unidirectional, in particular from cost-optimal to satisficing search, because it is easy or trivial to relax the optimality requirements.
% 
Our results and the new interpretation, \textbf{cost-optimal search is a sequence of satisficing searches on each plateau},
open up a new opportunity to break this boundary.
\end{comment}
% We provided the fundamentals of how and why we can import
% satisficing search techniques to the cost-optimal search (e.g. $\ffo$ heuristics in cost-optimal search).  There is a
% large avenue for future work in making a new migration happen.



\begin{comment}
% If you're still considering submitting tiebreaking for satisficing to a conference, including this subsection can block the conference paper and is a bad idea.
\subsection{Depth Diversification for Satisficing Search}

In order to strengthen the connection between tiebreaking and satisficing search,
we conducted another set of experiments. In the previous experiments, we showed that the distance-to-go
\ff heuristic $\ffo$ for \textbf{satisficing search within a plateau} was improved by the depth diversification
$\depth$.
% 
A natural extension of this idea is that the depth metric could also enhance the performance of $\ffo$ used for
\textbf{satisficing search in general}, which should hold if the search on plateaus and satisficing search are in
fact the same thing.
\todo*{``exporting from optimizing to satisficing'' and ``exporting from satisficing to optimizing'' are not symmetric. The latter is interesting and surprising, the former, not so much. --- changed the tone, emphasized the purpose}

We provide preliminary results on the 280 IPC8 satisficing track
instances. We tested GBFS using the distance-to-go variations of three
inadmissible heuristics for satisficing search: FF heuristics
 \cite{Hoffmann01}, Causal Graph (CG) heuristics \cite{Helmert2006}, and
Context Enhanced Additive (CEA) heuristics\ \cite{helmert2008unifying}.
For each heuristics, we tested eager and lazy search, with and without
the depth metric.  Tests are conducted under 5 min, 4GB
resource constraint.

In Eager search, depth metric
improved the performance of $\cgo$ ($60\rightarrow $ \textbf{64}), but no
improvement was observed in $\ceo$ ($62\rightarrow 62$)
and $\ffo$ ($73\rightarrow 73$). In Lazy search, depth metric
improved the performance of all three heuristics
($\cgo$: $36\rightarrow $ \textbf{50}, 
 $\ceo$: $39\rightarrow $ \textbf{48}, 
 $\ffo$: $54\rightarrow $ \textbf{93}). This is reasonable
because lazy search forces each node to derive the heuristic value from
its parent, and it makes more nodes to have the same heuristic value,
increasing the size of each plateau.

% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-gbfs}
%  \caption{
%  Coverages under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo default
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  (g): GBFS with $[\hh]$ sorting strategy.
%  (G): GBFS with depth based diversification $[\hh,\depth]$.
%  }
%  \label{tbl:gbfs}
% \end{table}

% We also tested each combination on Type-GBFS, a recent \sota enhancement
% to GBFS. The results in \reftbl{tbl:type-gbfs} show that the depth
% metric also improves the performance of these configurations. Furthermore, we tested LAMA and
% Type-LAMA with and without depth metric. LAMA is an old \sota
% satisficing planner combining various satisficing enhancements such as
% Lazy-evaluation, distance-to-go estimates, multi-heuristic search and
% preferred operator queues. Type-LAMA is a newer \sota planner and an
% extension of LAMA using Type-GBFS, and it has performed the best among non-portfolio
% planners in IPC8 satisficing track. In \reftbl{tbl:lama}, we observed
% that the depth metric also improved the performance of LAMA and Type-LAMA.
% 
% \begin{table}[htbp]
%  \setlength{\tabcolsep}{0.3em}
%  \centering
%  \input{tables/9-type-gbfs}
%  \caption{
%  Coverages of Type-GBFS under 5 min, 4GB experiments, comparing the variants with
%  and without depths. All configurations uses \fifo default
%  tiebreaking (we omit it from the description below).
%  $\ffo,\ceo,\cgo$ are the distance-to-go variations of FF,
%  Context Enhanced Additive, Causal Graph heuristics.
%  In each expansion, Type-GBFS alternates standard GBFS and Type-based exploration using $[g,\hh]$.
%  The sorting strategy of the GBFS part of (gt) is $[\hh]$, while (Gt) uses $[\hh,\depth]$.
%  }
%  \label{tbl:type-gbfs}
% \end{table}
% 
% \begin{table}[htbp]
%  % \setlength{\tabcolsep}{0.1em}
%  \centering
%  \input{tables/9-lama}
%  
%  \caption{ Coverages of satisficing planners LAMA (winner of IPC7, old \sota)
%  and Type-LAMA (non-portfolio winner of IPC8, newer \sota) under 5 min, 4GB
%  experiments, comparing the performance between the original and the
%  depth-enhanced variants. All configurations run the first GBFS
%  iteration only, apply \fifo default tiebreaking (we omit it from
%  the description below), apply lazy evaluation and use distance-to-go synergy
%  heuristics $\ffo / \hat{h}^{\text{LMcount}}$.
%  % 
%  LAMA alternates between four OPEN lists: an open list of $[\ffo]$, a
%  preferred operator queue of $\ffo$, an open list of
%  $[\hat{h}^{\text{LMcount}}]$, and a preferred operator queue of
%  $\hat{h}^{\text{LMcount}}$.  In contrast, Type-LAMA alternates
%  between five OPEN lists: In addition to the 4 queues in LAMA, it has a
%  type-based exploration queue using $[g,\ffo]$.  The depth is applied
%  only to the first queue, i.e. $[\ffo] \rightarrow [\ffo,\depth]$, and
%  is not applied to the other queues. In both LAMA and Type-LAMA, depth
%  metric improves the coverage.}
%  \label{tbl:lama}
% \end{table}
\end{comment}

\begin{comment} % Too much excitement. We've already said enough already on this.
In the past, cost-optimal search techniques and satisficing search techniques used to be developed rather separately, and there has been only a handful of knowledge migration between them, most of which are abstract ideas such as delete-relaxation, landmarks, causal graphs or pattern database.
Otherwise, the migration is unidirectional, in particular from cost-optimal to satisficing search, because it is easy or trivial to relax the optimality requirements.
% 
Our results and the new interpretation, \textbf{cost-optimal search is a sequence of satisficing searches on each plateau},
open up a new opportunity to break this boundary.  We provided the fundamentals of how and why we can import
satisficing search techniques to the cost-optimal search (e.g. $\ffo$ heuristics in cost-optimal search).  There is a
large avenue for future work in making a new migration happen.
\end{comment}

